{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag-IfAz56EUA"
      },
      "source": [
        "# Transfer Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jWP5W_Ud6EUB",
        "outputId": "c9434802-3eda-4e60-f955-579705d08b9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBI763ZLDBSI",
        "outputId": "59553491-4aa0-4fef-f2a0-fb55bf2348af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "# Compatibility layer between Python 2 and Python 3\n",
        "from __future__ import print_function\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
        "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qx-0OmLDBSJ"
      },
      "source": [
        "# import images without generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79-njE-xDBSJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from skimage.io import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7bRRiwtDBSJ"
      },
      "outputs": [],
      "source": [
        "train_data =r'C:\\Users\\cmp3woodwk\\Desktop\\deep transfer learning\\gasf_all'\n",
        "test_data =r'C:\\Users\\cmp3woodwk\\Desktop\\deep transfer learning\\gasf_user1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1eeqdWSDBSK"
      },
      "outputs": [],
      "source": [
        "# for 5 labels\n",
        "\n",
        "def one_hot_label(img):\n",
        "    label = img.split('.')[0]\n",
        "    if label == 'one':\n",
        "        ohl = np.array([1,0,0,0,0])\n",
        "    elif label == 'two':\n",
        "        ohl = np.array([0,1,0,0,0])\n",
        "    elif label == 'three':\n",
        "        ohl = np.array([0,0,1,0,0])\n",
        "    elif label == 'four':\n",
        "        ohl = np.array([0,0,0,1,0])\n",
        "    elif label == 'five':\n",
        "        ohl = np.array([0,0,0,0,1])\n",
        "    else:\n",
        "        print(label)\n",
        "    return ohl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIP1ajAmDBSK"
      },
      "outputs": [],
      "source": [
        "def train_data_with_label():\n",
        "  train_images = []\n",
        "  for i in tqdm(os.listdir(train_data)):\n",
        "    path = os.path.join(train_data, i)\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (64,64))\n",
        "\n",
        "    train_images.append([np.array(img)])\n",
        "\n",
        "  return train_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfVhciFKDBSL"
      },
      "outputs": [],
      "source": [
        "def test_data_with_label():\n",
        "  test_images = []\n",
        "  for i in tqdm(os.listdir(test_data)):\n",
        "    path = os.path.join(test_data, i)\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (64,64))\n",
        "\n",
        "    test_images.append([np.array(img)])\n",
        "\n",
        "\n",
        "\n",
        "  return test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq5obEZYDBSL"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fBom5HrnDBSL",
        "outputId": "003e6da2-f88e-4b49-fe3b-c4548332e58e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 17750/17750 [02:20<00:00, 125.90it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████| 874/874 [00:06<00:00, 129.72it/s]\n"
          ]
        }
      ],
      "source": [
        "training_images = train_data_with_label()\n",
        "testing_images = test_data_with_label()\n",
        "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,64,64,3)\n",
        "tst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,64,64,3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITRmXh-NDBSM"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IQWg_SX6EUE"
      },
      "outputs": [],
      "source": [
        "#mobile = keras.applications.mobilenet.MobileNet()\n",
        "mobile = keras.applications.InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eztjwgD6EUG"
      },
      "outputs": [],
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnixgJ1rDBSN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def feature_normalize(dataset):\n",
        "\n",
        "    mu = np.mean(dataset, axis=0)\n",
        "    sigma = np.std(dataset, axis=0)\n",
        "    return (dataset - mu)/sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kYi5rJnDBSN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def show_confusion_matrix(validations, predictions):\n",
        "\n",
        "    matrix = metrics.confusion_matrix(validations, predictions)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(matrix,\n",
        "                cmap=\"coolwarm\",\n",
        "                linecolor='white',\n",
        "                linewidths=1,\n",
        "                xticklabels=LABELS,\n",
        "                yticklabels=LABELS,\n",
        "                annot=True,\n",
        "                fmt=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YVGp3sPDBSN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def show_basic_dataframe_info(dataframe,\n",
        "                              preview_rows=20):\n",
        "\n",
        "    \"\"\"\n",
        "    This function shows basic information for the given dataframe\n",
        "    Args:\n",
        "        dataframe: A Pandas DataFrame expected to contain data\n",
        "        preview_rows: An integer value of how many rows to preview\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # Shape and how many rows and columns\n",
        "    print(\"Number of columns in the dataframe: %i\" % (dataframe.shape[1]))\n",
        "    print(\"Number of rows in the dataframe: %i\\n\" % (dataframe.shape[0]))\n",
        "    print(\"First 20 rows of the dataframe:\\n\")\n",
        "    # Show first 20 rows\n",
        "    print(dataframe.head(preview_rows))\n",
        "    print(\"\\nDescription of dataframe:\\n\")\n",
        "    # Describe dataset like mean, min, max, etc.\n",
        "    # print(dataframe.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5DwdhNsDBSO"
      },
      "outputs": [],
      "source": [
        "def read_data(file_path):\n",
        "    column_names =  ['AirPressure' , 'EDA' , 'EnvNoise' , 'HR', 'UV' , 'X' , 'Y' , 'Z' ,'Motion', 'bTemp' ,'state']\n",
        "    df = pd.read_csv(file_path,\n",
        "                     header=None,\n",
        "                     names=column_names)\n",
        "    df.dropna(axis=0, how='any', inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRrB2FOrDBSO"
      },
      "outputs": [],
      "source": [
        "def read_data2(file_path):\n",
        "    column_names =  ['EDA' , 'HR', 'X' , 'Y' , 'Z' ,'state']\n",
        "    df = pd.read_csv(file_path,\n",
        "                     header=None,\n",
        "                     names=column_names)\n",
        "    df.dropna(axis=0, how='any', inplace=True)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq2haPFSDBSO"
      },
      "outputs": [],
      "source": [
        "def convert_to_float(x):\n",
        "    try:\n",
        "        return np.float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1XVxAXiDBSO"
      },
      "outputs": [],
      "source": [
        "def feature_normalize(dataset):\n",
        "    mu = np.mean(dataset, axis=0)\n",
        "    sigma = np.std(dataset, axis=0)\n",
        "    return (dataset - mu)/sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVL-90aEDBSO"
      },
      "outputs": [],
      "source": [
        "def plot_axis(ax, x, y, title):\n",
        "    ax.plot(x, y)\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
        "    ax.set_xlim([min(x), max(x)])\n",
        "    ax.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyaCVUJvDBSP"
      },
      "outputs": [],
      "source": [
        "def plot_activity(activity, data):\n",
        "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3,\n",
        "         figsize=(15, 10),\n",
        "         sharex=True)\n",
        "    plot_axis(ax0, data['timestamp'], data['x-axis'], 'x-axis')\n",
        "    plot_axis(ax1, data['timestamp'], data['y-axis'], 'y-axis')\n",
        "    plot_axis(ax2, data['timestamp'], data['z-axis'], 'z-axis')\n",
        "    plt.subplots_adjust(hspace=0.2)\n",
        "    fig.suptitle(activity)\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_n5Q1tZDBSP"
      },
      "outputs": [],
      "source": [
        "def create_segments_and_labels(df, time_steps, step, label_name):\n",
        "\n",
        "    \"\"\"\n",
        "    This function receives a dataframe and returns the reshaped segments\n",
        "    of x,y,z acceleration as well as the corresponding labels\n",
        "    Args:\n",
        "        df: Dataframe in the expected format\n",
        "        time_steps: Integer value of the length of a segment that is created\n",
        "    Returns:\n",
        "        reshaped_segments\n",
        "        labels:\n",
        "    \"\"\"\n",
        "    N_FEATURES = 2\n",
        "    # Number of steps to advance in each iteration (for me, it should always\n",
        "    # be equal to the time_steps in order to have no overlap between segments)\n",
        "    # step = time_steps\n",
        "    segments = []\n",
        "    labels = []\n",
        "    for i in range(0, len(df) - time_steps, step):\n",
        "        xs = df['EDA'].values[i: i + time_steps]\n",
        "        ys = df['HR'].values[i: i + time_steps]\n",
        "        # Retrieve the most often used label in this segment\n",
        "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
        "        segments.append([xs, ys])\n",
        "        labels.append(label)\n",
        "    # Bring the segments into a better shape\n",
        "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    return reshaped_segments, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhDjKwXgDBSP"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "--H_wgJX6EUr",
        "outputId": "a9bb71a4-bd22-4271-c6b5-71404295c752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',input_shape=(64,64,3)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFzS3oJt6EUw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0j_Cb23I6EUw",
        "outputId": "b63c77fc-9050-4945-b250-12fe73372255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 conv2d_1\n",
            "1 conv2d_2\n",
            "2 max_pooling2d_1\n",
            "3 dropout_1\n",
            "4 flatten_1\n",
            "5 dense_1\n",
            "6 dropout_2\n",
            "7 dense_2\n"
          ]
        }
      ],
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM39Jlhx6EUy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0idogFq6EUy"
      },
      "outputs": [],
      "source": [
        "#for layer in model.layers:\n",
        "#    layer.trainable=True #50% accuracy when alone was false\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDZdvUmlDBSV",
        "outputId": "fe64cea1-9933-43b2-8a16-e2781bef2309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keras version  2.3.1\n",
            "\n",
            "--- Load, inspect and transform data ---\n",
            "\n",
            "Number of columns in the dataframe: 11\n",
            "Number of rows in the dataframe: 355089\n",
            "\n",
            "First 20 rows of the dataframe:\n",
            "\n",
            "    AirPressure    EDA  EnvNoise  HR  UV    X    Y    Z  Motion  bTemp  state\n",
            "0        1003.3  20903        54  73   0  0.7 -0.3  0.5     0.9   33.2      5\n",
            "1        1003.6  20903        54  73   0  0.9 -0.3 -0.1     0.9   33.2      5\n",
            "2        1004.1  20903        54  73   0  0.2 -0.7 -0.7     1.0   33.1      5\n",
            "3        1004.1  20903        54  73   0  0.2 -0.7 -0.7     1.0   33.1      5\n",
            "4        1004.0  20903        54  73   0  0.2 -0.7 -0.7     1.0   33.1      5\n",
            "5        1003.8  20903        54  73   0  0.2 -0.7 -0.7     1.0   33.1      5\n",
            "6        1003.8  20903        54  73   0  0.1 -0.7 -0.7     1.1   33.1      5\n",
            "7        1019.2  20903        54  73   0 -0.5 -0.6 -0.7     1.0   29.0      3\n",
            "8        1019.2  20903        54  73   0 -0.5 -0.6 -0.8     1.1   29.0      3\n",
            "9        1019.2  20903        54  73   0 -0.4 -0.8 -0.6     1.0   30.0      3\n",
            "10       1019.2  20903        54  73   0 -0.4 -0.8 -0.5     1.0   30.0      3\n",
            "11       1011.8  20903        54  73   0  0.2  1.0  0.0     1.0   27.7      2\n",
            "12       1011.8  20903        54  73   0  0.2  1.0  0.0     1.0   27.7      2\n",
            "13       1011.8  20903        54  73   0  0.3  1.0 -0.2     1.0   27.8      2\n",
            "14       1011.8  20903        54  73   0  0.2  1.0 -0.1     1.0   27.8      2\n",
            "15       1019.7  20222        54  73   0 -0.0  0.8  0.6     1.0   30.6      4\n",
            "16       1019.7  20222        54  73   0 -0.0  0.8  0.6     1.0   30.6      4\n",
            "17       1019.7  20222        54  73   0 -0.7  0.6 -0.5     1.1   30.6      4\n",
            "18       1019.7  20222        54  73   0 -0.6  0.3  0.2     0.7   30.6      4\n",
            "19       1019.7  20222        54  73   0 -0.1  1.1  0.3     1.2   30.6      4\n",
            "\n",
            "Description of dataframe:\n",
            "\n",
            "\n",
            "--- Reshape the data into segments ---\n",
            "\n",
            "\n",
            "--- Reshape data to be accepted by Keras ---\n",
            "\n",
            "x_train shape:  (17750, 100, 2)\n",
            "17750 training samples\n",
            "y_train shape:  (17750,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ------- THE PROGRAM TO LOAD DATA AND TRAIN THE MODEL -------\n",
        "\n",
        "# Set some standard parameters upfront\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "sns.set() # Default seaborn look and feel\n",
        "plt.style.use('ggplot')\n",
        "print('keras version ', keras.__version__)\n",
        "\n",
        "#LABELS = [\"rest\",\n",
        "#          \"experiment\"]\n",
        "\n",
        "LABELS = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The number of steps within one time segment\n",
        "TIME_PERIODS = 100 #was 80\n",
        "# The steps to take from one segment to the next; if this value is equal to\n",
        "# TIME_PERIODS, then there is no overlap between the segments\n",
        "STEP_DISTANCE = 20 #was 40\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Load, inspect and transform data ---\\n\")\n",
        "\n",
        "# Load data set containing all the data from csv\n",
        "df = read_data('all.csv')\n",
        "df_user1 = read_data2('user1.csv')\n",
        "\n",
        "\n",
        "# Describe the data\n",
        "show_basic_dataframe_info(df, 20)\n",
        "\n",
        "for activity in np.unique(df[\"state\"]):\n",
        "    subset = df[df[\"state\"] == activity][:180]\n",
        "    #plot_activity(activity, subset)\n",
        "\n",
        "# Define column name of the label vector\n",
        "LABEL = \"ActivityEncoded\"\n",
        "# Transform the labels from String to Integer via LabelEncoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Add a new column to the existing DataFrame with the encoded values\n",
        "#df[LABEL] = le.fit_transform(df[\"activity\"].values.ravel())\n",
        "\n",
        "df[LABEL] = le.fit_transform(df[\"state\"].values.ravel())\n",
        "df_user1[LABEL] = le.fit_transform(df_user1[\"state\"].values.ravel())\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Reshape the data into segments ---\\n\")\n",
        "\n",
        "# Differentiate between test set and training set\n",
        "df_test = df_user1\n",
        "#df_train = df[df['user-id'] <= 5]\n",
        "df_train = df\n",
        "\n",
        "# Normalize features for training data set\n",
        "df_train['EDA'] = feature_normalize(df['EDA'])\n",
        "df_train['HR'] = feature_normalize(df['HR'])\n",
        "\n",
        "\n",
        "# Reshape the training data into segments\n",
        "# so that they can be processed by the network\n",
        "x_train, y_train = create_segments_and_labels(df_train,\n",
        "                                              TIME_PERIODS,\n",
        "                                              STEP_DISTANCE,\n",
        "                                              LABEL)\n",
        "\n",
        "\n",
        "df_test['EDA'] = feature_normalize(df_user1['EDA'])\n",
        "df_test['HR'] = feature_normalize(df_user1['HR'])\n",
        "\n",
        "x_test1, y_test1 = create_segments_and_labels(df_test,\n",
        "                                              TIME_PERIODS,\n",
        "                                              STEP_DISTANCE,\n",
        "                                              LABEL)\n",
        "\n",
        "n_input = 3\n",
        "\n",
        "\n",
        "print(\"\\n--- Reshape data to be accepted by Keras ---\\n\")\n",
        "\n",
        "# Inspect x data\n",
        "print('x_train shape: ', x_train.shape)\n",
        "# Displays (20869, 40, 3)\n",
        "print(x_train.shape[0], 'training samples')\n",
        "# Displays 20869 train samples\n",
        "\n",
        "# Inspect y data\n",
        "print('y_train shape: ', y_train.shape)\n",
        "# Displays (20869,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIn5rTxkDBSW",
        "outputId": "9f692b77-d242-4388-bcc9-f1c3308dec6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AirPressure</th>\n",
              "      <th>EDA</th>\n",
              "      <th>EnvNoise</th>\n",
              "      <th>HR</th>\n",
              "      <th>UV</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>Motion</th>\n",
              "      <th>bTemp</th>\n",
              "      <th>state</th>\n",
              "      <th>ActivityEncoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1003.3</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>33.2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>33.2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355084</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>58</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355085</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>59</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355086</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>56</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355087</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>53</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355088</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>55</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>355089 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        AirPressure  EDA  EnvNoise   HR  UV   X    Y    Z  Motion  bTemp  \\\n",
              "0            1003.3  6.8        54 -0.6   0 0.7 -0.3  0.5     0.9   33.2   \n",
              "1            1003.6  6.8        54 -0.6   0 0.9 -0.3 -0.1     0.9   33.2   \n",
              "2            1004.1  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "3            1004.1  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "4            1004.0  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "...             ...  ...       ...  ...  ..  ..  ...  ...     ...    ...   \n",
              "355084       1003.7 -0.5        58  1.4   1 0.8 -0.1  0.0     0.8   33.8   \n",
              "355085       1003.7 -0.5        59  1.4   1 0.7 -1.0  0.0     1.2   33.8   \n",
              "355086       1003.7 -0.5        56  1.4   1 1.1 -0.5  0.3     1.2   33.8   \n",
              "355087       1003.7 -0.5        53  1.5   1 0.9 -0.4  0.3     1.0   33.8   \n",
              "355088       1003.7 -0.5        55  1.4   1 1.3 -0.5  0.3     1.4   33.8   \n",
              "\n",
              "        state  ActivityEncoded  \n",
              "0           5                4  \n",
              "1           5                4  \n",
              "2           5                4  \n",
              "3           5                4  \n",
              "4           5                4  \n",
              "...       ...              ...  \n",
              "355084      5                4  \n",
              "355085      5                4  \n",
              "355086      5                4  \n",
              "355087      5                4  \n",
              "355088      5                4  \n",
              "\n",
              "[355089 rows x 12 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42rebHIeDBSW",
        "outputId": "bc254d18-9628-401b-d0ea-eb338fee21ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(355089, 12)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTzjWJ26DBSW",
        "outputId": "b6714e16-c82b-462a-9a11-7ee0cbbe3512"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AirPressure</th>\n",
              "      <th>EDA</th>\n",
              "      <th>EnvNoise</th>\n",
              "      <th>HR</th>\n",
              "      <th>UV</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>Motion</th>\n",
              "      <th>bTemp</th>\n",
              "      <th>state</th>\n",
              "      <th>ActivityEncoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1003.3</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>33.2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>33.2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>54</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355084</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>58</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355085</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>59</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355086</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>56</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355087</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>53</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355088</th>\n",
              "      <td>1003.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>55</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106478 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        AirPressure  EDA  EnvNoise   HR  UV   X    Y    Z  Motion  bTemp  \\\n",
              "0            1003.3  6.8        54 -0.6   0 0.7 -0.3  0.5     0.9   33.2   \n",
              "1            1003.6  6.8        54 -0.6   0 0.9 -0.3 -0.1     0.9   33.2   \n",
              "2            1004.1  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "3            1004.1  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "4            1004.0  6.8        54 -0.6   0 0.2 -0.7 -0.7     1.0   33.1   \n",
              "...             ...  ...       ...  ...  ..  ..  ...  ...     ...    ...   \n",
              "355084       1003.7 -0.5        58  1.4   1 0.8 -0.1  0.0     0.8   33.8   \n",
              "355085       1003.7 -0.5        59  1.4   1 0.7 -1.0  0.0     1.2   33.8   \n",
              "355086       1003.7 -0.5        56  1.4   1 1.1 -0.5  0.3     1.2   33.8   \n",
              "355087       1003.7 -0.5        53  1.5   1 0.9 -0.4  0.3     1.0   33.8   \n",
              "355088       1003.7 -0.5        55  1.4   1 1.3 -0.5  0.3     1.4   33.8   \n",
              "\n",
              "        state  ActivityEncoded  \n",
              "0           5                4  \n",
              "1           5                4  \n",
              "2           5                4  \n",
              "3           5                4  \n",
              "4           5                4  \n",
              "...       ...              ...  \n",
              "355084      5                4  \n",
              "355085      5                4  \n",
              "355086      5                4  \n",
              "355087      5                4  \n",
              "355088      5                4  \n",
              "\n",
              "[106478 rows x 12 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[df['state'] == 5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8MsUqZpNDBSW",
        "outputId": "3e4dff0e-96a1-446a-f8d4-e295330cdf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
            "x_train shape: (17750, 200)\n",
            "input_shape: 200\n",
            "New y_train shape:  (17750, 5)\n",
            "\n",
            "--- Create neural network model ---\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 100, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 91, 32)            672       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 91, 32)            128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 30, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 21, 64)            20544     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 21,669\n",
            "Trainable params: 21,605\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 100, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 91, 32)            672       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 91, 32)            128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 30, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 21, 64)            20544     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 21,669\n",
            "Trainable params: 21,605\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set input & output dimensions\n",
        "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
        "num_classes = le.classes_.size\n",
        "print(list(le.classes_))\n",
        "num_classes = 5\n",
        "# Set input_shape / reshape for Keras\n",
        "# Remark: acceleration data is concatenated in one array in order to feed\n",
        "# it properly into coreml later, the preferred matrix of shape [40,3]\n",
        "# cannot be read in with the current version of coreml (see also reshape\n",
        "# layer as the first layer in the keras model)\n",
        "input_shape = (num_time_periods*num_sensors)\n",
        "x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
        "\n",
        "\n",
        "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
        "\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "# x_train shape: (20869, 120)\n",
        "print('input_shape:', input_shape)\n",
        "# input_shape: (120)\n",
        "\n",
        "# Convert type for Keras otherwise Keras cannot process the data\n",
        "x_train = x_train.astype(\"float32\")\n",
        "y_train = y_train.astype(\"float32\")\n",
        "\n",
        "x_test1 = x_test1.astype(\"float32\")\n",
        "y_test1 = y_test1.astype(\"float32\")\n",
        "\n",
        "# %%\n",
        "\n",
        "# One-hot encoding of y_train labels (only execute once!)\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test1 = np_utils.to_categorical(y_test1, num_classes)\n",
        "\n",
        "print('New y_train shape: ', y_train.shape)\n",
        "# (4173, 6)\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Create neural network model ---\\n\")\n",
        "\n",
        "# 1D CNN neural network\n",
        "model_m = Sequential()\n",
        "model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
        "model_m.add(Conv1D(32, 10, activation='tanh', input_shape=(TIME_PERIODS, num_sensors)))\n",
        "model_m.add(BatchNormalization(axis = -1))\n",
        "model_m.add(MaxPooling1D(3))\n",
        "model_m.add(Conv1D(64, 10, activation='tanh'))\n",
        "model_m.add(GlobalAveragePooling1D())\n",
        "model_m.add(Dropout(0.5))\n",
        "model_m.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "print(model_m.summary())\n",
        "\n",
        "\n",
        "ad = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "\n",
        "model_m.compile(loss='binary_crossentropy',\n",
        "                optimizer=ad, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "print(model_m.summary())\n",
        "# Accuracy on training data: 99%\n",
        "# Accuracy on test data: 91%\n",
        "\n",
        "model3 = Model(model_m)\n",
        "model5=Model(inputs=model_m.input,outputs=model_m.output)\n",
        "\n",
        "model2 = Model(inputs=[model_m.input,\n",
        "                       model.input],\n",
        "               outputs=model_m.output)\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "                optimizer=ad, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPOjWBPrDBSX",
        "outputId": "879a4373-6828-4828-d70f-180969e50686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqpKUDWcDBSX"
      },
      "outputs": [],
      "source": [
        "_NUM_CLASSES = 2\n",
        "\n",
        "def tfdata_generator(images, labels, is_training, batch_size=128):\n",
        "    '''Construct a data generator using tf.Dataset'''\n",
        "\n",
        "    def preprocess_fn(image, label):\n",
        "        '''A transformation function to preprocess raw data\n",
        "        into trainable input. '''\n",
        "        x = tf.reshape(tf.cast(image, tf.float32), (64, 64, 3)) # last value was 1 not 3\n",
        "        y = tf.one_hot(tf.cast(label, tf.uint8), _NUM_CLASSES)\n",
        "        return x, y\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
        "\n",
        "    # Transform and batch data at the same time\n",
        "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
        "        preprocess_fn, batch_size,\n",
        "        num_parallel_batches=4,  # cpu cores\n",
        "        drop_remainder=True if is_training else False))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-QlP24jDBSX"
      },
      "source": [
        "# 10 fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ1-sjF4DBSX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test2, y_train, y_test2 = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "tr_img_data, tst_img_data2 = train_test_split(tr_img_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Biy5Ju8aDBSX",
        "outputId": "a2698757-e0c2-4c4b-8e27-89170848a09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold(n_splits=10, random_state=None, shuffle=True)\n",
            "Train Index:  [    1     2     3 ... 14196 14197 14199] \n",
            "\n",
            "Test Index:  [    0     7    19 ... 14191 14193 14198]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 3:22 - loss: 0.8111 - accuracy: 0.39 - ETA: 50s - loss: 0.7998 - accuracy: 0.3935 - ETA: 24s - loss: 0.7695 - accuracy: 0.439 - ETA: 17s - loss: 0.7510 - accuracy: 0.467 - ETA: 12s - loss: 0.7279 - accuracy: 0.501 - ETA: 9s - loss: 0.7116 - accuracy: 0.528 - ETA: 8s - loss: 0.6958 - accuracy: 0.55 - ETA: 6s - loss: 0.6791 - accuracy: 0.57 - ETA: 5s - loss: 0.6673 - accuracy: 0.59 - ETA: 4s - loss: 0.6546 - accuracy: 0.60 - ETA: 4s - loss: 0.6441 - accuracy: 0.61 - ETA: 3s - loss: 0.6334 - accuracy: 0.63 - ETA: 2s - loss: 0.6220 - accuracy: 0.64 - ETA: 2s - loss: 0.6129 - accuracy: 0.65 - ETA: 2s - loss: 0.6056 - accuracy: 0.65 - ETA: 1s - loss: 0.5968 - accuracy: 0.66 - ETA: 1s - loss: 0.5899 - accuracy: 0.67 - ETA: 1s - loss: 0.5824 - accuracy: 0.68 - ETA: 1s - loss: 0.5769 - accuracy: 0.68 - ETA: 0s - loss: 0.5702 - accuracy: 0.69 - ETA: 0s - loss: 0.5650 - accuracy: 0.69 - ETA: 0s - loss: 0.5594 - accuracy: 0.69 - ETA: 0s - loss: 0.5545 - accuracy: 0.70 - ETA: 0s - loss: 0.5504 - accuracy: 0.70 - ETA: 0s - loss: 0.5457 - accuracy: 0.71 - 4s 360us/step - loss: 0.5456 - accuracy: 0.7110 - val_loss: 0.5167 - val_accuracy: 0.7981\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4503 - accuracy: 0.79 - ETA: 1s - loss: 0.4489 - accuracy: 0.77 - ETA: 1s - loss: 0.4493 - accuracy: 0.78 - ETA: 1s - loss: 0.4500 - accuracy: 0.78 - ETA: 1s - loss: 0.4516 - accuracy: 0.77 - ETA: 1s - loss: 0.4516 - accuracy: 0.77 - ETA: 0s - loss: 0.4495 - accuracy: 0.78 - ETA: 0s - loss: 0.4502 - accuracy: 0.78 - ETA: 0s - loss: 0.4507 - accuracy: 0.78 - ETA: 0s - loss: 0.4492 - accuracy: 0.78 - ETA: 0s - loss: 0.4484 - accuracy: 0.78 - ETA: 0s - loss: 0.4477 - accuracy: 0.78 - ETA: 0s - loss: 0.4466 - accuracy: 0.78 - ETA: 0s - loss: 0.4449 - accuracy: 0.78 - ETA: 0s - loss: 0.4448 - accuracy: 0.78 - ETA: 0s - loss: 0.4446 - accuracy: 0.78 - ETA: 0s - loss: 0.4441 - accuracy: 0.78 - ETA: 0s - loss: 0.4436 - accuracy: 0.78 - ETA: 0s - loss: 0.4438 - accuracy: 0.78 - ETA: 0s - loss: 0.4431 - accuracy: 0.78 - ETA: 0s - loss: 0.4424 - accuracy: 0.78 - ETA: 0s - loss: 0.4420 - accuracy: 0.78 - ETA: 0s - loss: 0.4418 - accuracy: 0.78 - 1s 142us/step - loss: 0.4418 - accuracy: 0.7854 - val_loss: 0.4444 - val_accuracy: 0.8028\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4192 - accuracy: 0.79 - ETA: 1s - loss: 0.4308 - accuracy: 0.78 - ETA: 1s - loss: 0.4361 - accuracy: 0.78 - ETA: 1s - loss: 0.4358 - accuracy: 0.78 - ETA: 1s - loss: 0.4319 - accuracy: 0.78 - ETA: 1s - loss: 0.4325 - accuracy: 0.78 - ETA: 0s - loss: 0.4304 - accuracy: 0.78 - ETA: 0s - loss: 0.4311 - accuracy: 0.78 - ETA: 0s - loss: 0.4301 - accuracy: 0.78 - ETA: 0s - loss: 0.4303 - accuracy: 0.79 - ETA: 0s - loss: 0.4296 - accuracy: 0.79 - ETA: 0s - loss: 0.4299 - accuracy: 0.79 - ETA: 0s - loss: 0.4294 - accuracy: 0.79 - ETA: 0s - loss: 0.4296 - accuracy: 0.78 - ETA: 0s - loss: 0.4284 - accuracy: 0.79 - ETA: 0s - loss: 0.4290 - accuracy: 0.79 - ETA: 0s - loss: 0.4291 - accuracy: 0.79 - ETA: 0s - loss: 0.4296 - accuracy: 0.79 - ETA: 0s - loss: 0.4291 - accuracy: 0.79 - ETA: 0s - loss: 0.4288 - accuracy: 0.79 - ETA: 0s - loss: 0.4288 - accuracy: 0.79 - ETA: 0s - loss: 0.4283 - accuracy: 0.79 - ETA: 0s - loss: 0.4279 - accuracy: 0.79 - ETA: 0s - loss: 0.4277 - accuracy: 0.79 - 2s 148us/step - loss: 0.4280 - accuracy: 0.7914 - val_loss: 0.4111 - val_accuracy: 0.8053\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4024 - accuracy: 0.80 - ETA: 1s - loss: 0.4243 - accuracy: 0.78 - ETA: 1s - loss: 0.4267 - accuracy: 0.78 - ETA: 1s - loss: 0.4231 - accuracy: 0.78 - ETA: 1s - loss: 0.4232 - accuracy: 0.78 - ETA: 0s - loss: 0.4235 - accuracy: 0.78 - ETA: 0s - loss: 0.4238 - accuracy: 0.79 - ETA: 0s - loss: 0.4228 - accuracy: 0.79 - ETA: 0s - loss: 0.4223 - accuracy: 0.79 - ETA: 0s - loss: 0.4228 - accuracy: 0.79 - ETA: 0s - loss: 0.4222 - accuracy: 0.79 - ETA: 0s - loss: 0.4221 - accuracy: 0.79 - ETA: 0s - loss: 0.4216 - accuracy: 0.79 - ETA: 0s - loss: 0.4222 - accuracy: 0.79 - ETA: 0s - loss: 0.4224 - accuracy: 0.79 - ETA: 0s - loss: 0.4221 - accuracy: 0.79 - ETA: 0s - loss: 0.4215 - accuracy: 0.79 - ETA: 0s - loss: 0.4214 - accuracy: 0.79 - ETA: 0s - loss: 0.4213 - accuracy: 0.79 - ETA: 0s - loss: 0.4203 - accuracy: 0.79 - ETA: 0s - loss: 0.4207 - accuracy: 0.79 - ETA: 0s - loss: 0.4205 - accuracy: 0.79 - 1s 135us/step - loss: 0.4206 - accuracy: 0.7924 - val_loss: 0.3952 - val_accuracy: 0.8061\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3892 - accuracy: 0.82 - ETA: 1s - loss: 0.4103 - accuracy: 0.80 - ETA: 1s - loss: 0.4124 - accuracy: 0.80 - ETA: 1s - loss: 0.4166 - accuracy: 0.79 - ETA: 1s - loss: 0.4167 - accuracy: 0.79 - ETA: 0s - loss: 0.4185 - accuracy: 0.79 - ETA: 0s - loss: 0.4169 - accuracy: 0.79 - ETA: 0s - loss: 0.4174 - accuracy: 0.79 - ETA: 0s - loss: 0.4161 - accuracy: 0.79 - ETA: 0s - loss: 0.4156 - accuracy: 0.79 - ETA: 0s - loss: 0.4159 - accuracy: 0.79 - ETA: 0s - loss: 0.4156 - accuracy: 0.79 - ETA: 0s - loss: 0.4157 - accuracy: 0.79 - ETA: 0s - loss: 0.4154 - accuracy: 0.79 - ETA: 0s - loss: 0.4147 - accuracy: 0.79 - ETA: 0s - loss: 0.4146 - accuracy: 0.79 - ETA: 0s - loss: 0.4145 - accuracy: 0.79 - ETA: 0s - loss: 0.4138 - accuracy: 0.79 - ETA: 0s - loss: 0.4139 - accuracy: 0.79 - ETA: 0s - loss: 0.4136 - accuracy: 0.79 - ETA: 0s - loss: 0.4135 - accuracy: 0.79 - ETA: 0s - loss: 0.4133 - accuracy: 0.79 - 1s 142us/step - loss: 0.4127 - accuracy: 0.7953 - val_loss: 0.3856 - val_accuracy: 0.8099\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4003 - accuracy: 0.81 - ETA: 1s - loss: 0.4075 - accuracy: 0.79 - ETA: 1s - loss: 0.4055 - accuracy: 0.80 - ETA: 1s - loss: 0.4095 - accuracy: 0.79 - ETA: 0s - loss: 0.4077 - accuracy: 0.79 - ETA: 0s - loss: 0.4089 - accuracy: 0.79 - ETA: 0s - loss: 0.4096 - accuracy: 0.79 - ETA: 0s - loss: 0.4099 - accuracy: 0.79 - ETA: 0s - loss: 0.4104 - accuracy: 0.79 - ETA: 0s - loss: 0.4099 - accuracy: 0.79 - ETA: 0s - loss: 0.4092 - accuracy: 0.79 - ETA: 0s - loss: 0.4092 - accuracy: 0.79 - ETA: 0s - loss: 0.4088 - accuracy: 0.79 - ETA: 0s - loss: 0.4090 - accuracy: 0.79 - ETA: 0s - loss: 0.4088 - accuracy: 0.79 - ETA: 0s - loss: 0.4086 - accuracy: 0.79 - ETA: 0s - loss: 0.4091 - accuracy: 0.79 - ETA: 0s - loss: 0.4087 - accuracy: 0.79 - ETA: 0s - loss: 0.4084 - accuracy: 0.79 - ETA: 0s - loss: 0.4077 - accuracy: 0.79 - ETA: 0s - loss: 0.4074 - accuracy: 0.79 - ETA: 0s - loss: 0.4072 - accuracy: 0.79 - ETA: 0s - loss: 0.4072 - accuracy: 0.79 - 1s 143us/step - loss: 0.4071 - accuracy: 0.7955 - val_loss: 0.3791 - val_accuracy: 0.8128\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3867 - accuracy: 0.82 - ETA: 1s - loss: 0.4008 - accuracy: 0.79 - ETA: 1s - loss: 0.3946 - accuracy: 0.80 - ETA: 1s - loss: 0.3926 - accuracy: 0.80 - ETA: 0s - loss: 0.3927 - accuracy: 0.80 - ETA: 0s - loss: 0.3964 - accuracy: 0.80 - ETA: 0s - loss: 0.3979 - accuracy: 0.80 - ETA: 0s - loss: 0.3968 - accuracy: 0.80 - ETA: 0s - loss: 0.3990 - accuracy: 0.79 - ETA: 0s - loss: 0.4002 - accuracy: 0.79 - ETA: 0s - loss: 0.4000 - accuracy: 0.79 - ETA: 0s - loss: 0.4006 - accuracy: 0.79 - ETA: 0s - loss: 0.4000 - accuracy: 0.79 - ETA: 0s - loss: 0.4006 - accuracy: 0.79 - ETA: 0s - loss: 0.4009 - accuracy: 0.79 - ETA: 0s - loss: 0.4003 - accuracy: 0.79 - ETA: 0s - loss: 0.4006 - accuracy: 0.79 - ETA: 0s - loss: 0.4006 - accuracy: 0.79 - ETA: 0s - loss: 0.4005 - accuracy: 0.79 - ETA: 0s - loss: 0.4006 - accuracy: 0.79 - ETA: 0s - loss: 0.4003 - accuracy: 0.79 - ETA: 0s - loss: 0.4000 - accuracy: 0.79 - 1s 141us/step - loss: 0.3999 - accuracy: 0.7985 - val_loss: 0.3741 - val_accuracy: 0.8128\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4199 - accuracy: 0.77 - ETA: 1s - loss: 0.3981 - accuracy: 0.79 - ETA: 1s - loss: 0.4009 - accuracy: 0.80 - ETA: 1s - loss: 0.4021 - accuracy: 0.79 - ETA: 0s - loss: 0.3998 - accuracy: 0.79 - ETA: 0s - loss: 0.3973 - accuracy: 0.79 - ETA: 0s - loss: 0.3957 - accuracy: 0.80 - ETA: 0s - loss: 0.3961 - accuracy: 0.80 - ETA: 0s - loss: 0.3955 - accuracy: 0.80 - ETA: 0s - loss: 0.3955 - accuracy: 0.80 - ETA: 0s - loss: 0.3951 - accuracy: 0.80 - ETA: 0s - loss: 0.3955 - accuracy: 0.80 - ETA: 0s - loss: 0.3959 - accuracy: 0.80 - ETA: 0s - loss: 0.3959 - accuracy: 0.80 - ETA: 0s - loss: 0.3955 - accuracy: 0.80 - ETA: 0s - loss: 0.3966 - accuracy: 0.80 - ETA: 0s - loss: 0.3965 - accuracy: 0.80 - ETA: 0s - loss: 0.3966 - accuracy: 0.80 - ETA: 0s - loss: 0.3961 - accuracy: 0.80 - ETA: 0s - loss: 0.3959 - accuracy: 0.80 - ETA: 0s - loss: 0.3959 - accuracy: 0.80 - ETA: 0s - loss: 0.3957 - accuracy: 0.80 - ETA: 0s - loss: 0.3957 - accuracy: 0.80 - 1s 143us/step - loss: 0.3955 - accuracy: 0.8013 - val_loss: 0.3689 - val_accuracy: 0.8137\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3796 - accuracy: 0.82 - ETA: 1s - loss: 0.3839 - accuracy: 0.80 - ETA: 1s - loss: 0.3929 - accuracy: 0.80 - ETA: 1s - loss: 0.3921 - accuracy: 0.80 - ETA: 1s - loss: 0.3929 - accuracy: 0.80 - ETA: 1s - loss: 0.3901 - accuracy: 0.80 - ETA: 1s - loss: 0.3912 - accuracy: 0.80 - ETA: 0s - loss: 0.3900 - accuracy: 0.80 - ETA: 0s - loss: 0.3900 - accuracy: 0.80 - ETA: 0s - loss: 0.3906 - accuracy: 0.80 - ETA: 0s - loss: 0.3904 - accuracy: 0.80 - ETA: 0s - loss: 0.3906 - accuracy: 0.80 - ETA: 0s - loss: 0.3903 - accuracy: 0.80 - ETA: 0s - loss: 0.3904 - accuracy: 0.80 - ETA: 0s - loss: 0.3910 - accuracy: 0.80 - ETA: 0s - loss: 0.3911 - accuracy: 0.80 - ETA: 0s - loss: 0.3910 - accuracy: 0.80 - ETA: 0s - loss: 0.3902 - accuracy: 0.80 - ETA: 0s - loss: 0.3898 - accuracy: 0.80 - ETA: 0s - loss: 0.3893 - accuracy: 0.80 - ETA: 0s - loss: 0.3886 - accuracy: 0.80 - ETA: 0s - loss: 0.3891 - accuracy: 0.80 - ETA: 0s - loss: 0.3892 - accuracy: 0.80 - ETA: 0s - loss: 0.3897 - accuracy: 0.80 - 1s 145us/step - loss: 0.3896 - accuracy: 0.8044 - val_loss: 0.3635 - val_accuracy: 0.8141\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3841 - accuracy: 0.80 - ETA: 1s - loss: 0.3875 - accuracy: 0.79 - ETA: 1s - loss: 0.3857 - accuracy: 0.80 - ETA: 1s - loss: 0.3871 - accuracy: 0.80 - ETA: 0s - loss: 0.3847 - accuracy: 0.80 - ETA: 0s - loss: 0.3840 - accuracy: 0.80 - ETA: 0s - loss: 0.3849 - accuracy: 0.80 - ETA: 0s - loss: 0.3857 - accuracy: 0.80 - ETA: 0s - loss: 0.3853 - accuracy: 0.80 - ETA: 0s - loss: 0.3865 - accuracy: 0.80 - ETA: 0s - loss: 0.3863 - accuracy: 0.80 - ETA: 0s - loss: 0.3854 - accuracy: 0.80 - ETA: 0s - loss: 0.3846 - accuracy: 0.80 - ETA: 0s - loss: 0.3846 - accuracy: 0.80 - ETA: 0s - loss: 0.3849 - accuracy: 0.80 - ETA: 0s - loss: 0.3843 - accuracy: 0.80 - ETA: 0s - loss: 0.3842 - accuracy: 0.80 - ETA: 0s - loss: 0.3848 - accuracy: 0.80 - ETA: 0s - loss: 0.3847 - accuracy: 0.80 - ETA: 0s - loss: 0.3852 - accuracy: 0.80 - ETA: 0s - loss: 0.3858 - accuracy: 0.80 - ETA: 0s - loss: 0.3856 - accuracy: 0.80 - ETA: 0s - loss: 0.3855 - accuracy: 0.80 - 1s 140us/step - loss: 0.3854 - accuracy: 0.8052 - val_loss: 0.3589 - val_accuracy: 0.8177\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.4116 - accuracy: 0.79 - ETA: 1s - loss: 0.3883 - accuracy: 0.80 - ETA: 1s - loss: 0.3875 - accuracy: 0.80 - ETA: 1s - loss: 0.3861 - accuracy: 0.80 - ETA: 0s - loss: 0.3854 - accuracy: 0.80 - ETA: 0s - loss: 0.3832 - accuracy: 0.80 - ETA: 0s - loss: 0.3833 - accuracy: 0.80 - ETA: 0s - loss: 0.3827 - accuracy: 0.80 - ETA: 0s - loss: 0.3824 - accuracy: 0.80 - ETA: 0s - loss: 0.3818 - accuracy: 0.80 - ETA: 0s - loss: 0.3810 - accuracy: 0.80 - ETA: 0s - loss: 0.3820 - accuracy: 0.80 - ETA: 0s - loss: 0.3814 - accuracy: 0.80 - ETA: 0s - loss: 0.3809 - accuracy: 0.80 - ETA: 0s - loss: 0.3804 - accuracy: 0.80 - ETA: 0s - loss: 0.3810 - accuracy: 0.80 - ETA: 0s - loss: 0.3807 - accuracy: 0.80 - ETA: 0s - loss: 0.3804 - accuracy: 0.80 - ETA: 0s - loss: 0.3802 - accuracy: 0.80 - ETA: 0s - loss: 0.3803 - accuracy: 0.80 - ETA: 0s - loss: 0.3806 - accuracy: 0.80 - ETA: 0s - loss: 0.3806 - accuracy: 0.80 - 1s 138us/step - loss: 0.3806 - accuracy: 0.8071 - val_loss: 0.3551 - val_accuracy: 0.8174\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3914 - accuracy: 0.80 - ETA: 1s - loss: 0.3808 - accuracy: 0.81 - ETA: 1s - loss: 0.3763 - accuracy: 0.81 - ETA: 1s - loss: 0.3771 - accuracy: 0.81 - ETA: 1s - loss: 0.3751 - accuracy: 0.81 - ETA: 0s - loss: 0.3742 - accuracy: 0.81 - ETA: 0s - loss: 0.3756 - accuracy: 0.81 - ETA: 0s - loss: 0.3761 - accuracy: 0.81 - ETA: 0s - loss: 0.3773 - accuracy: 0.81 - ETA: 0s - loss: 0.3768 - accuracy: 0.80 - ETA: 0s - loss: 0.3770 - accuracy: 0.80 - ETA: 0s - loss: 0.3773 - accuracy: 0.80 - ETA: 0s - loss: 0.3770 - accuracy: 0.80 - ETA: 0s - loss: 0.3767 - accuracy: 0.80 - ETA: 0s - loss: 0.3767 - accuracy: 0.80 - ETA: 0s - loss: 0.3764 - accuracy: 0.80 - ETA: 0s - loss: 0.3770 - accuracy: 0.80 - ETA: 0s - loss: 0.3767 - accuracy: 0.80 - ETA: 0s - loss: 0.3761 - accuracy: 0.80 - ETA: 0s - loss: 0.3764 - accuracy: 0.80 - ETA: 0s - loss: 0.3765 - accuracy: 0.80 - ETA: 0s - loss: 0.3762 - accuracy: 0.80 - ETA: 0s - loss: 0.3760 - accuracy: 0.80 - 1s 141us/step - loss: 0.3760 - accuracy: 0.8098 - val_loss: 0.3505 - val_accuracy: 0.8185\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3798 - accuracy: 0.79 - ETA: 1s - loss: 0.3797 - accuracy: 0.81 - ETA: 1s - loss: 0.3714 - accuracy: 0.81 - ETA: 1s - loss: 0.3732 - accuracy: 0.81 - ETA: 1s - loss: 0.3755 - accuracy: 0.81 - ETA: 1s - loss: 0.3761 - accuracy: 0.81 - ETA: 0s - loss: 0.3758 - accuracy: 0.81 - ETA: 0s - loss: 0.3748 - accuracy: 0.81 - ETA: 0s - loss: 0.3740 - accuracy: 0.81 - ETA: 0s - loss: 0.3738 - accuracy: 0.81 - ETA: 0s - loss: 0.3746 - accuracy: 0.81 - ETA: 0s - loss: 0.3745 - accuracy: 0.81 - ETA: 0s - loss: 0.3746 - accuracy: 0.81 - ETA: 0s - loss: 0.3741 - accuracy: 0.81 - ETA: 0s - loss: 0.3730 - accuracy: 0.81 - ETA: 0s - loss: 0.3727 - accuracy: 0.81 - ETA: 0s - loss: 0.3722 - accuracy: 0.81 - ETA: 0s - loss: 0.3720 - accuracy: 0.81 - ETA: 0s - loss: 0.3720 - accuracy: 0.81 - ETA: 0s - loss: 0.3722 - accuracy: 0.81 - ETA: 0s - loss: 0.3721 - accuracy: 0.81 - ETA: 0s - loss: 0.3723 - accuracy: 0.81 - ETA: 0s - loss: 0.3723 - accuracy: 0.81 - 1s 143us/step - loss: 0.3725 - accuracy: 0.8136 - val_loss: 0.3462 - val_accuracy: 0.8200\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3504 - accuracy: 0.83 - ETA: 1s - loss: 0.3629 - accuracy: 0.81 - ETA: 1s - loss: 0.3680 - accuracy: 0.81 - ETA: 0s - loss: 0.3669 - accuracy: 0.81 - ETA: 0s - loss: 0.3677 - accuracy: 0.81 - ETA: 0s - loss: 0.3694 - accuracy: 0.81 - ETA: 0s - loss: 0.3688 - accuracy: 0.81 - ETA: 0s - loss: 0.3687 - accuracy: 0.81 - ETA: 0s - loss: 0.3677 - accuracy: 0.81 - ETA: 0s - loss: 0.3672 - accuracy: 0.81 - ETA: 0s - loss: 0.3676 - accuracy: 0.81 - ETA: 0s - loss: 0.3679 - accuracy: 0.81 - ETA: 0s - loss: 0.3686 - accuracy: 0.81 - ETA: 0s - loss: 0.3682 - accuracy: 0.81 - ETA: 0s - loss: 0.3679 - accuracy: 0.81 - ETA: 0s - loss: 0.3684 - accuracy: 0.81 - ETA: 0s - loss: 0.3681 - accuracy: 0.81 - ETA: 0s - loss: 0.3684 - accuracy: 0.81 - ETA: 0s - loss: 0.3682 - accuracy: 0.81 - ETA: 0s - loss: 0.3682 - accuracy: 0.81 - ETA: 0s - loss: 0.3681 - accuracy: 0.81 - ETA: 0s - loss: 0.3680 - accuracy: 0.81 - 1s 142us/step - loss: 0.3678 - accuracy: 0.8147 - val_loss: 0.3425 - val_accuracy: 0.8233\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3747 - accuracy: 0.81 - ETA: 1s - loss: 0.3624 - accuracy: 0.82 - ETA: 1s - loss: 0.3592 - accuracy: 0.82 - ETA: 1s - loss: 0.3626 - accuracy: 0.82 - ETA: 1s - loss: 0.3608 - accuracy: 0.82 - ETA: 0s - loss: 0.3619 - accuracy: 0.81 - ETA: 0s - loss: 0.3619 - accuracy: 0.81 - ETA: 0s - loss: 0.3617 - accuracy: 0.81 - ETA: 0s - loss: 0.3622 - accuracy: 0.81 - ETA: 0s - loss: 0.3624 - accuracy: 0.81 - ETA: 0s - loss: 0.3625 - accuracy: 0.81 - ETA: 0s - loss: 0.3632 - accuracy: 0.81 - ETA: 0s - loss: 0.3633 - accuracy: 0.81 - ETA: 0s - loss: 0.3641 - accuracy: 0.81 - ETA: 0s - loss: 0.3646 - accuracy: 0.81 - ETA: 0s - loss: 0.3646 - accuracy: 0.81 - ETA: 0s - loss: 0.3642 - accuracy: 0.81 - ETA: 0s - loss: 0.3638 - accuracy: 0.81 - ETA: 0s - loss: 0.3638 - accuracy: 0.81 - ETA: 0s - loss: 0.3638 - accuracy: 0.81 - ETA: 0s - loss: 0.3641 - accuracy: 0.81 - ETA: 0s - loss: 0.3641 - accuracy: 0.81 - ETA: 0s - loss: 0.3643 - accuracy: 0.81 - 1s 141us/step - loss: 0.3640 - accuracy: 0.8169 - val_loss: 0.3378 - val_accuracy: 0.8254\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3566 - accuracy: 0.82 - ETA: 1s - loss: 0.3533 - accuracy: 0.82 - ETA: 1s - loss: 0.3550 - accuracy: 0.82 - ETA: 1s - loss: 0.3601 - accuracy: 0.81 - ETA: 0s - loss: 0.3602 - accuracy: 0.81 - ETA: 0s - loss: 0.3603 - accuracy: 0.81 - ETA: 0s - loss: 0.3591 - accuracy: 0.81 - ETA: 0s - loss: 0.3587 - accuracy: 0.81 - ETA: 0s - loss: 0.3592 - accuracy: 0.81 - ETA: 0s - loss: 0.3597 - accuracy: 0.81 - ETA: 0s - loss: 0.3596 - accuracy: 0.81 - ETA: 0s - loss: 0.3589 - accuracy: 0.81 - ETA: 0s - loss: 0.3592 - accuracy: 0.81 - ETA: 0s - loss: 0.3606 - accuracy: 0.81 - ETA: 0s - loss: 0.3594 - accuracy: 0.81 - ETA: 0s - loss: 0.3593 - accuracy: 0.81 - ETA: 0s - loss: 0.3592 - accuracy: 0.81 - ETA: 0s - loss: 0.3584 - accuracy: 0.81 - ETA: 0s - loss: 0.3587 - accuracy: 0.81 - ETA: 0s - loss: 0.3584 - accuracy: 0.81 - ETA: 0s - loss: 0.3592 - accuracy: 0.81 - ETA: 0s - loss: 0.3593 - accuracy: 0.81 - ETA: 0s - loss: 0.3587 - accuracy: 0.81 - 1s 140us/step - loss: 0.3586 - accuracy: 0.8197 - val_loss: 0.3341 - val_accuracy: 0.8314\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3632 - accuracy: 0.79 - ETA: 1s - loss: 0.3571 - accuracy: 0.81 - ETA: 1s - loss: 0.3593 - accuracy: 0.81 - ETA: 1s - loss: 0.3575 - accuracy: 0.81 - ETA: 1s - loss: 0.3598 - accuracy: 0.81 - ETA: 0s - loss: 0.3589 - accuracy: 0.81 - ETA: 0s - loss: 0.3603 - accuracy: 0.81 - ETA: 0s - loss: 0.3588 - accuracy: 0.81 - ETA: 0s - loss: 0.3581 - accuracy: 0.81 - ETA: 0s - loss: 0.3581 - accuracy: 0.81 - ETA: 0s - loss: 0.3568 - accuracy: 0.81 - ETA: 0s - loss: 0.3570 - accuracy: 0.81 - ETA: 0s - loss: 0.3571 - accuracy: 0.82 - ETA: 0s - loss: 0.3563 - accuracy: 0.82 - ETA: 0s - loss: 0.3560 - accuracy: 0.82 - ETA: 0s - loss: 0.3558 - accuracy: 0.82 - ETA: 0s - loss: 0.3555 - accuracy: 0.82 - ETA: 0s - loss: 0.3551 - accuracy: 0.82 - ETA: 0s - loss: 0.3552 - accuracy: 0.82 - ETA: 0s - loss: 0.3551 - accuracy: 0.82 - ETA: 0s - loss: 0.3553 - accuracy: 0.82 - ETA: 0s - loss: 0.3550 - accuracy: 0.82 - ETA: 0s - loss: 0.3545 - accuracy: 0.82 - 1s 141us/step - loss: 0.3546 - accuracy: 0.8226 - val_loss: 0.3291 - val_accuracy: 0.8344\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3606 - accuracy: 0.82 - ETA: 1s - loss: 0.3478 - accuracy: 0.82 - ETA: 1s - loss: 0.3479 - accuracy: 0.82 - ETA: 0s - loss: 0.3453 - accuracy: 0.82 - ETA: 0s - loss: 0.3463 - accuracy: 0.82 - ETA: 0s - loss: 0.3431 - accuracy: 0.83 - ETA: 0s - loss: 0.3464 - accuracy: 0.82 - ETA: 0s - loss: 0.3493 - accuracy: 0.82 - ETA: 0s - loss: 0.3494 - accuracy: 0.82 - ETA: 0s - loss: 0.3488 - accuracy: 0.82 - ETA: 0s - loss: 0.3487 - accuracy: 0.82 - ETA: 0s - loss: 0.3492 - accuracy: 0.82 - ETA: 0s - loss: 0.3502 - accuracy: 0.82 - ETA: 0s - loss: 0.3509 - accuracy: 0.82 - ETA: 0s - loss: 0.3513 - accuracy: 0.82 - ETA: 0s - loss: 0.3514 - accuracy: 0.82 - ETA: 0s - loss: 0.3510 - accuracy: 0.82 - ETA: 0s - loss: 0.3511 - accuracy: 0.82 - ETA: 0s - loss: 0.3509 - accuracy: 0.82 - ETA: 0s - loss: 0.3506 - accuracy: 0.82 - ETA: 0s - loss: 0.3507 - accuracy: 0.82 - ETA: 0s - loss: 0.3503 - accuracy: 0.82 - 1s 137us/step - loss: 0.3505 - accuracy: 0.8244 - val_loss: 0.3245 - val_accuracy: 0.8409\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3385 - accuracy: 0.82 - ETA: 1s - loss: 0.3541 - accuracy: 0.81 - ETA: 1s - loss: 0.3487 - accuracy: 0.82 - ETA: 1s - loss: 0.3488 - accuracy: 0.82 - ETA: 1s - loss: 0.3519 - accuracy: 0.82 - ETA: 0s - loss: 0.3518 - accuracy: 0.82 - ETA: 0s - loss: 0.3489 - accuracy: 0.82 - ETA: 0s - loss: 0.3476 - accuracy: 0.82 - ETA: 0s - loss: 0.3472 - accuracy: 0.82 - ETA: 0s - loss: 0.3475 - accuracy: 0.82 - ETA: 0s - loss: 0.3476 - accuracy: 0.82 - ETA: 0s - loss: 0.3477 - accuracy: 0.82 - ETA: 0s - loss: 0.3473 - accuracy: 0.82 - ETA: 0s - loss: 0.3475 - accuracy: 0.82 - ETA: 0s - loss: 0.3481 - accuracy: 0.82 - ETA: 0s - loss: 0.3480 - accuracy: 0.82 - ETA: 0s - loss: 0.3484 - accuracy: 0.82 - ETA: 0s - loss: 0.3482 - accuracy: 0.82 - ETA: 0s - loss: 0.3480 - accuracy: 0.82 - ETA: 0s - loss: 0.3480 - accuracy: 0.82 - ETA: 0s - loss: 0.3477 - accuracy: 0.82 - ETA: 0s - loss: 0.3471 - accuracy: 0.82 - 1s 138us/step - loss: 0.3472 - accuracy: 0.8271 - val_loss: 0.3227 - val_accuracy: 0.8459\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3455 - accuracy: 0.83 - ETA: 1s - loss: 0.3432 - accuracy: 0.83 - ETA: 1s - loss: 0.3451 - accuracy: 0.83 - ETA: 1s - loss: 0.3421 - accuracy: 0.83 - ETA: 0s - loss: 0.3468 - accuracy: 0.83 - ETA: 0s - loss: 0.3466 - accuracy: 0.83 - ETA: 0s - loss: 0.3457 - accuracy: 0.83 - ETA: 0s - loss: 0.3441 - accuracy: 0.83 - ETA: 0s - loss: 0.3436 - accuracy: 0.83 - ETA: 0s - loss: 0.3430 - accuracy: 0.83 - ETA: 0s - loss: 0.3442 - accuracy: 0.82 - ETA: 0s - loss: 0.3431 - accuracy: 0.82 - ETA: 0s - loss: 0.3423 - accuracy: 0.83 - ETA: 0s - loss: 0.3421 - accuracy: 0.83 - ETA: 0s - loss: 0.3427 - accuracy: 0.83 - ETA: 0s - loss: 0.3428 - accuracy: 0.83 - ETA: 0s - loss: 0.3421 - accuracy: 0.83 - ETA: 0s - loss: 0.3430 - accuracy: 0.83 - ETA: 0s - loss: 0.3424 - accuracy: 0.83 - ETA: 0s - loss: 0.3422 - accuracy: 0.83 - ETA: 0s - loss: 0.3423 - accuracy: 0.83 - ETA: 0s - loss: 0.3424 - accuracy: 0.83 - 1s 137us/step - loss: 0.3424 - accuracy: 0.8314 - val_loss: 0.3159 - val_accuracy: 0.8497\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3630 - accuracy: 0.81 - ETA: 1s - loss: 0.3391 - accuracy: 0.83 - ETA: 1s - loss: 0.3420 - accuracy: 0.83 - ETA: 1s - loss: 0.3405 - accuracy: 0.83 - ETA: 0s - loss: 0.3397 - accuracy: 0.83 - ETA: 0s - loss: 0.3402 - accuracy: 0.83 - ETA: 0s - loss: 0.3405 - accuracy: 0.83 - ETA: 0s - loss: 0.3404 - accuracy: 0.83 - ETA: 0s - loss: 0.3397 - accuracy: 0.83 - ETA: 0s - loss: 0.3399 - accuracy: 0.83 - ETA: 0s - loss: 0.3408 - accuracy: 0.83 - ETA: 0s - loss: 0.3413 - accuracy: 0.83 - ETA: 0s - loss: 0.3415 - accuracy: 0.83 - ETA: 0s - loss: 0.3405 - accuracy: 0.83 - ETA: 0s - loss: 0.3405 - accuracy: 0.83 - ETA: 0s - loss: 0.3400 - accuracy: 0.83 - ETA: 0s - loss: 0.3397 - accuracy: 0.83 - ETA: 0s - loss: 0.3391 - accuracy: 0.83 - ETA: 0s - loss: 0.3387 - accuracy: 0.83 - ETA: 0s - loss: 0.3386 - accuracy: 0.83 - ETA: 0s - loss: 0.3394 - accuracy: 0.83 - ETA: 0s - loss: 0.3389 - accuracy: 0.83 - ETA: 0s - loss: 0.3388 - accuracy: 0.83 - 1s 140us/step - loss: 0.3388 - accuracy: 0.8339 - val_loss: 0.3120 - val_accuracy: 0.8513\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3461 - accuracy: 0.82 - ETA: 1s - loss: 0.3470 - accuracy: 0.82 - ETA: 1s - loss: 0.3380 - accuracy: 0.83 - ETA: 1s - loss: 0.3361 - accuracy: 0.83 - ETA: 1s - loss: 0.3361 - accuracy: 0.83 - ETA: 1s - loss: 0.3359 - accuracy: 0.83 - ETA: 0s - loss: 0.3361 - accuracy: 0.83 - ETA: 0s - loss: 0.3356 - accuracy: 0.83 - ETA: 0s - loss: 0.3354 - accuracy: 0.83 - ETA: 0s - loss: 0.3336 - accuracy: 0.83 - ETA: 0s - loss: 0.3339 - accuracy: 0.83 - ETA: 0s - loss: 0.3344 - accuracy: 0.83 - ETA: 0s - loss: 0.3341 - accuracy: 0.83 - ETA: 0s - loss: 0.3352 - accuracy: 0.83 - ETA: 0s - loss: 0.3346 - accuracy: 0.83 - ETA: 0s - loss: 0.3351 - accuracy: 0.83 - ETA: 0s - loss: 0.3352 - accuracy: 0.83 - ETA: 0s - loss: 0.3353 - accuracy: 0.83 - ETA: 0s - loss: 0.3348 - accuracy: 0.83 - ETA: 0s - loss: 0.3349 - accuracy: 0.83 - ETA: 0s - loss: 0.3347 - accuracy: 0.83 - ETA: 0s - loss: 0.3343 - accuracy: 0.83 - 1s 141us/step - loss: 0.3345 - accuracy: 0.8353 - val_loss: 0.3084 - val_accuracy: 0.8598\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3287 - accuracy: 0.84 - ETA: 1s - loss: 0.3381 - accuracy: 0.83 - ETA: 1s - loss: 0.3372 - accuracy: 0.83 - ETA: 1s - loss: 0.3337 - accuracy: 0.83 - ETA: 0s - loss: 0.3317 - accuracy: 0.84 - ETA: 0s - loss: 0.3304 - accuracy: 0.84 - ETA: 0s - loss: 0.3309 - accuracy: 0.84 - ETA: 0s - loss: 0.3300 - accuracy: 0.84 - ETA: 0s - loss: 0.3298 - accuracy: 0.84 - ETA: 0s - loss: 0.3307 - accuracy: 0.84 - ETA: 0s - loss: 0.3310 - accuracy: 0.83 - ETA: 0s - loss: 0.3313 - accuracy: 0.83 - ETA: 0s - loss: 0.3308 - accuracy: 0.83 - ETA: 0s - loss: 0.3306 - accuracy: 0.83 - ETA: 0s - loss: 0.3300 - accuracy: 0.83 - ETA: 0s - loss: 0.3295 - accuracy: 0.84 - ETA: 0s - loss: 0.3295 - accuracy: 0.84 - ETA: 0s - loss: 0.3296 - accuracy: 0.84 - ETA: 0s - loss: 0.3294 - accuracy: 0.84 - ETA: 0s - loss: 0.3297 - accuracy: 0.84 - ETA: 0s - loss: 0.3299 - accuracy: 0.84 - ETA: 0s - loss: 0.3301 - accuracy: 0.83 - 1s 139us/step - loss: 0.3300 - accuracy: 0.8398 - val_loss: 0.3029 - val_accuracy: 0.8600\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3202 - accuracy: 0.84 - ETA: 1s - loss: 0.3307 - accuracy: 0.83 - ETA: 1s - loss: 0.3294 - accuracy: 0.83 - ETA: 1s - loss: 0.3278 - accuracy: 0.84 - ETA: 0s - loss: 0.3288 - accuracy: 0.83 - ETA: 0s - loss: 0.3274 - accuracy: 0.84 - ETA: 0s - loss: 0.3269 - accuracy: 0.84 - ETA: 0s - loss: 0.3264 - accuracy: 0.84 - ETA: 0s - loss: 0.3263 - accuracy: 0.84 - ETA: 0s - loss: 0.3265 - accuracy: 0.84 - ETA: 0s - loss: 0.3257 - accuracy: 0.84 - ETA: 0s - loss: 0.3251 - accuracy: 0.84 - ETA: 0s - loss: 0.3254 - accuracy: 0.84 - ETA: 0s - loss: 0.3256 - accuracy: 0.84 - ETA: 0s - loss: 0.3259 - accuracy: 0.84 - ETA: 0s - loss: 0.3254 - accuracy: 0.84 - ETA: 0s - loss: 0.3254 - accuracy: 0.84 - ETA: 0s - loss: 0.3251 - accuracy: 0.84 - ETA: 0s - loss: 0.3256 - accuracy: 0.84 - ETA: 0s - loss: 0.3261 - accuracy: 0.84 - ETA: 0s - loss: 0.3258 - accuracy: 0.84 - ETA: 0s - loss: 0.3256 - accuracy: 0.84 - ETA: 0s - loss: 0.3256 - accuracy: 0.84 - 1s 145us/step - loss: 0.3253 - accuracy: 0.8420 - val_loss: 0.2992 - val_accuracy: 0.8671\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3280 - accuracy: 0.84 - ETA: 1s - loss: 0.3306 - accuracy: 0.84 - ETA: 1s - loss: 0.3277 - accuracy: 0.84 - ETA: 1s - loss: 0.3252 - accuracy: 0.84 - ETA: 0s - loss: 0.3241 - accuracy: 0.84 - ETA: 0s - loss: 0.3222 - accuracy: 0.84 - ETA: 0s - loss: 0.3220 - accuracy: 0.85 - ETA: 0s - loss: 0.3217 - accuracy: 0.84 - ETA: 0s - loss: 0.3211 - accuracy: 0.84 - ETA: 0s - loss: 0.3221 - accuracy: 0.84 - ETA: 0s - loss: 0.3211 - accuracy: 0.84 - ETA: 0s - loss: 0.3206 - accuracy: 0.84 - ETA: 0s - loss: 0.3217 - accuracy: 0.84 - ETA: 0s - loss: 0.3221 - accuracy: 0.84 - ETA: 0s - loss: 0.3220 - accuracy: 0.84 - ETA: 0s - loss: 0.3218 - accuracy: 0.84 - ETA: 0s - loss: 0.3222 - accuracy: 0.84 - ETA: 0s - loss: 0.3219 - accuracy: 0.84 - ETA: 0s - loss: 0.3217 - accuracy: 0.84 - ETA: 0s - loss: 0.3213 - accuracy: 0.84 - ETA: 0s - loss: 0.3212 - accuracy: 0.84 - ETA: 0s - loss: 0.3214 - accuracy: 0.84 - 1s 141us/step - loss: 0.3214 - accuracy: 0.8449 - val_loss: 0.2949 - val_accuracy: 0.8653\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3352 - accuracy: 0.83 - ETA: 1s - loss: 0.3192 - accuracy: 0.84 - ETA: 1s - loss: 0.3174 - accuracy: 0.84 - ETA: 1s - loss: 0.3207 - accuracy: 0.84 - ETA: 1s - loss: 0.3195 - accuracy: 0.84 - ETA: 1s - loss: 0.3186 - accuracy: 0.84 - ETA: 1s - loss: 0.3189 - accuracy: 0.84 - ETA: 0s - loss: 0.3188 - accuracy: 0.84 - ETA: 0s - loss: 0.3196 - accuracy: 0.84 - ETA: 0s - loss: 0.3197 - accuracy: 0.84 - ETA: 0s - loss: 0.3192 - accuracy: 0.84 - ETA: 0s - loss: 0.3197 - accuracy: 0.84 - ETA: 0s - loss: 0.3194 - accuracy: 0.84 - ETA: 0s - loss: 0.3193 - accuracy: 0.84 - ETA: 0s - loss: 0.3184 - accuracy: 0.84 - ETA: 0s - loss: 0.3184 - accuracy: 0.84 - ETA: 0s - loss: 0.3179 - accuracy: 0.84 - ETA: 0s - loss: 0.3173 - accuracy: 0.84 - ETA: 0s - loss: 0.3174 - accuracy: 0.84 - ETA: 0s - loss: 0.3174 - accuracy: 0.84 - ETA: 0s - loss: 0.3171 - accuracy: 0.84 - ETA: 0s - loss: 0.3168 - accuracy: 0.84 - ETA: 0s - loss: 0.3165 - accuracy: 0.84 - 1s 145us/step - loss: 0.3164 - accuracy: 0.8491 - val_loss: 0.2908 - val_accuracy: 0.8717\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3221 - accuracy: 0.84 - ETA: 1s - loss: 0.3198 - accuracy: 0.85 - ETA: 1s - loss: 0.3254 - accuracy: 0.84 - ETA: 0s - loss: 0.3214 - accuracy: 0.84 - ETA: 0s - loss: 0.3195 - accuracy: 0.84 - ETA: 0s - loss: 0.3208 - accuracy: 0.84 - ETA: 0s - loss: 0.3215 - accuracy: 0.84 - ETA: 0s - loss: 0.3218 - accuracy: 0.84 - ETA: 0s - loss: 0.3201 - accuracy: 0.84 - ETA: 0s - loss: 0.3191 - accuracy: 0.84 - ETA: 0s - loss: 0.3191 - accuracy: 0.84 - ETA: 0s - loss: 0.3189 - accuracy: 0.84 - ETA: 0s - loss: 0.3185 - accuracy: 0.84 - ETA: 0s - loss: 0.3178 - accuracy: 0.84 - ETA: 0s - loss: 0.3180 - accuracy: 0.84 - ETA: 0s - loss: 0.3169 - accuracy: 0.84 - ETA: 0s - loss: 0.3160 - accuracy: 0.84 - ETA: 0s - loss: 0.3158 - accuracy: 0.84 - ETA: 0s - loss: 0.3164 - accuracy: 0.84 - ETA: 0s - loss: 0.3162 - accuracy: 0.84 - ETA: 0s - loss: 0.3158 - accuracy: 0.84 - 1s 137us/step - loss: 0.3156 - accuracy: 0.8494 - val_loss: 0.2861 - val_accuracy: 0.8710\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3095 - accuracy: 0.86 - ETA: 1s - loss: 0.3126 - accuracy: 0.85 - ETA: 1s - loss: 0.3091 - accuracy: 0.85 - ETA: 1s - loss: 0.3118 - accuracy: 0.85 - ETA: 0s - loss: 0.3115 - accuracy: 0.85 - ETA: 0s - loss: 0.3099 - accuracy: 0.85 - ETA: 0s - loss: 0.3089 - accuracy: 0.85 - ETA: 0s - loss: 0.3080 - accuracy: 0.85 - ETA: 0s - loss: 0.3096 - accuracy: 0.85 - ETA: 0s - loss: 0.3084 - accuracy: 0.85 - ETA: 0s - loss: 0.3087 - accuracy: 0.85 - ETA: 0s - loss: 0.3077 - accuracy: 0.85 - ETA: 0s - loss: 0.3073 - accuracy: 0.85 - ETA: 0s - loss: 0.3072 - accuracy: 0.85 - ETA: 0s - loss: 0.3080 - accuracy: 0.85 - ETA: 0s - loss: 0.3082 - accuracy: 0.85 - ETA: 0s - loss: 0.3087 - accuracy: 0.85 - ETA: 0s - loss: 0.3080 - accuracy: 0.85 - ETA: 0s - loss: 0.3084 - accuracy: 0.85 - ETA: 0s - loss: 0.3083 - accuracy: 0.85 - ETA: 0s - loss: 0.3089 - accuracy: 0.85 - ETA: 0s - loss: 0.3086 - accuracy: 0.85 - ETA: 0s - loss: 0.3088 - accuracy: 0.85 - 1s 143us/step - loss: 0.3082 - accuracy: 0.8534 - val_loss: 0.2838 - val_accuracy: 0.8757\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3008 - accuracy: 0.86 - ETA: 1s - loss: 0.3073 - accuracy: 0.85 - ETA: 1s - loss: 0.3120 - accuracy: 0.85 - ETA: 1s - loss: 0.3097 - accuracy: 0.85 - ETA: 1s - loss: 0.3086 - accuracy: 0.85 - ETA: 0s - loss: 0.3086 - accuracy: 0.85 - ETA: 0s - loss: 0.3092 - accuracy: 0.85 - ETA: 0s - loss: 0.3089 - accuracy: 0.85 - ETA: 0s - loss: 0.3103 - accuracy: 0.85 - ETA: 0s - loss: 0.3089 - accuracy: 0.85 - ETA: 0s - loss: 0.3081 - accuracy: 0.85 - ETA: 0s - loss: 0.3078 - accuracy: 0.85 - ETA: 0s - loss: 0.3070 - accuracy: 0.85 - ETA: 0s - loss: 0.3067 - accuracy: 0.85 - ETA: 0s - loss: 0.3076 - accuracy: 0.85 - ETA: 0s - loss: 0.3077 - accuracy: 0.85 - ETA: 0s - loss: 0.3072 - accuracy: 0.85 - ETA: 0s - loss: 0.3067 - accuracy: 0.85 - ETA: 0s - loss: 0.3068 - accuracy: 0.85 - ETA: 0s - loss: 0.3069 - accuracy: 0.85 - ETA: 0s - loss: 0.3068 - accuracy: 0.85 - ETA: 0s - loss: 0.3062 - accuracy: 0.85 - ETA: 0s - loss: 0.3060 - accuracy: 0.85 - 1s 142us/step - loss: 0.3062 - accuracy: 0.8563 - val_loss: 0.2784 - val_accuracy: 0.8782\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3037 - accuracy: 0.84 - ETA: 1s - loss: 0.2927 - accuracy: 0.86 - ETA: 1s - loss: 0.2990 - accuracy: 0.86 - ETA: 1s - loss: 0.3023 - accuracy: 0.85 - ETA: 0s - loss: 0.3028 - accuracy: 0.85 - ETA: 0s - loss: 0.3039 - accuracy: 0.85 - ETA: 0s - loss: 0.3047 - accuracy: 0.85 - ETA: 0s - loss: 0.3052 - accuracy: 0.85 - ETA: 0s - loss: 0.3058 - accuracy: 0.85 - ETA: 0s - loss: 0.3061 - accuracy: 0.85 - ETA: 0s - loss: 0.3062 - accuracy: 0.85 - ETA: 0s - loss: 0.3064 - accuracy: 0.85 - ETA: 0s - loss: 0.3054 - accuracy: 0.85 - ETA: 0s - loss: 0.3051 - accuracy: 0.85 - ETA: 0s - loss: 0.3046 - accuracy: 0.85 - ETA: 0s - loss: 0.3047 - accuracy: 0.85 - ETA: 0s - loss: 0.3041 - accuracy: 0.85 - ETA: 0s - loss: 0.3037 - accuracy: 0.85 - ETA: 0s - loss: 0.3039 - accuracy: 0.85 - ETA: 0s - loss: 0.3033 - accuracy: 0.85 - ETA: 0s - loss: 0.3035 - accuracy: 0.85 - ETA: 0s - loss: 0.3029 - accuracy: 0.85 - 1s 137us/step - loss: 0.3031 - accuracy: 0.8564 - val_loss: 0.2754 - val_accuracy: 0.8820\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3239 - accuracy: 0.84 - ETA: 1s - loss: 0.3060 - accuracy: 0.85 - ETA: 1s - loss: 0.3099 - accuracy: 0.85 - ETA: 1s - loss: 0.3094 - accuracy: 0.85 - ETA: 1s - loss: 0.3089 - accuracy: 0.85 - ETA: 0s - loss: 0.3078 - accuracy: 0.85 - ETA: 0s - loss: 0.3033 - accuracy: 0.85 - ETA: 0s - loss: 0.3020 - accuracy: 0.85 - ETA: 0s - loss: 0.3025 - accuracy: 0.85 - ETA: 0s - loss: 0.3030 - accuracy: 0.85 - ETA: 0s - loss: 0.3013 - accuracy: 0.85 - ETA: 0s - loss: 0.3015 - accuracy: 0.85 - ETA: 0s - loss: 0.3015 - accuracy: 0.85 - ETA: 0s - loss: 0.3007 - accuracy: 0.85 - ETA: 0s - loss: 0.2994 - accuracy: 0.85 - ETA: 0s - loss: 0.2995 - accuracy: 0.85 - ETA: 0s - loss: 0.2995 - accuracy: 0.85 - ETA: 0s - loss: 0.2994 - accuracy: 0.85 - ETA: 0s - loss: 0.2990 - accuracy: 0.85 - ETA: 0s - loss: 0.2987 - accuracy: 0.85 - ETA: 0s - loss: 0.2985 - accuracy: 0.85 - ETA: 0s - loss: 0.2984 - accuracy: 0.86 - 1s 136us/step - loss: 0.2989 - accuracy: 0.8598 - val_loss: 0.2744 - val_accuracy: 0.8847\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3037 - accuracy: 0.85 - ETA: 1s - loss: 0.3045 - accuracy: 0.85 - ETA: 1s - loss: 0.3020 - accuracy: 0.85 - ETA: 1s - loss: 0.3013 - accuracy: 0.85 - ETA: 1s - loss: 0.2987 - accuracy: 0.86 - ETA: 0s - loss: 0.2981 - accuracy: 0.86 - ETA: 0s - loss: 0.2990 - accuracy: 0.86 - ETA: 0s - loss: 0.2973 - accuracy: 0.86 - ETA: 0s - loss: 0.2978 - accuracy: 0.86 - ETA: 0s - loss: 0.2978 - accuracy: 0.86 - ETA: 0s - loss: 0.2968 - accuracy: 0.86 - ETA: 0s - loss: 0.2964 - accuracy: 0.86 - ETA: 0s - loss: 0.2964 - accuracy: 0.86 - ETA: 0s - loss: 0.2961 - accuracy: 0.86 - ETA: 0s - loss: 0.2965 - accuracy: 0.86 - ETA: 0s - loss: 0.2960 - accuracy: 0.86 - ETA: 0s - loss: 0.2968 - accuracy: 0.86 - ETA: 0s - loss: 0.2968 - accuracy: 0.86 - ETA: 0s - loss: 0.2968 - accuracy: 0.86 - ETA: 0s - loss: 0.2965 - accuracy: 0.86 - ETA: 0s - loss: 0.2966 - accuracy: 0.86 - ETA: 0s - loss: 0.2964 - accuracy: 0.86 - 1s 138us/step - loss: 0.2964 - accuracy: 0.8617 - val_loss: 0.2674 - val_accuracy: 0.8876\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2726 - accuracy: 0.88 - ETA: 1s - loss: 0.2841 - accuracy: 0.87 - ETA: 1s - loss: 0.2845 - accuracy: 0.87 - ETA: 1s - loss: 0.2877 - accuracy: 0.86 - ETA: 1s - loss: 0.2913 - accuracy: 0.86 - ETA: 0s - loss: 0.2923 - accuracy: 0.86 - ETA: 0s - loss: 0.2918 - accuracy: 0.86 - ETA: 0s - loss: 0.2906 - accuracy: 0.86 - ETA: 0s - loss: 0.2924 - accuracy: 0.86 - ETA: 0s - loss: 0.2921 - accuracy: 0.86 - ETA: 0s - loss: 0.2921 - accuracy: 0.86 - ETA: 0s - loss: 0.2915 - accuracy: 0.86 - ETA: 0s - loss: 0.2899 - accuracy: 0.86 - ETA: 0s - loss: 0.2898 - accuracy: 0.86 - ETA: 0s - loss: 0.2901 - accuracy: 0.86 - ETA: 0s - loss: 0.2895 - accuracy: 0.86 - ETA: 0s - loss: 0.2899 - accuracy: 0.86 - ETA: 0s - loss: 0.2901 - accuracy: 0.86 - ETA: 0s - loss: 0.2902 - accuracy: 0.86 - ETA: 0s - loss: 0.2902 - accuracy: 0.86 - ETA: 0s - loss: 0.2904 - accuracy: 0.86 - ETA: 0s - loss: 0.2910 - accuracy: 0.86 - ETA: 0s - loss: 0.2913 - accuracy: 0.86 - 1s 142us/step - loss: 0.2917 - accuracy: 0.8650 - val_loss: 0.2639 - val_accuracy: 0.8887\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2807 - accuracy: 0.87 - ETA: 1s - loss: 0.2944 - accuracy: 0.85 - ETA: 1s - loss: 0.2973 - accuracy: 0.85 - ETA: 1s - loss: 0.2938 - accuracy: 0.86 - ETA: 1s - loss: 0.2911 - accuracy: 0.86 - ETA: 1s - loss: 0.2922 - accuracy: 0.86 - ETA: 0s - loss: 0.2914 - accuracy: 0.86 - ETA: 0s - loss: 0.2904 - accuracy: 0.86 - ETA: 0s - loss: 0.2903 - accuracy: 0.86 - ETA: 0s - loss: 0.2910 - accuracy: 0.86 - ETA: 0s - loss: 0.2915 - accuracy: 0.86 - ETA: 0s - loss: 0.2920 - accuracy: 0.86 - ETA: 0s - loss: 0.2919 - accuracy: 0.86 - ETA: 0s - loss: 0.2911 - accuracy: 0.86 - ETA: 0s - loss: 0.2912 - accuracy: 0.86 - ETA: 0s - loss: 0.2902 - accuracy: 0.86 - ETA: 0s - loss: 0.2909 - accuracy: 0.86 - ETA: 0s - loss: 0.2909 - accuracy: 0.86 - ETA: 0s - loss: 0.2906 - accuracy: 0.86 - ETA: 0s - loss: 0.2899 - accuracy: 0.86 - ETA: 0s - loss: 0.2893 - accuracy: 0.86 - ETA: 0s - loss: 0.2888 - accuracy: 0.86 - 1s 143us/step - loss: 0.2891 - accuracy: 0.8659 - val_loss: 0.2611 - val_accuracy: 0.8933\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2453 - accuracy: 0.90 - ETA: 1s - loss: 0.2817 - accuracy: 0.86 - ETA: 1s - loss: 0.2841 - accuracy: 0.86 - ETA: 1s - loss: 0.2873 - accuracy: 0.86 - ETA: 1s - loss: 0.2856 - accuracy: 0.86 - ETA: 0s - loss: 0.2864 - accuracy: 0.86 - ETA: 0s - loss: 0.2861 - accuracy: 0.86 - ETA: 0s - loss: 0.2859 - accuracy: 0.86 - ETA: 0s - loss: 0.2858 - accuracy: 0.86 - ETA: 0s - loss: 0.2858 - accuracy: 0.86 - ETA: 0s - loss: 0.2857 - accuracy: 0.86 - ETA: 0s - loss: 0.2853 - accuracy: 0.86 - ETA: 0s - loss: 0.2842 - accuracy: 0.86 - ETA: 0s - loss: 0.2834 - accuracy: 0.86 - ETA: 0s - loss: 0.2831 - accuracy: 0.86 - ETA: 0s - loss: 0.2831 - accuracy: 0.86 - ETA: 0s - loss: 0.2830 - accuracy: 0.86 - ETA: 0s - loss: 0.2830 - accuracy: 0.86 - ETA: 0s - loss: 0.2826 - accuracy: 0.87 - ETA: 0s - loss: 0.2836 - accuracy: 0.86 - ETA: 0s - loss: 0.2846 - accuracy: 0.86 - ETA: 0s - loss: 0.2846 - accuracy: 0.86 - 1s 139us/step - loss: 0.2845 - accuracy: 0.8689 - val_loss: 0.2585 - val_accuracy: 0.8901\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2827 - accuracy: 0.87 - ETA: 1s - loss: 0.2871 - accuracy: 0.86 - ETA: 1s - loss: 0.2801 - accuracy: 0.87 - ETA: 1s - loss: 0.2818 - accuracy: 0.86 - ETA: 0s - loss: 0.2845 - accuracy: 0.86 - ETA: 0s - loss: 0.2850 - accuracy: 0.86 - ETA: 0s - loss: 0.2829 - accuracy: 0.86 - ETA: 0s - loss: 0.2829 - accuracy: 0.86 - ETA: 0s - loss: 0.2816 - accuracy: 0.86 - ETA: 0s - loss: 0.2813 - accuracy: 0.86 - ETA: 0s - loss: 0.2802 - accuracy: 0.87 - ETA: 0s - loss: 0.2802 - accuracy: 0.87 - ETA: 0s - loss: 0.2810 - accuracy: 0.87 - ETA: 0s - loss: 0.2817 - accuracy: 0.87 - ETA: 0s - loss: 0.2814 - accuracy: 0.87 - ETA: 0s - loss: 0.2815 - accuracy: 0.87 - ETA: 0s - loss: 0.2809 - accuracy: 0.87 - ETA: 0s - loss: 0.2805 - accuracy: 0.87 - ETA: 0s - loss: 0.2810 - accuracy: 0.87 - ETA: 0s - loss: 0.2807 - accuracy: 0.87 - ETA: 0s - loss: 0.2807 - accuracy: 0.87 - ETA: 0s - loss: 0.2818 - accuracy: 0.87 - 1s 141us/step - loss: 0.2817 - accuracy: 0.8704 - val_loss: 0.2542 - val_accuracy: 0.8946\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2729 - accuracy: 0.87 - ETA: 1s - loss: 0.2659 - accuracy: 0.88 - ETA: 1s - loss: 0.2754 - accuracy: 0.87 - ETA: 1s - loss: 0.2778 - accuracy: 0.87 - ETA: 0s - loss: 0.2794 - accuracy: 0.87 - ETA: 0s - loss: 0.2786 - accuracy: 0.87 - ETA: 0s - loss: 0.2774 - accuracy: 0.87 - ETA: 0s - loss: 0.2762 - accuracy: 0.87 - ETA: 0s - loss: 0.2748 - accuracy: 0.87 - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - ETA: 0s - loss: 0.2765 - accuracy: 0.87 - ETA: 0s - loss: 0.2770 - accuracy: 0.87 - ETA: 0s - loss: 0.2773 - accuracy: 0.87 - ETA: 0s - loss: 0.2773 - accuracy: 0.87 - ETA: 0s - loss: 0.2778 - accuracy: 0.87 - ETA: 0s - loss: 0.2771 - accuracy: 0.87 - ETA: 0s - loss: 0.2768 - accuracy: 0.87 - ETA: 0s - loss: 0.2767 - accuracy: 0.87 - ETA: 0s - loss: 0.2769 - accuracy: 0.87 - ETA: 0s - loss: 0.2773 - accuracy: 0.87 - ETA: 0s - loss: 0.2775 - accuracy: 0.87 - ETA: 0s - loss: 0.2775 - accuracy: 0.87 - ETA: 0s - loss: 0.2779 - accuracy: 0.87 - 1s 140us/step - loss: 0.2785 - accuracy: 0.8731 - val_loss: 0.2513 - val_accuracy: 0.8947\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2841 - accuracy: 0.85 - ETA: 1s - loss: 0.2824 - accuracy: 0.86 - ETA: 1s - loss: 0.2785 - accuracy: 0.87 - ETA: 1s - loss: 0.2766 - accuracy: 0.86 - ETA: 1s - loss: 0.2737 - accuracy: 0.87 - ETA: 0s - loss: 0.2746 - accuracy: 0.87 - ETA: 0s - loss: 0.2747 - accuracy: 0.87 - ETA: 0s - loss: 0.2749 - accuracy: 0.87 - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - ETA: 0s - loss: 0.2763 - accuracy: 0.87 - ETA: 0s - loss: 0.2770 - accuracy: 0.87 - ETA: 0s - loss: 0.2762 - accuracy: 0.87 - ETA: 0s - loss: 0.2758 - accuracy: 0.87 - ETA: 0s - loss: 0.2756 - accuracy: 0.87 - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - ETA: 0s - loss: 0.2759 - accuracy: 0.87 - ETA: 0s - loss: 0.2760 - accuracy: 0.87 - ETA: 0s - loss: 0.2767 - accuracy: 0.87 - ETA: 0s - loss: 0.2767 - accuracy: 0.87 - ETA: 0s - loss: 0.2768 - accuracy: 0.87 - ETA: 0s - loss: 0.2764 - accuracy: 0.87 - ETA: 0s - loss: 0.2765 - accuracy: 0.87 - 1s 145us/step - loss: 0.2768 - accuracy: 0.8714 - val_loss: 0.2488 - val_accuracy: 0.9014\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2664 - accuracy: 0.87 - ETA: 1s - loss: 0.2743 - accuracy: 0.86 - ETA: 1s - loss: 0.2737 - accuracy: 0.87 - ETA: 1s - loss: 0.2791 - accuracy: 0.87 - ETA: 0s - loss: 0.2790 - accuracy: 0.87 - ETA: 0s - loss: 0.2776 - accuracy: 0.87 - ETA: 0s - loss: 0.2775 - accuracy: 0.87 - ETA: 0s - loss: 0.2779 - accuracy: 0.87 - ETA: 0s - loss: 0.2766 - accuracy: 0.87 - ETA: 0s - loss: 0.2785 - accuracy: 0.87 - ETA: 0s - loss: 0.2778 - accuracy: 0.87 - ETA: 0s - loss: 0.2772 - accuracy: 0.87 - ETA: 0s - loss: 0.2765 - accuracy: 0.87 - ETA: 0s - loss: 0.2776 - accuracy: 0.87 - ETA: 0s - loss: 0.2775 - accuracy: 0.87 - ETA: 0s - loss: 0.2765 - accuracy: 0.87 - ETA: 0s - loss: 0.2755 - accuracy: 0.87 - ETA: 0s - loss: 0.2758 - accuracy: 0.87 - ETA: 0s - loss: 0.2753 - accuracy: 0.87 - ETA: 0s - loss: 0.2751 - accuracy: 0.87 - ETA: 0s - loss: 0.2742 - accuracy: 0.87 - ETA: 0s - loss: 0.2741 - accuracy: 0.87 - 1s 139us/step - loss: 0.2740 - accuracy: 0.8756 - val_loss: 0.2444 - val_accuracy: 0.9022\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2487 - accuracy: 0.89 - ETA: 1s - loss: 0.2662 - accuracy: 0.88 - ETA: 1s - loss: 0.2642 - accuracy: 0.88 - ETA: 1s - loss: 0.2629 - accuracy: 0.88 - ETA: 1s - loss: 0.2642 - accuracy: 0.88 - ETA: 0s - loss: 0.2644 - accuracy: 0.88 - ETA: 0s - loss: 0.2664 - accuracy: 0.88 - ETA: 0s - loss: 0.2680 - accuracy: 0.88 - ETA: 0s - loss: 0.2687 - accuracy: 0.88 - ETA: 0s - loss: 0.2697 - accuracy: 0.87 - ETA: 0s - loss: 0.2689 - accuracy: 0.87 - ETA: 0s - loss: 0.2703 - accuracy: 0.87 - ETA: 0s - loss: 0.2703 - accuracy: 0.87 - ETA: 0s - loss: 0.2701 - accuracy: 0.87 - ETA: 0s - loss: 0.2705 - accuracy: 0.87 - ETA: 0s - loss: 0.2703 - accuracy: 0.87 - ETA: 0s - loss: 0.2702 - accuracy: 0.87 - ETA: 0s - loss: 0.2699 - accuracy: 0.87 - ETA: 0s - loss: 0.2693 - accuracy: 0.87 - ETA: 0s - loss: 0.2693 - accuracy: 0.87 - ETA: 0s - loss: 0.2698 - accuracy: 0.87 - ETA: 0s - loss: 0.2698 - accuracy: 0.87 - ETA: 0s - loss: 0.2697 - accuracy: 0.87 - 1s 142us/step - loss: 0.2703 - accuracy: 0.8776 - val_loss: 0.2424 - val_accuracy: 0.8979\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2584 - accuracy: 0.87 - ETA: 1s - loss: 0.2683 - accuracy: 0.87 - ETA: 1s - loss: 0.2705 - accuracy: 0.87 - ETA: 1s - loss: 0.2665 - accuracy: 0.87 - ETA: 1s - loss: 0.2663 - accuracy: 0.87 - ETA: 0s - loss: 0.2667 - accuracy: 0.87 - ETA: 0s - loss: 0.2691 - accuracy: 0.87 - ETA: 0s - loss: 0.2691 - accuracy: 0.87 - ETA: 0s - loss: 0.2685 - accuracy: 0.87 - ETA: 0s - loss: 0.2672 - accuracy: 0.87 - ETA: 0s - loss: 0.2672 - accuracy: 0.87 - ETA: 0s - loss: 0.2675 - accuracy: 0.87 - ETA: 0s - loss: 0.2682 - accuracy: 0.87 - ETA: 0s - loss: 0.2679 - accuracy: 0.87 - ETA: 0s - loss: 0.2681 - accuracy: 0.87 - ETA: 0s - loss: 0.2693 - accuracy: 0.87 - ETA: 0s - loss: 0.2692 - accuracy: 0.87 - ETA: 0s - loss: 0.2691 - accuracy: 0.87 - ETA: 0s - loss: 0.2691 - accuracy: 0.87 - ETA: 0s - loss: 0.2698 - accuracy: 0.87 - ETA: 0s - loss: 0.2695 - accuracy: 0.87 - ETA: 0s - loss: 0.2691 - accuracy: 0.87 - 1s 139us/step - loss: 0.2696 - accuracy: 0.8781 - val_loss: 0.2420 - val_accuracy: 0.9029\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2699 - accuracy: 0.87 - ETA: 1s - loss: 0.2628 - accuracy: 0.87 - ETA: 1s - loss: 0.2638 - accuracy: 0.87 - ETA: 1s - loss: 0.2639 - accuracy: 0.87 - ETA: 0s - loss: 0.2615 - accuracy: 0.88 - ETA: 0s - loss: 0.2632 - accuracy: 0.87 - ETA: 0s - loss: 0.2639 - accuracy: 0.87 - ETA: 0s - loss: 0.2640 - accuracy: 0.87 - ETA: 0s - loss: 0.2634 - accuracy: 0.88 - ETA: 0s - loss: 0.2633 - accuracy: 0.88 - ETA: 0s - loss: 0.2638 - accuracy: 0.87 - ETA: 0s - loss: 0.2637 - accuracy: 0.88 - ETA: 0s - loss: 0.2630 - accuracy: 0.88 - ETA: 0s - loss: 0.2627 - accuracy: 0.88 - ETA: 0s - loss: 0.2636 - accuracy: 0.88 - ETA: 0s - loss: 0.2636 - accuracy: 0.88 - ETA: 0s - loss: 0.2627 - accuracy: 0.88 - ETA: 0s - loss: 0.2632 - accuracy: 0.88 - ETA: 0s - loss: 0.2638 - accuracy: 0.88 - ETA: 0s - loss: 0.2637 - accuracy: 0.88 - ETA: 0s - loss: 0.2642 - accuracy: 0.88 - ETA: 0s - loss: 0.2643 - accuracy: 0.88 - 1s 137us/step - loss: 0.2643 - accuracy: 0.8802 - val_loss: 0.2358 - val_accuracy: 0.9063\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2609 - accuracy: 0.88 - ETA: 1s - loss: 0.2768 - accuracy: 0.87 - ETA: 1s - loss: 0.2786 - accuracy: 0.87 - ETA: 1s - loss: 0.2767 - accuracy: 0.87 - ETA: 1s - loss: 0.2740 - accuracy: 0.87 - ETA: 0s - loss: 0.2695 - accuracy: 0.87 - ETA: 0s - loss: 0.2705 - accuracy: 0.87 - ETA: 0s - loss: 0.2714 - accuracy: 0.87 - ETA: 0s - loss: 0.2687 - accuracy: 0.87 - ETA: 0s - loss: 0.2681 - accuracy: 0.87 - ETA: 0s - loss: 0.2666 - accuracy: 0.87 - ETA: 0s - loss: 0.2671 - accuracy: 0.87 - ETA: 0s - loss: 0.2662 - accuracy: 0.87 - ETA: 0s - loss: 0.2655 - accuracy: 0.87 - ETA: 0s - loss: 0.2660 - accuracy: 0.87 - ETA: 0s - loss: 0.2657 - accuracy: 0.87 - ETA: 0s - loss: 0.2656 - accuracy: 0.87 - ETA: 0s - loss: 0.2650 - accuracy: 0.88 - ETA: 0s - loss: 0.2645 - accuracy: 0.88 - ETA: 0s - loss: 0.2636 - accuracy: 0.88 - ETA: 0s - loss: 0.2631 - accuracy: 0.88 - ETA: 0s - loss: 0.2623 - accuracy: 0.88 - 1s 141us/step - loss: 0.2624 - accuracy: 0.8819 - val_loss: 0.2351 - val_accuracy: 0.9096\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2743 - accuracy: 0.88 - ETA: 1s - loss: 0.2608 - accuracy: 0.89 - ETA: 1s - loss: 0.2618 - accuracy: 0.88 - ETA: 1s - loss: 0.2628 - accuracy: 0.88 - ETA: 1s - loss: 0.2690 - accuracy: 0.87 - ETA: 0s - loss: 0.2644 - accuracy: 0.88 - ETA: 0s - loss: 0.2643 - accuracy: 0.88 - ETA: 0s - loss: 0.2622 - accuracy: 0.88 - ETA: 0s - loss: 0.2618 - accuracy: 0.88 - ETA: 0s - loss: 0.2614 - accuracy: 0.88 - ETA: 0s - loss: 0.2632 - accuracy: 0.88 - ETA: 0s - loss: 0.2623 - accuracy: 0.88 - ETA: 0s - loss: 0.2620 - accuracy: 0.88 - ETA: 0s - loss: 0.2623 - accuracy: 0.88 - ETA: 0s - loss: 0.2608 - accuracy: 0.88 - ETA: 0s - loss: 0.2600 - accuracy: 0.88 - ETA: 0s - loss: 0.2608 - accuracy: 0.88 - ETA: 0s - loss: 0.2599 - accuracy: 0.88 - ETA: 0s - loss: 0.2609 - accuracy: 0.88 - ETA: 0s - loss: 0.2614 - accuracy: 0.88 - ETA: 0s - loss: 0.2614 - accuracy: 0.88 - ETA: 0s - loss: 0.2609 - accuracy: 0.88 - 1s 136us/step - loss: 0.2609 - accuracy: 0.8820 - val_loss: 0.2309 - val_accuracy: 0.9034\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2566 - accuracy: 0.89 - ETA: 1s - loss: 0.2707 - accuracy: 0.87 - ETA: 1s - loss: 0.2600 - accuracy: 0.87 - ETA: 1s - loss: 0.2579 - accuracy: 0.88 - ETA: 1s - loss: 0.2534 - accuracy: 0.88 - ETA: 1s - loss: 0.2535 - accuracy: 0.88 - ETA: 1s - loss: 0.2546 - accuracy: 0.88 - ETA: 0s - loss: 0.2553 - accuracy: 0.88 - ETA: 0s - loss: 0.2559 - accuracy: 0.88 - ETA: 0s - loss: 0.2557 - accuracy: 0.88 - ETA: 0s - loss: 0.2557 - accuracy: 0.88 - ETA: 0s - loss: 0.2570 - accuracy: 0.88 - ETA: 0s - loss: 0.2572 - accuracy: 0.88 - ETA: 0s - loss: 0.2576 - accuracy: 0.88 - ETA: 0s - loss: 0.2578 - accuracy: 0.88 - ETA: 0s - loss: 0.2575 - accuracy: 0.88 - ETA: 0s - loss: 0.2575 - accuracy: 0.88 - ETA: 0s - loss: 0.2574 - accuracy: 0.88 - ETA: 0s - loss: 0.2579 - accuracy: 0.88 - ETA: 0s - loss: 0.2577 - accuracy: 0.88 - ETA: 0s - loss: 0.2572 - accuracy: 0.88 - ETA: 0s - loss: 0.2564 - accuracy: 0.88 - ETA: 0s - loss: 0.2561 - accuracy: 0.88 - 1s 143us/step - loss: 0.2562 - accuracy: 0.8847 - val_loss: 0.2277 - val_accuracy: 0.9087\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2761 - accuracy: 0.88 - ETA: 1s - loss: 0.2518 - accuracy: 0.88 - ETA: 1s - loss: 0.2531 - accuracy: 0.88 - ETA: 1s - loss: 0.2518 - accuracy: 0.88 - ETA: 0s - loss: 0.2478 - accuracy: 0.89 - ETA: 0s - loss: 0.2498 - accuracy: 0.88 - ETA: 0s - loss: 0.2503 - accuracy: 0.89 - ETA: 0s - loss: 0.2505 - accuracy: 0.89 - ETA: 0s - loss: 0.2499 - accuracy: 0.89 - ETA: 0s - loss: 0.2499 - accuracy: 0.89 - ETA: 0s - loss: 0.2506 - accuracy: 0.88 - ETA: 0s - loss: 0.2507 - accuracy: 0.88 - ETA: 0s - loss: 0.2524 - accuracy: 0.88 - ETA: 0s - loss: 0.2523 - accuracy: 0.88 - ETA: 0s - loss: 0.2520 - accuracy: 0.88 - ETA: 0s - loss: 0.2521 - accuracy: 0.88 - ETA: 0s - loss: 0.2516 - accuracy: 0.88 - ETA: 0s - loss: 0.2524 - accuracy: 0.88 - ETA: 0s - loss: 0.2527 - accuracy: 0.88 - ETA: 0s - loss: 0.2524 - accuracy: 0.88 - ETA: 0s - loss: 0.2521 - accuracy: 0.88 - ETA: 0s - loss: 0.2520 - accuracy: 0.88 - 1s 137us/step - loss: 0.2520 - accuracy: 0.8873 - val_loss: 0.2255 - val_accuracy: 0.9121\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2499 - accuracy: 0.88 - ETA: 1s - loss: 0.2488 - accuracy: 0.88 - ETA: 1s - loss: 0.2464 - accuracy: 0.89 - ETA: 1s - loss: 0.2568 - accuracy: 0.88 - ETA: 1s - loss: 0.2616 - accuracy: 0.88 - ETA: 1s - loss: 0.2583 - accuracy: 0.88 - ETA: 0s - loss: 0.2575 - accuracy: 0.88 - ETA: 0s - loss: 0.2560 - accuracy: 0.88 - ETA: 0s - loss: 0.2558 - accuracy: 0.88 - ETA: 0s - loss: 0.2558 - accuracy: 0.88 - ETA: 0s - loss: 0.2550 - accuracy: 0.88 - ETA: 0s - loss: 0.2543 - accuracy: 0.88 - ETA: 0s - loss: 0.2531 - accuracy: 0.88 - ETA: 0s - loss: 0.2521 - accuracy: 0.88 - ETA: 0s - loss: 0.2524 - accuracy: 0.88 - ETA: 0s - loss: 0.2522 - accuracy: 0.88 - ETA: 0s - loss: 0.2529 - accuracy: 0.88 - ETA: 0s - loss: 0.2528 - accuracy: 0.88 - ETA: 0s - loss: 0.2525 - accuracy: 0.88 - ETA: 0s - loss: 0.2522 - accuracy: 0.88 - ETA: 0s - loss: 0.2523 - accuracy: 0.88 - ETA: 0s - loss: 0.2520 - accuracy: 0.88 - ETA: 0s - loss: 0.2516 - accuracy: 0.88 - 1s 141us/step - loss: 0.2515 - accuracy: 0.8879 - val_loss: 0.2227 - val_accuracy: 0.9135\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2385 - accuracy: 0.88 - ETA: 1s - loss: 0.2451 - accuracy: 0.89 - ETA: 1s - loss: 0.2472 - accuracy: 0.89 - ETA: 1s - loss: 0.2530 - accuracy: 0.88 - ETA: 1s - loss: 0.2525 - accuracy: 0.88 - ETA: 1s - loss: 0.2512 - accuracy: 0.88 - ETA: 0s - loss: 0.2504 - accuracy: 0.88 - ETA: 0s - loss: 0.2516 - accuracy: 0.88 - ETA: 0s - loss: 0.2503 - accuracy: 0.88 - ETA: 0s - loss: 0.2494 - accuracy: 0.88 - ETA: 0s - loss: 0.2496 - accuracy: 0.88 - ETA: 0s - loss: 0.2490 - accuracy: 0.88 - ETA: 0s - loss: 0.2496 - accuracy: 0.88 - ETA: 0s - loss: 0.2502 - accuracy: 0.88 - ETA: 0s - loss: 0.2495 - accuracy: 0.88 - ETA: 0s - loss: 0.2498 - accuracy: 0.88 - ETA: 0s - loss: 0.2499 - accuracy: 0.88 - ETA: 0s - loss: 0.2493 - accuracy: 0.88 - ETA: 0s - loss: 0.2486 - accuracy: 0.88 - ETA: 0s - loss: 0.2484 - accuracy: 0.88 - ETA: 0s - loss: 0.2480 - accuracy: 0.88 - ETA: 0s - loss: 0.2481 - accuracy: 0.88 - ETA: 0s - loss: 0.2479 - accuracy: 0.88 - 1s 144us/step - loss: 0.2478 - accuracy: 0.8899 - val_loss: 0.2212 - val_accuracy: 0.9152\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2486 - accuracy: 0.87 - ETA: 1s - loss: 0.2527 - accuracy: 0.88 - ETA: 1s - loss: 0.2503 - accuracy: 0.88 - ETA: 1s - loss: 0.2499 - accuracy: 0.88 - ETA: 1s - loss: 0.2503 - accuracy: 0.88 - ETA: 1s - loss: 0.2499 - accuracy: 0.88 - ETA: 0s - loss: 0.2518 - accuracy: 0.88 - ETA: 0s - loss: 0.2518 - accuracy: 0.88 - ETA: 0s - loss: 0.2520 - accuracy: 0.88 - ETA: 0s - loss: 0.2505 - accuracy: 0.88 - ETA: 0s - loss: 0.2496 - accuracy: 0.88 - ETA: 0s - loss: 0.2492 - accuracy: 0.88 - ETA: 0s - loss: 0.2488 - accuracy: 0.88 - ETA: 0s - loss: 0.2486 - accuracy: 0.88 - ETA: 0s - loss: 0.2477 - accuracy: 0.88 - ETA: 0s - loss: 0.2475 - accuracy: 0.88 - ETA: 0s - loss: 0.2485 - accuracy: 0.88 - ETA: 0s - loss: 0.2485 - accuracy: 0.88 - ETA: 0s - loss: 0.2485 - accuracy: 0.88 - ETA: 0s - loss: 0.2489 - accuracy: 0.88 - ETA: 0s - loss: 0.2492 - accuracy: 0.88 - ETA: 0s - loss: 0.2495 - accuracy: 0.88 - 1s 138us/step - loss: 0.2487 - accuracy: 0.8893 - val_loss: 0.2193 - val_accuracy: 0.9092\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2393 - accuracy: 0.88 - ETA: 1s - loss: 0.2423 - accuracy: 0.88 - ETA: 1s - loss: 0.2443 - accuracy: 0.88 - ETA: 1s - loss: 0.2449 - accuracy: 0.88 - ETA: 0s - loss: 0.2421 - accuracy: 0.89 - ETA: 0s - loss: 0.2407 - accuracy: 0.89 - ETA: 0s - loss: 0.2419 - accuracy: 0.89 - ETA: 0s - loss: 0.2426 - accuracy: 0.89 - ETA: 0s - loss: 0.2424 - accuracy: 0.89 - ETA: 0s - loss: 0.2438 - accuracy: 0.89 - ETA: 0s - loss: 0.2447 - accuracy: 0.89 - ETA: 0s - loss: 0.2446 - accuracy: 0.89 - ETA: 0s - loss: 0.2452 - accuracy: 0.89 - ETA: 0s - loss: 0.2468 - accuracy: 0.88 - ETA: 0s - loss: 0.2477 - accuracy: 0.88 - ETA: 0s - loss: 0.2475 - accuracy: 0.88 - ETA: 0s - loss: 0.2469 - accuracy: 0.89 - ETA: 0s - loss: 0.2463 - accuracy: 0.89 - ETA: 0s - loss: 0.2459 - accuracy: 0.89 - ETA: 0s - loss: 0.2460 - accuracy: 0.89 - ETA: 0s - loss: 0.2470 - accuracy: 0.89 - ETA: 0s - loss: 0.2467 - accuracy: 0.89 - 1s 141us/step - loss: 0.2464 - accuracy: 0.8906 - val_loss: 0.2172 - val_accuracy: 0.9145\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 140us/step\n",
            "\n",
            "Accuracy on test data: 0.91\n",
            "\n",
            "Loss on test data: 0.22\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       104\n",
            "           1       0.86      0.98      0.91       123\n",
            "           2       0.87      0.92      0.89       455\n",
            "           3       0.89      0.15      0.26       307\n",
            "           4       0.66      0.97      0.79       431\n",
            "\n",
            "    accuracy                           0.77      1420\n",
            "   macro avg       0.82      0.77      0.74      1420\n",
            "weighted avg       0.80      0.77      0.72      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [   10    12    29 ... 14176 14178 14185]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 2s - loss: 0.2468 - accuracy: 0.89 - ETA: 1s - loss: 0.2379 - accuracy: 0.90 - ETA: 1s - loss: 0.2416 - accuracy: 0.89 - ETA: 1s - loss: 0.2399 - accuracy: 0.89 - ETA: 1s - loss: 0.2438 - accuracy: 0.89 - ETA: 1s - loss: 0.2451 - accuracy: 0.89 - ETA: 1s - loss: 0.2449 - accuracy: 0.89 - ETA: 1s - loss: 0.2439 - accuracy: 0.89 - ETA: 0s - loss: 0.2448 - accuracy: 0.89 - ETA: 0s - loss: 0.2426 - accuracy: 0.89 - ETA: 0s - loss: 0.2418 - accuracy: 0.89 - ETA: 0s - loss: 0.2426 - accuracy: 0.89 - ETA: 0s - loss: 0.2426 - accuracy: 0.89 - ETA: 0s - loss: 0.2428 - accuracy: 0.89 - ETA: 0s - loss: 0.2427 - accuracy: 0.89 - ETA: 0s - loss: 0.2426 - accuracy: 0.89 - ETA: 0s - loss: 0.2417 - accuracy: 0.89 - ETA: 0s - loss: 0.2432 - accuracy: 0.89 - ETA: 0s - loss: 0.2425 - accuracy: 0.89 - ETA: 0s - loss: 0.2419 - accuracy: 0.89 - ETA: 0s - loss: 0.2417 - accuracy: 0.89 - ETA: 0s - loss: 0.2405 - accuracy: 0.89 - ETA: 0s - loss: 0.2405 - accuracy: 0.89 - ETA: 0s - loss: 0.2411 - accuracy: 0.89 - 2s 153us/step - loss: 0.2416 - accuracy: 0.8938 - val_loss: 0.2160 - val_accuracy: 0.9167\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2347 - accuracy: 0.90 - ETA: 1s - loss: 0.2322 - accuracy: 0.90 - ETA: 1s - loss: 0.2270 - accuracy: 0.90 - ETA: 1s - loss: 0.2301 - accuracy: 0.90 - ETA: 0s - loss: 0.2315 - accuracy: 0.90 - ETA: 0s - loss: 0.2328 - accuracy: 0.89 - ETA: 0s - loss: 0.2339 - accuracy: 0.89 - ETA: 0s - loss: 0.2332 - accuracy: 0.89 - ETA: 0s - loss: 0.2336 - accuracy: 0.89 - ETA: 0s - loss: 0.2358 - accuracy: 0.89 - ETA: 0s - loss: 0.2371 - accuracy: 0.89 - ETA: 0s - loss: 0.2372 - accuracy: 0.89 - ETA: 0s - loss: 0.2375 - accuracy: 0.89 - ETA: 0s - loss: 0.2379 - accuracy: 0.89 - ETA: 0s - loss: 0.2383 - accuracy: 0.89 - ETA: 0s - loss: 0.2391 - accuracy: 0.89 - ETA: 0s - loss: 0.2390 - accuracy: 0.89 - ETA: 0s - loss: 0.2385 - accuracy: 0.89 - ETA: 0s - loss: 0.2390 - accuracy: 0.89 - ETA: 0s - loss: 0.2390 - accuracy: 0.89 - ETA: 0s - loss: 0.2389 - accuracy: 0.89 - ETA: 0s - loss: 0.2389 - accuracy: 0.89 - ETA: 0s - loss: 0.2390 - accuracy: 0.89 - 1s 143us/step - loss: 0.2389 - accuracy: 0.8947 - val_loss: 0.2160 - val_accuracy: 0.9167\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2860 - accuracy: 0.86 - ETA: 1s - loss: 0.2451 - accuracy: 0.88 - ETA: 1s - loss: 0.2415 - accuracy: 0.88 - ETA: 1s - loss: 0.2404 - accuracy: 0.89 - ETA: 1s - loss: 0.2375 - accuracy: 0.89 - ETA: 0s - loss: 0.2364 - accuracy: 0.89 - ETA: 0s - loss: 0.2381 - accuracy: 0.89 - ETA: 0s - loss: 0.2393 - accuracy: 0.89 - ETA: 0s - loss: 0.2384 - accuracy: 0.89 - ETA: 0s - loss: 0.2392 - accuracy: 0.89 - ETA: 0s - loss: 0.2400 - accuracy: 0.89 - ETA: 0s - loss: 0.2412 - accuracy: 0.89 - ETA: 0s - loss: 0.2416 - accuracy: 0.89 - ETA: 0s - loss: 0.2417 - accuracy: 0.89 - ETA: 0s - loss: 0.2417 - accuracy: 0.89 - ETA: 0s - loss: 0.2412 - accuracy: 0.89 - ETA: 0s - loss: 0.2411 - accuracy: 0.89 - ETA: 0s - loss: 0.2418 - accuracy: 0.89 - ETA: 0s - loss: 0.2414 - accuracy: 0.89 - ETA: 0s - loss: 0.2417 - accuracy: 0.89 - ETA: 0s - loss: 0.2410 - accuracy: 0.89 - ETA: 0s - loss: 0.2405 - accuracy: 0.89 - ETA: 0s - loss: 0.2412 - accuracy: 0.89 - 1s 144us/step - loss: 0.2412 - accuracy: 0.8925 - val_loss: 0.2126 - val_accuracy: 0.9181\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2360 - accuracy: 0.89 - ETA: 1s - loss: 0.2428 - accuracy: 0.89 - ETA: 1s - loss: 0.2416 - accuracy: 0.89 - ETA: 1s - loss: 0.2474 - accuracy: 0.88 - ETA: 1s - loss: 0.2463 - accuracy: 0.89 - ETA: 1s - loss: 0.2462 - accuracy: 0.88 - ETA: 0s - loss: 0.2451 - accuracy: 0.88 - ETA: 0s - loss: 0.2457 - accuracy: 0.88 - ETA: 0s - loss: 0.2458 - accuracy: 0.88 - ETA: 0s - loss: 0.2454 - accuracy: 0.89 - ETA: 0s - loss: 0.2434 - accuracy: 0.89 - ETA: 0s - loss: 0.2423 - accuracy: 0.89 - ETA: 0s - loss: 0.2414 - accuracy: 0.89 - ETA: 0s - loss: 0.2401 - accuracy: 0.89 - ETA: 0s - loss: 0.2396 - accuracy: 0.89 - ETA: 0s - loss: 0.2398 - accuracy: 0.89 - ETA: 0s - loss: 0.2390 - accuracy: 0.89 - ETA: 0s - loss: 0.2386 - accuracy: 0.89 - ETA: 0s - loss: 0.2386 - accuracy: 0.89 - ETA: 0s - loss: 0.2387 - accuracy: 0.89 - ETA: 0s - loss: 0.2383 - accuracy: 0.89 - ETA: 0s - loss: 0.2383 - accuracy: 0.89 - ETA: 0s - loss: 0.2384 - accuracy: 0.89 - 1s 141us/step - loss: 0.2384 - accuracy: 0.8947 - val_loss: 0.2098 - val_accuracy: 0.9197\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2264 - accuracy: 0.89 - ETA: 1s - loss: 0.2279 - accuracy: 0.89 - ETA: 1s - loss: 0.2223 - accuracy: 0.90 - ETA: 1s - loss: 0.2226 - accuracy: 0.90 - ETA: 0s - loss: 0.2311 - accuracy: 0.90 - ETA: 0s - loss: 0.2330 - accuracy: 0.89 - ETA: 0s - loss: 0.2329 - accuracy: 0.89 - ETA: 0s - loss: 0.2336 - accuracy: 0.89 - ETA: 0s - loss: 0.2361 - accuracy: 0.89 - ETA: 0s - loss: 0.2353 - accuracy: 0.89 - ETA: 0s - loss: 0.2356 - accuracy: 0.89 - ETA: 0s - loss: 0.2357 - accuracy: 0.89 - ETA: 0s - loss: 0.2372 - accuracy: 0.89 - ETA: 0s - loss: 0.2369 - accuracy: 0.89 - ETA: 0s - loss: 0.2381 - accuracy: 0.89 - ETA: 0s - loss: 0.2376 - accuracy: 0.89 - ETA: 0s - loss: 0.2378 - accuracy: 0.89 - ETA: 0s - loss: 0.2365 - accuracy: 0.89 - ETA: 0s - loss: 0.2366 - accuracy: 0.89 - ETA: 0s - loss: 0.2369 - accuracy: 0.89 - ETA: 0s - loss: 0.2364 - accuracy: 0.89 - ETA: 0s - loss: 0.2359 - accuracy: 0.89 - 1s 138us/step - loss: 0.2361 - accuracy: 0.8961 - val_loss: 0.2093 - val_accuracy: 0.9183\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2161 - accuracy: 0.91 - ETA: 1s - loss: 0.2406 - accuracy: 0.89 - ETA: 1s - loss: 0.2341 - accuracy: 0.90 - ETA: 1s - loss: 0.2333 - accuracy: 0.90 - ETA: 0s - loss: 0.2331 - accuracy: 0.90 - ETA: 0s - loss: 0.2336 - accuracy: 0.90 - ETA: 0s - loss: 0.2343 - accuracy: 0.89 - ETA: 0s - loss: 0.2332 - accuracy: 0.89 - ETA: 0s - loss: 0.2336 - accuracy: 0.89 - ETA: 0s - loss: 0.2343 - accuracy: 0.89 - ETA: 0s - loss: 0.2329 - accuracy: 0.89 - ETA: 0s - loss: 0.2338 - accuracy: 0.89 - ETA: 0s - loss: 0.2349 - accuracy: 0.89 - ETA: 0s - loss: 0.2345 - accuracy: 0.89 - ETA: 0s - loss: 0.2351 - accuracy: 0.89 - ETA: 0s - loss: 0.2340 - accuracy: 0.89 - ETA: 0s - loss: 0.2334 - accuracy: 0.89 - ETA: 0s - loss: 0.2334 - accuracy: 0.89 - ETA: 0s - loss: 0.2335 - accuracy: 0.89 - ETA: 0s - loss: 0.2335 - accuracy: 0.89 - ETA: 0s - loss: 0.2337 - accuracy: 0.89 - ETA: 0s - loss: 0.2337 - accuracy: 0.89 - 1s 137us/step - loss: 0.2336 - accuracy: 0.8976 - val_loss: 0.2065 - val_accuracy: 0.9206\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2187 - accuracy: 0.90 - ETA: 1s - loss: 0.2335 - accuracy: 0.90 - ETA: 1s - loss: 0.2251 - accuracy: 0.90 - ETA: 1s - loss: 0.2332 - accuracy: 0.90 - ETA: 1s - loss: 0.2314 - accuracy: 0.90 - ETA: 0s - loss: 0.2309 - accuracy: 0.90 - ETA: 0s - loss: 0.2311 - accuracy: 0.90 - ETA: 0s - loss: 0.2312 - accuracy: 0.90 - ETA: 0s - loss: 0.2292 - accuracy: 0.90 - ETA: 0s - loss: 0.2276 - accuracy: 0.90 - ETA: 0s - loss: 0.2274 - accuracy: 0.90 - ETA: 0s - loss: 0.2281 - accuracy: 0.90 - ETA: 0s - loss: 0.2283 - accuracy: 0.90 - ETA: 0s - loss: 0.2283 - accuracy: 0.90 - ETA: 0s - loss: 0.2295 - accuracy: 0.90 - ETA: 0s - loss: 0.2295 - accuracy: 0.90 - ETA: 0s - loss: 0.2302 - accuracy: 0.89 - ETA: 0s - loss: 0.2312 - accuracy: 0.89 - ETA: 0s - loss: 0.2310 - accuracy: 0.89 - ETA: 0s - loss: 0.2311 - accuracy: 0.89 - ETA: 0s - loss: 0.2307 - accuracy: 0.89 - ETA: 0s - loss: 0.2313 - accuracy: 0.89 - 1s 140us/step - loss: 0.2316 - accuracy: 0.8989 - val_loss: 0.2042 - val_accuracy: 0.9205\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2704 - accuracy: 0.89 - ETA: 1s - loss: 0.2403 - accuracy: 0.89 - ETA: 1s - loss: 0.2462 - accuracy: 0.88 - ETA: 1s - loss: 0.2397 - accuracy: 0.89 - ETA: 1s - loss: 0.2348 - accuracy: 0.89 - ETA: 0s - loss: 0.2336 - accuracy: 0.89 - ETA: 0s - loss: 0.2323 - accuracy: 0.89 - ETA: 0s - loss: 0.2329 - accuracy: 0.89 - ETA: 0s - loss: 0.2315 - accuracy: 0.89 - ETA: 0s - loss: 0.2299 - accuracy: 0.89 - ETA: 0s - loss: 0.2289 - accuracy: 0.89 - ETA: 0s - loss: 0.2295 - accuracy: 0.89 - ETA: 0s - loss: 0.2293 - accuracy: 0.89 - ETA: 0s - loss: 0.2293 - accuracy: 0.89 - ETA: 0s - loss: 0.2296 - accuracy: 0.89 - ETA: 0s - loss: 0.2295 - accuracy: 0.89 - ETA: 0s - loss: 0.2303 - accuracy: 0.89 - ETA: 0s - loss: 0.2300 - accuracy: 0.89 - ETA: 0s - loss: 0.2308 - accuracy: 0.89 - ETA: 0s - loss: 0.2307 - accuracy: 0.89 - ETA: 0s - loss: 0.2299 - accuracy: 0.89 - ETA: 0s - loss: 0.2300 - accuracy: 0.89 - 1s 140us/step - loss: 0.2301 - accuracy: 0.8982 - val_loss: 0.2037 - val_accuracy: 0.9208\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2214 - accuracy: 0.89 - ETA: 1s - loss: 0.2459 - accuracy: 0.88 - ETA: 1s - loss: 0.2395 - accuracy: 0.89 - ETA: 1s - loss: 0.2342 - accuracy: 0.89 - ETA: 1s - loss: 0.2329 - accuracy: 0.89 - ETA: 1s - loss: 0.2320 - accuracy: 0.89 - ETA: 0s - loss: 0.2330 - accuracy: 0.89 - ETA: 0s - loss: 0.2339 - accuracy: 0.89 - ETA: 0s - loss: 0.2340 - accuracy: 0.89 - ETA: 0s - loss: 0.2346 - accuracy: 0.89 - ETA: 0s - loss: 0.2342 - accuracy: 0.89 - ETA: 0s - loss: 0.2332 - accuracy: 0.89 - ETA: 0s - loss: 0.2320 - accuracy: 0.89 - ETA: 0s - loss: 0.2316 - accuracy: 0.89 - ETA: 0s - loss: 0.2319 - accuracy: 0.89 - ETA: 0s - loss: 0.2321 - accuracy: 0.89 - ETA: 0s - loss: 0.2328 - accuracy: 0.89 - ETA: 0s - loss: 0.2322 - accuracy: 0.89 - ETA: 0s - loss: 0.2324 - accuracy: 0.89 - ETA: 0s - loss: 0.2324 - accuracy: 0.89 - ETA: 0s - loss: 0.2321 - accuracy: 0.89 - ETA: 0s - loss: 0.2323 - accuracy: 0.89 - ETA: 0s - loss: 0.2321 - accuracy: 0.89 - 1s 142us/step - loss: 0.2321 - accuracy: 0.8969 - val_loss: 0.2018 - val_accuracy: 0.9219\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2461 - accuracy: 0.88 - ETA: 1s - loss: 0.2277 - accuracy: 0.89 - ETA: 1s - loss: 0.2256 - accuracy: 0.90 - ETA: 1s - loss: 0.2304 - accuracy: 0.89 - ETA: 0s - loss: 0.2294 - accuracy: 0.89 - ETA: 0s - loss: 0.2307 - accuracy: 0.89 - ETA: 0s - loss: 0.2302 - accuracy: 0.89 - ETA: 0s - loss: 0.2290 - accuracy: 0.89 - ETA: 0s - loss: 0.2292 - accuracy: 0.89 - ETA: 0s - loss: 0.2309 - accuracy: 0.89 - ETA: 0s - loss: 0.2299 - accuracy: 0.89 - ETA: 0s - loss: 0.2295 - accuracy: 0.90 - ETA: 0s - loss: 0.2292 - accuracy: 0.90 - ETA: 0s - loss: 0.2300 - accuracy: 0.89 - ETA: 0s - loss: 0.2304 - accuracy: 0.89 - ETA: 0s - loss: 0.2311 - accuracy: 0.89 - ETA: 0s - loss: 0.2303 - accuracy: 0.89 - ETA: 0s - loss: 0.2302 - accuracy: 0.89 - ETA: 0s - loss: 0.2296 - accuracy: 0.89 - ETA: 0s - loss: 0.2292 - accuracy: 0.89 - ETA: 0s - loss: 0.2289 - accuracy: 0.89 - ETA: 0s - loss: 0.2286 - accuracy: 0.89 - ETA: 0s - loss: 0.2285 - accuracy: 0.90 - 1s 140us/step - loss: 0.2285 - accuracy: 0.8999 - val_loss: 0.1992 - val_accuracy: 0.9229\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2348 - accuracy: 0.88 - ETA: 1s - loss: 0.2220 - accuracy: 0.90 - ETA: 1s - loss: 0.2239 - accuracy: 0.90 - ETA: 1s - loss: 0.2198 - accuracy: 0.90 - ETA: 1s - loss: 0.2228 - accuracy: 0.90 - ETA: 1s - loss: 0.2225 - accuracy: 0.90 - ETA: 0s - loss: 0.2227 - accuracy: 0.90 - ETA: 0s - loss: 0.2238 - accuracy: 0.90 - ETA: 0s - loss: 0.2251 - accuracy: 0.90 - ETA: 0s - loss: 0.2257 - accuracy: 0.90 - ETA: 0s - loss: 0.2246 - accuracy: 0.90 - ETA: 0s - loss: 0.2234 - accuracy: 0.90 - ETA: 0s - loss: 0.2236 - accuracy: 0.90 - ETA: 0s - loss: 0.2237 - accuracy: 0.90 - ETA: 0s - loss: 0.2247 - accuracy: 0.90 - ETA: 0s - loss: 0.2250 - accuracy: 0.90 - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - ETA: 0s - loss: 0.2244 - accuracy: 0.90 - ETA: 0s - loss: 0.2243 - accuracy: 0.90 - ETA: 0s - loss: 0.2247 - accuracy: 0.90 - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - ETA: 0s - loss: 0.2242 - accuracy: 0.90 - ETA: 0s - loss: 0.2242 - accuracy: 0.90 - 1s 144us/step - loss: 0.2240 - accuracy: 0.9020 - val_loss: 0.1975 - val_accuracy: 0.9234\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2074 - accuracy: 0.90 - ETA: 1s - loss: 0.2318 - accuracy: 0.89 - ETA: 1s - loss: 0.2234 - accuracy: 0.90 - ETA: 1s - loss: 0.2237 - accuracy: 0.90 - ETA: 0s - loss: 0.2242 - accuracy: 0.90 - ETA: 0s - loss: 0.2260 - accuracy: 0.90 - ETA: 0s - loss: 0.2250 - accuracy: 0.90 - ETA: 0s - loss: 0.2259 - accuracy: 0.90 - ETA: 0s - loss: 0.2251 - accuracy: 0.90 - ETA: 0s - loss: 0.2251 - accuracy: 0.90 - ETA: 0s - loss: 0.2250 - accuracy: 0.90 - ETA: 0s - loss: 0.2238 - accuracy: 0.90 - ETA: 0s - loss: 0.2239 - accuracy: 0.90 - ETA: 0s - loss: 0.2240 - accuracy: 0.90 - ETA: 0s - loss: 0.2241 - accuracy: 0.90 - ETA: 0s - loss: 0.2233 - accuracy: 0.90 - ETA: 0s - loss: 0.2231 - accuracy: 0.90 - ETA: 0s - loss: 0.2230 - accuracy: 0.90 - ETA: 0s - loss: 0.2230 - accuracy: 0.90 - ETA: 0s - loss: 0.2233 - accuracy: 0.90 - ETA: 0s - loss: 0.2238 - accuracy: 0.90 - ETA: 0s - loss: 0.2236 - accuracy: 0.90 - 1s 137us/step - loss: 0.2235 - accuracy: 0.9018 - val_loss: 0.1964 - val_accuracy: 0.9225\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 2s - loss: 0.2298 - accuracy: 0.88 - ETA: 1s - loss: 0.2221 - accuracy: 0.89 - ETA: 1s - loss: 0.2218 - accuracy: 0.89 - ETA: 1s - loss: 0.2156 - accuracy: 0.90 - ETA: 1s - loss: 0.2188 - accuracy: 0.90 - ETA: 1s - loss: 0.2201 - accuracy: 0.90 - ETA: 0s - loss: 0.2217 - accuracy: 0.90 - ETA: 0s - loss: 0.2202 - accuracy: 0.90 - ETA: 0s - loss: 0.2216 - accuracy: 0.90 - ETA: 0s - loss: 0.2217 - accuracy: 0.90 - ETA: 0s - loss: 0.2204 - accuracy: 0.90 - ETA: 0s - loss: 0.2200 - accuracy: 0.90 - ETA: 0s - loss: 0.2201 - accuracy: 0.90 - ETA: 0s - loss: 0.2197 - accuracy: 0.90 - ETA: 0s - loss: 0.2204 - accuracy: 0.90 - ETA: 0s - loss: 0.2197 - accuracy: 0.90 - ETA: 0s - loss: 0.2195 - accuracy: 0.90 - ETA: 0s - loss: 0.2199 - accuracy: 0.90 - ETA: 0s - loss: 0.2208 - accuracy: 0.90 - ETA: 0s - loss: 0.2209 - accuracy: 0.90 - ETA: 0s - loss: 0.2213 - accuracy: 0.90 - ETA: 0s - loss: 0.2205 - accuracy: 0.90 - 1s 138us/step - loss: 0.2207 - accuracy: 0.9024 - val_loss: 0.1951 - val_accuracy: 0.9222\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2162 - accuracy: 0.91 - ETA: 1s - loss: 0.2349 - accuracy: 0.89 - ETA: 1s - loss: 0.2268 - accuracy: 0.89 - ETA: 1s - loss: 0.2243 - accuracy: 0.90 - ETA: 0s - loss: 0.2199 - accuracy: 0.90 - ETA: 0s - loss: 0.2212 - accuracy: 0.90 - ETA: 0s - loss: 0.2216 - accuracy: 0.90 - ETA: 0s - loss: 0.2204 - accuracy: 0.90 - ETA: 0s - loss: 0.2216 - accuracy: 0.90 - ETA: 0s - loss: 0.2225 - accuracy: 0.90 - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - ETA: 0s - loss: 0.2228 - accuracy: 0.90 - ETA: 0s - loss: 0.2223 - accuracy: 0.90 - ETA: 0s - loss: 0.2229 - accuracy: 0.90 - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - ETA: 0s - loss: 0.2227 - accuracy: 0.90 - ETA: 0s - loss: 0.2224 - accuracy: 0.90 - ETA: 0s - loss: 0.2227 - accuracy: 0.90 - ETA: 0s - loss: 0.2220 - accuracy: 0.90 - ETA: 0s - loss: 0.2218 - accuracy: 0.90 - ETA: 0s - loss: 0.2214 - accuracy: 0.90 - 1s 143us/step - loss: 0.2209 - accuracy: 0.9026 - val_loss: 0.1935 - val_accuracy: 0.9249\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2262 - accuracy: 0.89 - ETA: 1s - loss: 0.2169 - accuracy: 0.90 - ETA: 1s - loss: 0.2234 - accuracy: 0.90 - ETA: 0s - loss: 0.2265 - accuracy: 0.90 - ETA: 0s - loss: 0.2233 - accuracy: 0.90 - ETA: 0s - loss: 0.2224 - accuracy: 0.90 - ETA: 0s - loss: 0.2215 - accuracy: 0.90 - ETA: 0s - loss: 0.2222 - accuracy: 0.90 - ETA: 0s - loss: 0.2218 - accuracy: 0.90 - ETA: 0s - loss: 0.2224 - accuracy: 0.90 - ETA: 0s - loss: 0.2207 - accuracy: 0.90 - ETA: 0s - loss: 0.2203 - accuracy: 0.90 - ETA: 0s - loss: 0.2194 - accuracy: 0.90 - ETA: 0s - loss: 0.2195 - accuracy: 0.90 - ETA: 0s - loss: 0.2193 - accuracy: 0.90 - ETA: 0s - loss: 0.2195 - accuracy: 0.90 - ETA: 0s - loss: 0.2193 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2196 - accuracy: 0.90 - ETA: 0s - loss: 0.2191 - accuracy: 0.90 - 1s 138us/step - loss: 0.2195 - accuracy: 0.9035 - val_loss: 0.1915 - val_accuracy: 0.9254\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2223 - accuracy: 0.89 - ETA: 1s - loss: 0.2223 - accuracy: 0.90 - ETA: 1s - loss: 0.2155 - accuracy: 0.90 - ETA: 1s - loss: 0.2184 - accuracy: 0.90 - ETA: 1s - loss: 0.2205 - accuracy: 0.90 - ETA: 0s - loss: 0.2229 - accuracy: 0.90 - ETA: 0s - loss: 0.2235 - accuracy: 0.89 - ETA: 0s - loss: 0.2220 - accuracy: 0.90 - ETA: 0s - loss: 0.2211 - accuracy: 0.90 - ETA: 0s - loss: 0.2203 - accuracy: 0.90 - ETA: 0s - loss: 0.2198 - accuracy: 0.90 - ETA: 0s - loss: 0.2188 - accuracy: 0.90 - ETA: 0s - loss: 0.2183 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2190 - accuracy: 0.90 - ETA: 0s - loss: 0.2186 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2183 - accuracy: 0.90 - ETA: 0s - loss: 0.2179 - accuracy: 0.90 - ETA: 0s - loss: 0.2175 - accuracy: 0.90 - ETA: 0s - loss: 0.2174 - accuracy: 0.90 - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - ETA: 0s - loss: 0.2170 - accuracy: 0.90 - 1s 141us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.1902 - val_accuracy: 0.9249\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2438 - accuracy: 0.89 - ETA: 1s - loss: 0.2229 - accuracy: 0.90 - ETA: 1s - loss: 0.2169 - accuracy: 0.90 - ETA: 1s - loss: 0.2148 - accuracy: 0.90 - ETA: 1s - loss: 0.2118 - accuracy: 0.90 - ETA: 0s - loss: 0.2130 - accuracy: 0.90 - ETA: 0s - loss: 0.2126 - accuracy: 0.90 - ETA: 0s - loss: 0.2131 - accuracy: 0.90 - ETA: 0s - loss: 0.2134 - accuracy: 0.90 - ETA: 0s - loss: 0.2143 - accuracy: 0.90 - ETA: 0s - loss: 0.2166 - accuracy: 0.90 - ETA: 0s - loss: 0.2158 - accuracy: 0.90 - ETA: 0s - loss: 0.2157 - accuracy: 0.90 - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - ETA: 0s - loss: 0.2160 - accuracy: 0.90 - ETA: 0s - loss: 0.2155 - accuracy: 0.90 - ETA: 0s - loss: 0.2159 - accuracy: 0.90 - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - ETA: 0s - loss: 0.2166 - accuracy: 0.90 - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - ETA: 0s - loss: 0.2170 - accuracy: 0.90 - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - 1s 143us/step - loss: 0.2167 - accuracy: 0.9050 - val_loss: 0.1897 - val_accuracy: 0.9256\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1945 - accuracy: 0.91 - ETA: 1s - loss: 0.2036 - accuracy: 0.91 - ETA: 1s - loss: 0.2080 - accuracy: 0.91 - ETA: 1s - loss: 0.2120 - accuracy: 0.90 - ETA: 0s - loss: 0.2131 - accuracy: 0.90 - ETA: 0s - loss: 0.2163 - accuracy: 0.90 - ETA: 0s - loss: 0.2168 - accuracy: 0.90 - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - ETA: 0s - loss: 0.2168 - accuracy: 0.90 - ETA: 0s - loss: 0.2181 - accuracy: 0.90 - ETA: 0s - loss: 0.2182 - accuracy: 0.90 - ETA: 0s - loss: 0.2185 - accuracy: 0.90 - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - ETA: 0s - loss: 0.2190 - accuracy: 0.90 - ETA: 0s - loss: 0.2199 - accuracy: 0.90 - ETA: 0s - loss: 0.2206 - accuracy: 0.90 - ETA: 0s - loss: 0.2196 - accuracy: 0.90 - ETA: 0s - loss: 0.2187 - accuracy: 0.90 - ETA: 0s - loss: 0.2187 - accuracy: 0.90 - ETA: 0s - loss: 0.2179 - accuracy: 0.90 - ETA: 0s - loss: 0.2187 - accuracy: 0.90 - ETA: 0s - loss: 0.2184 - accuracy: 0.90 - 1s 140us/step - loss: 0.2181 - accuracy: 0.9031 - val_loss: 0.1869 - val_accuracy: 0.9272\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2190 - accuracy: 0.90 - ETA: 1s - loss: 0.2120 - accuracy: 0.90 - ETA: 1s - loss: 0.2106 - accuracy: 0.90 - ETA: 0s - loss: 0.2119 - accuracy: 0.90 - ETA: 0s - loss: 0.2142 - accuracy: 0.90 - ETA: 0s - loss: 0.2122 - accuracy: 0.90 - ETA: 0s - loss: 0.2117 - accuracy: 0.90 - ETA: 0s - loss: 0.2127 - accuracy: 0.90 - ETA: 0s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2124 - accuracy: 0.90 - ETA: 0s - loss: 0.2143 - accuracy: 0.90 - ETA: 0s - loss: 0.2154 - accuracy: 0.90 - ETA: 0s - loss: 0.2147 - accuracy: 0.90 - ETA: 0s - loss: 0.2145 - accuracy: 0.90 - ETA: 0s - loss: 0.2145 - accuracy: 0.90 - ETA: 0s - loss: 0.2141 - accuracy: 0.90 - ETA: 0s - loss: 0.2128 - accuracy: 0.90 - ETA: 0s - loss: 0.2126 - accuracy: 0.90 - ETA: 0s - loss: 0.2136 - accuracy: 0.90 - ETA: 0s - loss: 0.2145 - accuracy: 0.90 - ETA: 0s - loss: 0.2143 - accuracy: 0.90 - ETA: 0s - loss: 0.2135 - accuracy: 0.90 - 1s 137us/step - loss: 0.2136 - accuracy: 0.9069 - val_loss: 0.1857 - val_accuracy: 0.9279\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2359 - accuracy: 0.89 - ETA: 1s - loss: 0.2222 - accuracy: 0.90 - ETA: 1s - loss: 0.2172 - accuracy: 0.90 - ETA: 1s - loss: 0.2108 - accuracy: 0.90 - ETA: 1s - loss: 0.2090 - accuracy: 0.90 - ETA: 1s - loss: 0.2093 - accuracy: 0.90 - ETA: 1s - loss: 0.2092 - accuracy: 0.90 - ETA: 0s - loss: 0.2083 - accuracy: 0.91 - ETA: 0s - loss: 0.2089 - accuracy: 0.91 - ETA: 0s - loss: 0.2087 - accuracy: 0.91 - ETA: 0s - loss: 0.2078 - accuracy: 0.91 - ETA: 0s - loss: 0.2092 - accuracy: 0.90 - ETA: 0s - loss: 0.2086 - accuracy: 0.90 - ETA: 0s - loss: 0.2099 - accuracy: 0.90 - ETA: 0s - loss: 0.2107 - accuracy: 0.90 - ETA: 0s - loss: 0.2115 - accuracy: 0.90 - ETA: 0s - loss: 0.2119 - accuracy: 0.90 - ETA: 0s - loss: 0.2122 - accuracy: 0.90 - ETA: 0s - loss: 0.2127 - accuracy: 0.90 - ETA: 0s - loss: 0.2128 - accuracy: 0.90 - ETA: 0s - loss: 0.2129 - accuracy: 0.90 - ETA: 0s - loss: 0.2131 - accuracy: 0.90 - 1s 141us/step - loss: 0.2128 - accuracy: 0.9064 - val_loss: 0.1870 - val_accuracy: 0.9248\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2355 - accuracy: 0.90 - ETA: 1s - loss: 0.2284 - accuracy: 0.89 - ETA: 1s - loss: 0.2205 - accuracy: 0.90 - ETA: 1s - loss: 0.2285 - accuracy: 0.89 - ETA: 0s - loss: 0.2229 - accuracy: 0.90 - ETA: 0s - loss: 0.2215 - accuracy: 0.90 - ETA: 0s - loss: 0.2207 - accuracy: 0.90 - ETA: 0s - loss: 0.2203 - accuracy: 0.90 - ETA: 0s - loss: 0.2185 - accuracy: 0.90 - ETA: 0s - loss: 0.2186 - accuracy: 0.90 - ETA: 0s - loss: 0.2184 - accuracy: 0.90 - ETA: 0s - loss: 0.2168 - accuracy: 0.90 - ETA: 0s - loss: 0.2174 - accuracy: 0.90 - ETA: 0s - loss: 0.2167 - accuracy: 0.90 - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - ETA: 0s - loss: 0.2171 - accuracy: 0.90 - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - ETA: 0s - loss: 0.2162 - accuracy: 0.90 - ETA: 0s - loss: 0.2156 - accuracy: 0.90 - ETA: 0s - loss: 0.2150 - accuracy: 0.90 - ETA: 0s - loss: 0.2153 - accuracy: 0.90 - 1s 134us/step - loss: 0.2153 - accuracy: 0.9038 - val_loss: 0.1833 - val_accuracy: 0.9284\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2326 - accuracy: 0.89 - ETA: 1s - loss: 0.2210 - accuracy: 0.89 - ETA: 1s - loss: 0.2150 - accuracy: 0.90 - ETA: 1s - loss: 0.2131 - accuracy: 0.90 - ETA: 0s - loss: 0.2148 - accuracy: 0.90 - ETA: 0s - loss: 0.2107 - accuracy: 0.90 - ETA: 0s - loss: 0.2119 - accuracy: 0.90 - ETA: 0s - loss: 0.2116 - accuracy: 0.90 - ETA: 0s - loss: 0.2126 - accuracy: 0.90 - ETA: 0s - loss: 0.2125 - accuracy: 0.90 - ETA: 0s - loss: 0.2108 - accuracy: 0.90 - ETA: 0s - loss: 0.2101 - accuracy: 0.90 - ETA: 0s - loss: 0.2100 - accuracy: 0.90 - ETA: 0s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2105 - accuracy: 0.90 - ETA: 0s - loss: 0.2094 - accuracy: 0.90 - ETA: 0s - loss: 0.2086 - accuracy: 0.90 - ETA: 0s - loss: 0.2082 - accuracy: 0.90 - ETA: 0s - loss: 0.2084 - accuracy: 0.90 - ETA: 0s - loss: 0.2085 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2082 - accuracy: 0.90 - 1s 139us/step - loss: 0.2080 - accuracy: 0.9079 - val_loss: 0.1828 - val_accuracy: 0.9288\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1741 - accuracy: 0.92 - ETA: 1s - loss: 0.1972 - accuracy: 0.91 - ETA: 1s - loss: 0.2094 - accuracy: 0.90 - ETA: 1s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2081 - accuracy: 0.90 - ETA: 0s - loss: 0.2090 - accuracy: 0.90 - ETA: 0s - loss: 0.2097 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2071 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2085 - accuracy: 0.90 - ETA: 0s - loss: 0.2096 - accuracy: 0.90 - ETA: 0s - loss: 0.2107 - accuracy: 0.90 - ETA: 0s - loss: 0.2103 - accuracy: 0.90 - ETA: 0s - loss: 0.2096 - accuracy: 0.90 - ETA: 0s - loss: 0.2092 - accuracy: 0.90 - ETA: 0s - loss: 0.2094 - accuracy: 0.90 - ETA: 0s - loss: 0.2077 - accuracy: 0.90 - ETA: 0s - loss: 0.2085 - accuracy: 0.90 - ETA: 0s - loss: 0.2081 - accuracy: 0.90 - ETA: 0s - loss: 0.2079 - accuracy: 0.90 - ETA: 0s - loss: 0.2072 - accuracy: 0.90 - 1s 140us/step - loss: 0.2084 - accuracy: 0.9084 - val_loss: 0.1801 - val_accuracy: 0.9282\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2167 - accuracy: 0.89 - ETA: 1s - loss: 0.2152 - accuracy: 0.90 - ETA: 1s - loss: 0.2111 - accuracy: 0.90 - ETA: 0s - loss: 0.2111 - accuracy: 0.90 - ETA: 0s - loss: 0.2106 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2084 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2123 - accuracy: 0.90 - ETA: 0s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2107 - accuracy: 0.90 - ETA: 0s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2104 - accuracy: 0.90 - ETA: 0s - loss: 0.2091 - accuracy: 0.90 - ETA: 0s - loss: 0.2086 - accuracy: 0.90 - ETA: 0s - loss: 0.2087 - accuracy: 0.90 - ETA: 0s - loss: 0.2084 - accuracy: 0.90 - ETA: 0s - loss: 0.2089 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2094 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2092 - accuracy: 0.90 - 1s 137us/step - loss: 0.2088 - accuracy: 0.9067 - val_loss: 0.1799 - val_accuracy: 0.9297\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1975 - accuracy: 0.90 - ETA: 1s - loss: 0.2135 - accuracy: 0.90 - ETA: 1s - loss: 0.2168 - accuracy: 0.90 - ETA: 1s - loss: 0.2111 - accuracy: 0.90 - ETA: 1s - loss: 0.2088 - accuracy: 0.90 - ETA: 0s - loss: 0.2087 - accuracy: 0.90 - ETA: 0s - loss: 0.2113 - accuracy: 0.90 - ETA: 0s - loss: 0.2116 - accuracy: 0.90 - ETA: 0s - loss: 0.2116 - accuracy: 0.90 - ETA: 0s - loss: 0.2105 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2095 - accuracy: 0.90 - ETA: 0s - loss: 0.2089 - accuracy: 0.90 - ETA: 0s - loss: 0.2091 - accuracy: 0.90 - ETA: 0s - loss: 0.2087 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2078 - accuracy: 0.90 - ETA: 0s - loss: 0.2078 - accuracy: 0.90 - ETA: 0s - loss: 0.2083 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2087 - accuracy: 0.90 - ETA: 0s - loss: 0.2085 - accuracy: 0.90 - 1s 141us/step - loss: 0.2088 - accuracy: 0.9077 - val_loss: 0.1796 - val_accuracy: 0.9257\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2028 - accuracy: 0.91 - ETA: 1s - loss: 0.1983 - accuracy: 0.91 - ETA: 1s - loss: 0.1968 - accuracy: 0.91 - ETA: 0s - loss: 0.1997 - accuracy: 0.91 - ETA: 0s - loss: 0.2002 - accuracy: 0.91 - ETA: 0s - loss: 0.2010 - accuracy: 0.90 - ETA: 0s - loss: 0.2011 - accuracy: 0.90 - ETA: 0s - loss: 0.2024 - accuracy: 0.90 - ETA: 0s - loss: 0.2027 - accuracy: 0.90 - ETA: 0s - loss: 0.1999 - accuracy: 0.91 - ETA: 0s - loss: 0.2017 - accuracy: 0.91 - ETA: 0s - loss: 0.2024 - accuracy: 0.91 - ETA: 0s - loss: 0.2021 - accuracy: 0.91 - ETA: 0s - loss: 0.2017 - accuracy: 0.91 - ETA: 0s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.2016 - accuracy: 0.91 - ETA: 0s - loss: 0.2023 - accuracy: 0.91 - ETA: 0s - loss: 0.2035 - accuracy: 0.90 - ETA: 0s - loss: 0.2043 - accuracy: 0.90 - ETA: 0s - loss: 0.2038 - accuracy: 0.90 - ETA: 0s - loss: 0.2039 - accuracy: 0.90 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - 1s 139us/step - loss: 0.2039 - accuracy: 0.9096 - val_loss: 0.1772 - val_accuracy: 0.9290\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1896 - accuracy: 0.93 - ETA: 1s - loss: 0.1854 - accuracy: 0.91 - ETA: 1s - loss: 0.2001 - accuracy: 0.91 - ETA: 1s - loss: 0.2033 - accuracy: 0.91 - ETA: 1s - loss: 0.2061 - accuracy: 0.90 - ETA: 0s - loss: 0.2028 - accuracy: 0.91 - ETA: 0s - loss: 0.2028 - accuracy: 0.91 - ETA: 0s - loss: 0.2051 - accuracy: 0.90 - ETA: 0s - loss: 0.2054 - accuracy: 0.90 - ETA: 0s - loss: 0.2049 - accuracy: 0.90 - ETA: 0s - loss: 0.2053 - accuracy: 0.91 - ETA: 0s - loss: 0.2058 - accuracy: 0.90 - ETA: 0s - loss: 0.2067 - accuracy: 0.90 - ETA: 0s - loss: 0.2072 - accuracy: 0.90 - ETA: 0s - loss: 0.2063 - accuracy: 0.90 - ETA: 0s - loss: 0.2054 - accuracy: 0.91 - ETA: 0s - loss: 0.2058 - accuracy: 0.90 - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - ETA: 0s - loss: 0.2072 - accuracy: 0.90 - ETA: 0s - loss: 0.2074 - accuracy: 0.90 - ETA: 0s - loss: 0.2071 - accuracy: 0.90 - ETA: 0s - loss: 0.2070 - accuracy: 0.90 - 1s 137us/step - loss: 0.2066 - accuracy: 0.9087 - val_loss: 0.1760 - val_accuracy: 0.9297\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2168 - accuracy: 0.89 - ETA: 1s - loss: 0.2142 - accuracy: 0.90 - ETA: 1s - loss: 0.2101 - accuracy: 0.90 - ETA: 1s - loss: 0.2097 - accuracy: 0.90 - ETA: 1s - loss: 0.2117 - accuracy: 0.90 - ETA: 1s - loss: 0.2128 - accuracy: 0.90 - ETA: 0s - loss: 0.2090 - accuracy: 0.90 - ETA: 0s - loss: 0.2072 - accuracy: 0.90 - ETA: 0s - loss: 0.2082 - accuracy: 0.90 - ETA: 0s - loss: 0.2081 - accuracy: 0.90 - ETA: 0s - loss: 0.2080 - accuracy: 0.90 - ETA: 0s - loss: 0.2070 - accuracy: 0.90 - ETA: 0s - loss: 0.2058 - accuracy: 0.90 - ETA: 0s - loss: 0.2054 - accuracy: 0.90 - ETA: 0s - loss: 0.2047 - accuracy: 0.90 - ETA: 0s - loss: 0.2032 - accuracy: 0.90 - ETA: 0s - loss: 0.2031 - accuracy: 0.90 - ETA: 0s - loss: 0.2025 - accuracy: 0.91 - ETA: 0s - loss: 0.2026 - accuracy: 0.91 - ETA: 0s - loss: 0.2030 - accuracy: 0.91 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - ETA: 0s - loss: 0.2048 - accuracy: 0.90 - ETA: 0s - loss: 0.2041 - accuracy: 0.90 - 1s 142us/step - loss: 0.2044 - accuracy: 0.9093 - val_loss: 0.1757 - val_accuracy: 0.9297\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2284 - accuracy: 0.89 - ETA: 1s - loss: 0.2050 - accuracy: 0.90 - ETA: 1s - loss: 0.2025 - accuracy: 0.90 - ETA: 1s - loss: 0.2030 - accuracy: 0.90 - ETA: 0s - loss: 0.2010 - accuracy: 0.90 - ETA: 0s - loss: 0.2031 - accuracy: 0.90 - ETA: 0s - loss: 0.2026 - accuracy: 0.90 - ETA: 0s - loss: 0.2048 - accuracy: 0.90 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - ETA: 0s - loss: 0.2022 - accuracy: 0.90 - ETA: 0s - loss: 0.2019 - accuracy: 0.90 - ETA: 0s - loss: 0.2003 - accuracy: 0.91 - ETA: 0s - loss: 0.2007 - accuracy: 0.91 - ETA: 0s - loss: 0.2011 - accuracy: 0.91 - ETA: 0s - loss: 0.2016 - accuracy: 0.90 - ETA: 0s - loss: 0.2018 - accuracy: 0.90 - ETA: 0s - loss: 0.2005 - accuracy: 0.91 - ETA: 0s - loss: 0.2009 - accuracy: 0.91 - ETA: 0s - loss: 0.2022 - accuracy: 0.90 - ETA: 0s - loss: 0.2020 - accuracy: 0.90 - ETA: 0s - loss: 0.2018 - accuracy: 0.91 - 1s 136us/step - loss: 0.2014 - accuracy: 0.9104 - val_loss: 0.1736 - val_accuracy: 0.9296\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1939 - accuracy: 0.91 - ETA: 1s - loss: 0.1926 - accuracy: 0.91 - ETA: 1s - loss: 0.1991 - accuracy: 0.91 - ETA: 0s - loss: 0.2013 - accuracy: 0.91 - ETA: 0s - loss: 0.2028 - accuracy: 0.91 - ETA: 0s - loss: 0.2043 - accuracy: 0.90 - ETA: 0s - loss: 0.2051 - accuracy: 0.90 - ETA: 0s - loss: 0.2056 - accuracy: 0.90 - ETA: 0s - loss: 0.2057 - accuracy: 0.90 - ETA: 0s - loss: 0.2051 - accuracy: 0.90 - ETA: 0s - loss: 0.2042 - accuracy: 0.90 - ETA: 0s - loss: 0.2034 - accuracy: 0.90 - ETA: 0s - loss: 0.2032 - accuracy: 0.90 - ETA: 0s - loss: 0.2032 - accuracy: 0.90 - ETA: 0s - loss: 0.2014 - accuracy: 0.90 - ETA: 0s - loss: 0.2005 - accuracy: 0.91 - ETA: 0s - loss: 0.2007 - accuracy: 0.91 - ETA: 0s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.2016 - accuracy: 0.91 - ETA: 0s - loss: 0.2017 - accuracy: 0.91 - ETA: 0s - loss: 0.2022 - accuracy: 0.90 - 1s 136us/step - loss: 0.2020 - accuracy: 0.9100 - val_loss: 0.1723 - val_accuracy: 0.9307\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2038 - accuracy: 0.92 - ETA: 1s - loss: 0.2219 - accuracy: 0.90 - ETA: 1s - loss: 0.2107 - accuracy: 0.90 - ETA: 1s - loss: 0.2034 - accuracy: 0.91 - ETA: 0s - loss: 0.2029 - accuracy: 0.91 - ETA: 0s - loss: 0.2007 - accuracy: 0.91 - ETA: 0s - loss: 0.1997 - accuracy: 0.91 - ETA: 0s - loss: 0.1993 - accuracy: 0.91 - ETA: 0s - loss: 0.2004 - accuracy: 0.91 - ETA: 0s - loss: 0.2007 - accuracy: 0.91 - ETA: 0s - loss: 0.2004 - accuracy: 0.91 - ETA: 0s - loss: 0.2017 - accuracy: 0.91 - ETA: 0s - loss: 0.2012 - accuracy: 0.91 - ETA: 0s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.2012 - accuracy: 0.91 - ETA: 0s - loss: 0.2010 - accuracy: 0.91 - ETA: 0s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.2011 - accuracy: 0.91 - ETA: 0s - loss: 0.2004 - accuracy: 0.91 - ETA: 0s - loss: 0.1997 - accuracy: 0.91 - ETA: 0s - loss: 0.2002 - accuracy: 0.91 - ETA: 0s - loss: 0.2009 - accuracy: 0.91 - 1s 140us/step - loss: 0.2011 - accuracy: 0.9116 - val_loss: 0.1722 - val_accuracy: 0.9300\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1930 - accuracy: 0.91 - ETA: 1s - loss: 0.2015 - accuracy: 0.91 - ETA: 1s - loss: 0.1982 - accuracy: 0.91 - ETA: 1s - loss: 0.2001 - accuracy: 0.91 - ETA: 1s - loss: 0.2005 - accuracy: 0.91 - ETA: 1s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.1996 - accuracy: 0.91 - ETA: 0s - loss: 0.2005 - accuracy: 0.91 - ETA: 0s - loss: 0.2010 - accuracy: 0.91 - ETA: 0s - loss: 0.2022 - accuracy: 0.91 - ETA: 0s - loss: 0.2044 - accuracy: 0.90 - ETA: 0s - loss: 0.2047 - accuracy: 0.90 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - ETA: 0s - loss: 0.2032 - accuracy: 0.90 - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - ETA: 0s - loss: 0.2039 - accuracy: 0.90 - ETA: 0s - loss: 0.2042 - accuracy: 0.90 - ETA: 0s - loss: 0.2036 - accuracy: 0.90 - ETA: 0s - loss: 0.2030 - accuracy: 0.90 - ETA: 0s - loss: 0.2023 - accuracy: 0.90 - ETA: 0s - loss: 0.2021 - accuracy: 0.90 - ETA: 0s - loss: 0.2025 - accuracy: 0.90 - ETA: 0s - loss: 0.2023 - accuracy: 0.90 - 1s 140us/step - loss: 0.2022 - accuracy: 0.9099 - val_loss: 0.1710 - val_accuracy: 0.9296\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1793 - accuracy: 0.92 - ETA: 1s - loss: 0.1855 - accuracy: 0.92 - ETA: 1s - loss: 0.1933 - accuracy: 0.91 - ETA: 1s - loss: 0.1894 - accuracy: 0.92 - ETA: 0s - loss: 0.1922 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1977 - accuracy: 0.91 - ETA: 0s - loss: 0.1967 - accuracy: 0.91 - ETA: 0s - loss: 0.1977 - accuracy: 0.91 - ETA: 0s - loss: 0.1978 - accuracy: 0.91 - ETA: 0s - loss: 0.1963 - accuracy: 0.91 - ETA: 0s - loss: 0.1965 - accuracy: 0.91 - ETA: 0s - loss: 0.1956 - accuracy: 0.91 - ETA: 0s - loss: 0.1952 - accuracy: 0.91 - ETA: 0s - loss: 0.1954 - accuracy: 0.91 - ETA: 0s - loss: 0.1952 - accuracy: 0.91 - ETA: 0s - loss: 0.1957 - accuracy: 0.91 - ETA: 0s - loss: 0.1957 - accuracy: 0.91 - ETA: 0s - loss: 0.1954 - accuracy: 0.91 - ETA: 0s - loss: 0.1956 - accuracy: 0.91 - ETA: 0s - loss: 0.1959 - accuracy: 0.91 - ETA: 0s - loss: 0.1953 - accuracy: 0.91 - ETA: 0s - loss: 0.1955 - accuracy: 0.91 - 1s 141us/step - loss: 0.1957 - accuracy: 0.9133 - val_loss: 0.1704 - val_accuracy: 0.9312\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2082 - accuracy: 0.90 - ETA: 1s - loss: 0.2027 - accuracy: 0.90 - ETA: 1s - loss: 0.1987 - accuracy: 0.90 - ETA: 1s - loss: 0.1963 - accuracy: 0.90 - ETA: 1s - loss: 0.1954 - accuracy: 0.91 - ETA: 1s - loss: 0.1934 - accuracy: 0.91 - ETA: 1s - loss: 0.1931 - accuracy: 0.91 - ETA: 0s - loss: 0.1937 - accuracy: 0.91 - ETA: 0s - loss: 0.1945 - accuracy: 0.91 - ETA: 0s - loss: 0.1973 - accuracy: 0.91 - ETA: 0s - loss: 0.1984 - accuracy: 0.91 - ETA: 0s - loss: 0.1985 - accuracy: 0.91 - ETA: 0s - loss: 0.1978 - accuracy: 0.91 - ETA: 0s - loss: 0.1981 - accuracy: 0.91 - ETA: 0s - loss: 0.1990 - accuracy: 0.91 - ETA: 0s - loss: 0.1988 - accuracy: 0.91 - ETA: 0s - loss: 0.1985 - accuracy: 0.91 - ETA: 0s - loss: 0.1984 - accuracy: 0.91 - ETA: 0s - loss: 0.1975 - accuracy: 0.91 - ETA: 0s - loss: 0.1976 - accuracy: 0.91 - ETA: 0s - loss: 0.1970 - accuracy: 0.91 - ETA: 0s - loss: 0.1972 - accuracy: 0.91 - ETA: 0s - loss: 0.1971 - accuracy: 0.91 - 1s 141us/step - loss: 0.1971 - accuracy: 0.9116 - val_loss: 0.1693 - val_accuracy: 0.9318\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1545 - accuracy: 0.94 - ETA: 1s - loss: 0.1908 - accuracy: 0.91 - ETA: 1s - loss: 0.1902 - accuracy: 0.91 - ETA: 1s - loss: 0.1926 - accuracy: 0.91 - ETA: 1s - loss: 0.1939 - accuracy: 0.91 - ETA: 1s - loss: 0.1946 - accuracy: 0.91 - ETA: 0s - loss: 0.1956 - accuracy: 0.91 - ETA: 0s - loss: 0.1929 - accuracy: 0.91 - ETA: 0s - loss: 0.1929 - accuracy: 0.91 - ETA: 0s - loss: 0.1923 - accuracy: 0.91 - ETA: 0s - loss: 0.1922 - accuracy: 0.91 - ETA: 0s - loss: 0.1920 - accuracy: 0.91 - ETA: 0s - loss: 0.1925 - accuracy: 0.91 - ETA: 0s - loss: 0.1932 - accuracy: 0.91 - ETA: 0s - loss: 0.1940 - accuracy: 0.91 - ETA: 0s - loss: 0.1936 - accuracy: 0.91 - ETA: 0s - loss: 0.1930 - accuracy: 0.91 - ETA: 0s - loss: 0.1927 - accuracy: 0.91 - ETA: 0s - loss: 0.1923 - accuracy: 0.91 - ETA: 0s - loss: 0.1932 - accuracy: 0.91 - ETA: 0s - loss: 0.1936 - accuracy: 0.91 - ETA: 0s - loss: 0.1940 - accuracy: 0.91 - ETA: 0s - loss: 0.1942 - accuracy: 0.91 - 1s 144us/step - loss: 0.1946 - accuracy: 0.9144 - val_loss: 0.1701 - val_accuracy: 0.9304\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1548 - accuracy: 0.95 - ETA: 1s - loss: 0.1914 - accuracy: 0.91 - ETA: 1s - loss: 0.2001 - accuracy: 0.91 - ETA: 1s - loss: 0.2019 - accuracy: 0.91 - ETA: 0s - loss: 0.1997 - accuracy: 0.91 - ETA: 0s - loss: 0.1993 - accuracy: 0.91 - ETA: 0s - loss: 0.1985 - accuracy: 0.91 - ETA: 0s - loss: 0.2014 - accuracy: 0.91 - ETA: 0s - loss: 0.1990 - accuracy: 0.91 - ETA: 0s - loss: 0.1974 - accuracy: 0.91 - ETA: 0s - loss: 0.1971 - accuracy: 0.91 - ETA: 0s - loss: 0.1976 - accuracy: 0.91 - ETA: 0s - loss: 0.1981 - accuracy: 0.91 - ETA: 0s - loss: 0.1981 - accuracy: 0.91 - ETA: 0s - loss: 0.1975 - accuracy: 0.91 - ETA: 0s - loss: 0.1970 - accuracy: 0.91 - ETA: 0s - loss: 0.1964 - accuracy: 0.91 - ETA: 0s - loss: 0.1967 - accuracy: 0.91 - ETA: 0s - loss: 0.1974 - accuracy: 0.91 - ETA: 0s - loss: 0.1978 - accuracy: 0.91 - ETA: 0s - loss: 0.1977 - accuracy: 0.91 - ETA: 0s - loss: 0.1975 - accuracy: 0.91 - ETA: 0s - loss: 0.1974 - accuracy: 0.91 - 1s 141us/step - loss: 0.1976 - accuracy: 0.9130 - val_loss: 0.1663 - val_accuracy: 0.9324\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1716 - accuracy: 0.93 - ETA: 1s - loss: 0.1822 - accuracy: 0.92 - ETA: 1s - loss: 0.1855 - accuracy: 0.92 - ETA: 1s - loss: 0.1943 - accuracy: 0.91 - ETA: 0s - loss: 0.1939 - accuracy: 0.91 - ETA: 0s - loss: 0.1916 - accuracy: 0.91 - ETA: 0s - loss: 0.1939 - accuracy: 0.91 - ETA: 0s - loss: 0.1938 - accuracy: 0.91 - ETA: 0s - loss: 0.1950 - accuracy: 0.91 - ETA: 0s - loss: 0.1950 - accuracy: 0.91 - ETA: 0s - loss: 0.1955 - accuracy: 0.91 - ETA: 0s - loss: 0.1957 - accuracy: 0.91 - ETA: 0s - loss: 0.1954 - accuracy: 0.91 - ETA: 0s - loss: 0.1953 - accuracy: 0.91 - ETA: 0s - loss: 0.1971 - accuracy: 0.91 - ETA: 0s - loss: 0.1965 - accuracy: 0.91 - ETA: 0s - loss: 0.1966 - accuracy: 0.91 - ETA: 0s - loss: 0.1966 - accuracy: 0.91 - ETA: 0s - loss: 0.1963 - accuracy: 0.91 - ETA: 0s - loss: 0.1967 - accuracy: 0.91 - ETA: 0s - loss: 0.1956 - accuracy: 0.91 - ETA: 0s - loss: 0.1956 - accuracy: 0.91 - 1s 134us/step - loss: 0.1958 - accuracy: 0.9126 - val_loss: 0.1706 - val_accuracy: 0.9246\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1867 - accuracy: 0.92 - ETA: 1s - loss: 0.1943 - accuracy: 0.91 - ETA: 1s - loss: 0.1958 - accuracy: 0.91 - ETA: 1s - loss: 0.1971 - accuracy: 0.91 - ETA: 0s - loss: 0.1947 - accuracy: 0.91 - ETA: 0s - loss: 0.1963 - accuracy: 0.91 - ETA: 0s - loss: 0.1959 - accuracy: 0.91 - ETA: 0s - loss: 0.1944 - accuracy: 0.91 - ETA: 0s - loss: 0.1927 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1931 - accuracy: 0.91 - ETA: 0s - loss: 0.1941 - accuracy: 0.91 - ETA: 0s - loss: 0.1928 - accuracy: 0.91 - ETA: 0s - loss: 0.1937 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1931 - accuracy: 0.91 - ETA: 0s - loss: 0.1942 - accuracy: 0.91 - ETA: 0s - loss: 0.1948 - accuracy: 0.91 - ETA: 0s - loss: 0.1940 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1934 - accuracy: 0.91 - 1s 139us/step - loss: 0.1941 - accuracy: 0.9135 - val_loss: 0.1655 - val_accuracy: 0.9307\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2078 - accuracy: 0.90 - ETA: 1s - loss: 0.2000 - accuracy: 0.91 - ETA: 1s - loss: 0.1925 - accuracy: 0.91 - ETA: 1s - loss: 0.1893 - accuracy: 0.91 - ETA: 1s - loss: 0.1899 - accuracy: 0.91 - ETA: 0s - loss: 0.1920 - accuracy: 0.91 - ETA: 0s - loss: 0.1915 - accuracy: 0.91 - ETA: 0s - loss: 0.1885 - accuracy: 0.91 - ETA: 0s - loss: 0.1882 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1890 - accuracy: 0.91 - ETA: 0s - loss: 0.1892 - accuracy: 0.91 - ETA: 0s - loss: 0.1889 - accuracy: 0.91 - ETA: 0s - loss: 0.1911 - accuracy: 0.91 - ETA: 0s - loss: 0.1913 - accuracy: 0.91 - ETA: 0s - loss: 0.1906 - accuracy: 0.91 - ETA: 0s - loss: 0.1900 - accuracy: 0.91 - ETA: 0s - loss: 0.1898 - accuracy: 0.91 - ETA: 0s - loss: 0.1916 - accuracy: 0.91 - ETA: 0s - loss: 0.1924 - accuracy: 0.91 - ETA: 0s - loss: 0.1916 - accuracy: 0.91 - ETA: 0s - loss: 0.1916 - accuracy: 0.91 - ETA: 0s - loss: 0.1919 - accuracy: 0.91 - 1s 140us/step - loss: 0.1918 - accuracy: 0.9143 - val_loss: 0.1648 - val_accuracy: 0.9300\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1834 - accuracy: 0.92 - ETA: 1s - loss: 0.1874 - accuracy: 0.91 - ETA: 1s - loss: 0.1930 - accuracy: 0.91 - ETA: 1s - loss: 0.1935 - accuracy: 0.91 - ETA: 1s - loss: 0.1891 - accuracy: 0.91 - ETA: 0s - loss: 0.1914 - accuracy: 0.91 - ETA: 0s - loss: 0.1931 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1917 - accuracy: 0.91 - ETA: 0s - loss: 0.1923 - accuracy: 0.91 - ETA: 0s - loss: 0.1913 - accuracy: 0.91 - ETA: 0s - loss: 0.1925 - accuracy: 0.91 - ETA: 0s - loss: 0.1926 - accuracy: 0.91 - ETA: 0s - loss: 0.1947 - accuracy: 0.91 - ETA: 0s - loss: 0.1954 - accuracy: 0.91 - ETA: 0s - loss: 0.1947 - accuracy: 0.91 - ETA: 0s - loss: 0.1952 - accuracy: 0.91 - ETA: 0s - loss: 0.1951 - accuracy: 0.91 - ETA: 0s - loss: 0.1953 - accuracy: 0.91 - ETA: 0s - loss: 0.1951 - accuracy: 0.91 - ETA: 0s - loss: 0.1948 - accuracy: 0.91 - ETA: 0s - loss: 0.1948 - accuracy: 0.91 - 1s 139us/step - loss: 0.1949 - accuracy: 0.9130 - val_loss: 0.1649 - val_accuracy: 0.9324\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1982 - accuracy: 0.91 - ETA: 1s - loss: 0.1951 - accuracy: 0.91 - ETA: 1s - loss: 0.1931 - accuracy: 0.91 - ETA: 0s - loss: 0.1950 - accuracy: 0.91 - ETA: 0s - loss: 0.1995 - accuracy: 0.91 - ETA: 0s - loss: 0.1988 - accuracy: 0.91 - ETA: 0s - loss: 0.1970 - accuracy: 0.91 - ETA: 0s - loss: 0.1966 - accuracy: 0.91 - ETA: 0s - loss: 0.1937 - accuracy: 0.91 - ETA: 0s - loss: 0.1934 - accuracy: 0.91 - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - ETA: 0s - loss: 0.1945 - accuracy: 0.91 - ETA: 0s - loss: 0.1940 - accuracy: 0.91 - ETA: 0s - loss: 0.1939 - accuracy: 0.91 - ETA: 0s - loss: 0.1939 - accuracy: 0.91 - ETA: 0s - loss: 0.1944 - accuracy: 0.91 - ETA: 0s - loss: 0.1938 - accuracy: 0.91 - ETA: 0s - loss: 0.1932 - accuracy: 0.91 - ETA: 0s - loss: 0.1933 - accuracy: 0.91 - ETA: 0s - loss: 0.1934 - accuracy: 0.91 - ETA: 0s - loss: 0.1941 - accuracy: 0.91 - ETA: 0s - loss: 0.1942 - accuracy: 0.91 - 1s 138us/step - loss: 0.1941 - accuracy: 0.9144 - val_loss: 0.1616 - val_accuracy: 0.9316\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2378 - accuracy: 0.90 - ETA: 1s - loss: 0.2018 - accuracy: 0.90 - ETA: 1s - loss: 0.1896 - accuracy: 0.91 - ETA: 1s - loss: 0.1845 - accuracy: 0.91 - ETA: 1s - loss: 0.1854 - accuracy: 0.91 - ETA: 1s - loss: 0.1867 - accuracy: 0.91 - ETA: 1s - loss: 0.1864 - accuracy: 0.91 - ETA: 1s - loss: 0.1893 - accuracy: 0.91 - ETA: 1s - loss: 0.1885 - accuracy: 0.91 - ETA: 0s - loss: 0.1881 - accuracy: 0.91 - ETA: 0s - loss: 0.1858 - accuracy: 0.91 - ETA: 0s - loss: 0.1871 - accuracy: 0.91 - ETA: 0s - loss: 0.1870 - accuracy: 0.91 - ETA: 0s - loss: 0.1887 - accuracy: 0.91 - ETA: 0s - loss: 0.1885 - accuracy: 0.91 - ETA: 0s - loss: 0.1881 - accuracy: 0.91 - ETA: 0s - loss: 0.1875 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1876 - accuracy: 0.91 - ETA: 0s - loss: 0.1878 - accuracy: 0.91 - ETA: 0s - loss: 0.1884 - accuracy: 0.91 - ETA: 0s - loss: 0.1878 - accuracy: 0.91 - 2s 150us/step - loss: 0.1875 - accuracy: 0.9158 - val_loss: 0.1603 - val_accuracy: 0.9353\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1944 - accuracy: 0.91 - ETA: 1s - loss: 0.1935 - accuracy: 0.91 - ETA: 1s - loss: 0.1877 - accuracy: 0.91 - ETA: 1s - loss: 0.1845 - accuracy: 0.92 - ETA: 1s - loss: 0.1860 - accuracy: 0.91 - ETA: 1s - loss: 0.1857 - accuracy: 0.91 - ETA: 0s - loss: 0.1865 - accuracy: 0.91 - ETA: 0s - loss: 0.1876 - accuracy: 0.91 - ETA: 0s - loss: 0.1859 - accuracy: 0.91 - ETA: 0s - loss: 0.1889 - accuracy: 0.91 - ETA: 0s - loss: 0.1899 - accuracy: 0.91 - ETA: 0s - loss: 0.1902 - accuracy: 0.91 - ETA: 0s - loss: 0.1899 - accuracy: 0.91 - ETA: 0s - loss: 0.1893 - accuracy: 0.91 - ETA: 0s - loss: 0.1904 - accuracy: 0.91 - ETA: 0s - loss: 0.1902 - accuracy: 0.91 - ETA: 0s - loss: 0.1898 - accuracy: 0.91 - ETA: 0s - loss: 0.1900 - accuracy: 0.91 - ETA: 0s - loss: 0.1890 - accuracy: 0.91 - ETA: 0s - loss: 0.1889 - accuracy: 0.91 - ETA: 0s - loss: 0.1892 - accuracy: 0.91 - ETA: 0s - loss: 0.1893 - accuracy: 0.91 - ETA: 0s - loss: 0.1893 - accuracy: 0.91 - 1s 141us/step - loss: 0.1897 - accuracy: 0.9157 - val_loss: 0.1634 - val_accuracy: 0.9279\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1506 - accuracy: 0.94 - ETA: 1s - loss: 0.1852 - accuracy: 0.92 - ETA: 1s - loss: 0.1823 - accuracy: 0.92 - ETA: 1s - loss: 0.1833 - accuracy: 0.92 - ETA: 1s - loss: 0.1839 - accuracy: 0.92 - ETA: 0s - loss: 0.1864 - accuracy: 0.91 - ETA: 0s - loss: 0.1869 - accuracy: 0.91 - ETA: 0s - loss: 0.1867 - accuracy: 0.91 - ETA: 0s - loss: 0.1861 - accuracy: 0.91 - ETA: 0s - loss: 0.1877 - accuracy: 0.91 - ETA: 0s - loss: 0.1892 - accuracy: 0.91 - ETA: 0s - loss: 0.1896 - accuracy: 0.91 - ETA: 0s - loss: 0.1903 - accuracy: 0.91 - ETA: 0s - loss: 0.1899 - accuracy: 0.91 - ETA: 0s - loss: 0.1907 - accuracy: 0.91 - ETA: 0s - loss: 0.1905 - accuracy: 0.91 - ETA: 0s - loss: 0.1910 - accuracy: 0.91 - ETA: 0s - loss: 0.1911 - accuracy: 0.91 - ETA: 0s - loss: 0.1907 - accuracy: 0.91 - ETA: 0s - loss: 0.1903 - accuracy: 0.91 - ETA: 0s - loss: 0.1905 - accuracy: 0.91 - ETA: 0s - loss: 0.1902 - accuracy: 0.91 - ETA: 0s - loss: 0.1912 - accuracy: 0.91 - ETA: 0s - loss: 0.1920 - accuracy: 0.91 - 1s 144us/step - loss: 0.1920 - accuracy: 0.9143 - val_loss: 0.1625 - val_accuracy: 0.9290\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1709 - accuracy: 0.91 - ETA: 1s - loss: 0.1764 - accuracy: 0.92 - ETA: 1s - loss: 0.1838 - accuracy: 0.91 - ETA: 0s - loss: 0.1827 - accuracy: 0.92 - ETA: 0s - loss: 0.1825 - accuracy: 0.91 - ETA: 0s - loss: 0.1839 - accuracy: 0.91 - ETA: 0s - loss: 0.1855 - accuracy: 0.91 - ETA: 0s - loss: 0.1854 - accuracy: 0.91 - ETA: 0s - loss: 0.1867 - accuracy: 0.91 - ETA: 0s - loss: 0.1855 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - ETA: 0s - loss: 0.1848 - accuracy: 0.91 - ETA: 0s - loss: 0.1852 - accuracy: 0.91 - ETA: 0s - loss: 0.1848 - accuracy: 0.91 - ETA: 0s - loss: 0.1851 - accuracy: 0.91 - ETA: 0s - loss: 0.1853 - accuracy: 0.91 - ETA: 0s - loss: 0.1856 - accuracy: 0.91 - ETA: 0s - loss: 0.1854 - accuracy: 0.91 - ETA: 0s - loss: 0.1842 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - ETA: 0s - loss: 0.1846 - accuracy: 0.91 - ETA: 0s - loss: 0.1842 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - 1s 142us/step - loss: 0.1842 - accuracy: 0.9179 - val_loss: 0.1577 - val_accuracy: 0.9325\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1553 - accuracy: 0.93 - ETA: 1s - loss: 0.1939 - accuracy: 0.91 - ETA: 1s - loss: 0.1894 - accuracy: 0.91 - ETA: 1s - loss: 0.1885 - accuracy: 0.91 - ETA: 0s - loss: 0.1883 - accuracy: 0.91 - ETA: 0s - loss: 0.1884 - accuracy: 0.91 - ETA: 0s - loss: 0.1872 - accuracy: 0.91 - ETA: 0s - loss: 0.1859 - accuracy: 0.91 - ETA: 0s - loss: 0.1857 - accuracy: 0.91 - ETA: 0s - loss: 0.1855 - accuracy: 0.91 - ETA: 0s - loss: 0.1851 - accuracy: 0.91 - ETA: 0s - loss: 0.1851 - accuracy: 0.91 - ETA: 0s - loss: 0.1845 - accuracy: 0.91 - ETA: 0s - loss: 0.1849 - accuracy: 0.91 - ETA: 0s - loss: 0.1846 - accuracy: 0.91 - ETA: 0s - loss: 0.1832 - accuracy: 0.91 - ETA: 0s - loss: 0.1831 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - ETA: 0s - loss: 0.1846 - accuracy: 0.91 - ETA: 0s - loss: 0.1846 - accuracy: 0.91 - ETA: 0s - loss: 0.1848 - accuracy: 0.91 - ETA: 0s - loss: 0.1855 - accuracy: 0.91 - 1s 137us/step - loss: 0.1850 - accuracy: 0.9169 - val_loss: 0.1583 - val_accuracy: 0.9318\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1822 - accuracy: 0.92 - ETA: 1s - loss: 0.1781 - accuracy: 0.92 - ETA: 1s - loss: 0.1806 - accuracy: 0.92 - ETA: 1s - loss: 0.1827 - accuracy: 0.92 - ETA: 1s - loss: 0.1804 - accuracy: 0.92 - ETA: 1s - loss: 0.1810 - accuracy: 0.92 - ETA: 0s - loss: 0.1800 - accuracy: 0.92 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1800 - accuracy: 0.92 - ETA: 0s - loss: 0.1820 - accuracy: 0.91 - ETA: 0s - loss: 0.1821 - accuracy: 0.92 - ETA: 0s - loss: 0.1817 - accuracy: 0.92 - ETA: 0s - loss: 0.1827 - accuracy: 0.91 - ETA: 0s - loss: 0.1829 - accuracy: 0.91 - ETA: 0s - loss: 0.1831 - accuracy: 0.91 - ETA: 0s - loss: 0.1826 - accuracy: 0.91 - ETA: 0s - loss: 0.1829 - accuracy: 0.91 - ETA: 0s - loss: 0.1833 - accuracy: 0.91 - ETA: 0s - loss: 0.1836 - accuracy: 0.91 - ETA: 0s - loss: 0.1832 - accuracy: 0.91 - ETA: 0s - loss: 0.1835 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - 1s 143us/step - loss: 0.1845 - accuracy: 0.9176 - val_loss: 0.1556 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1833 - accuracy: 0.90 - ETA: 1s - loss: 0.1905 - accuracy: 0.91 - ETA: 1s - loss: 0.1883 - accuracy: 0.91 - ETA: 1s - loss: 0.1822 - accuracy: 0.91 - ETA: 1s - loss: 0.1861 - accuracy: 0.91 - ETA: 1s - loss: 0.1854 - accuracy: 0.91 - ETA: 0s - loss: 0.1829 - accuracy: 0.91 - ETA: 0s - loss: 0.1850 - accuracy: 0.91 - ETA: 0s - loss: 0.1873 - accuracy: 0.91 - ETA: 0s - loss: 0.1867 - accuracy: 0.91 - ETA: 0s - loss: 0.1876 - accuracy: 0.91 - ETA: 0s - loss: 0.1870 - accuracy: 0.91 - ETA: 0s - loss: 0.1874 - accuracy: 0.91 - ETA: 0s - loss: 0.1869 - accuracy: 0.91 - ETA: 0s - loss: 0.1866 - accuracy: 0.91 - ETA: 0s - loss: 0.1864 - accuracy: 0.91 - ETA: 0s - loss: 0.1856 - accuracy: 0.91 - ETA: 0s - loss: 0.1870 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1886 - accuracy: 0.91 - ETA: 0s - loss: 0.1882 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1875 - accuracy: 0.91 - 1s 142us/step - loss: 0.1881 - accuracy: 0.9155 - val_loss: 0.1558 - val_accuracy: 0.9322\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1608 - accuracy: 0.93 - ETA: 1s - loss: 0.1980 - accuracy: 0.91 - ETA: 1s - loss: 0.1974 - accuracy: 0.91 - ETA: 1s - loss: 0.1975 - accuracy: 0.91 - ETA: 1s - loss: 0.1950 - accuracy: 0.91 - ETA: 0s - loss: 0.1917 - accuracy: 0.91 - ETA: 0s - loss: 0.1905 - accuracy: 0.91 - ETA: 0s - loss: 0.1901 - accuracy: 0.91 - ETA: 0s - loss: 0.1908 - accuracy: 0.91 - ETA: 0s - loss: 0.1904 - accuracy: 0.91 - ETA: 0s - loss: 0.1905 - accuracy: 0.91 - ETA: 0s - loss: 0.1894 - accuracy: 0.91 - ETA: 0s - loss: 0.1895 - accuracy: 0.91 - ETA: 0s - loss: 0.1884 - accuracy: 0.91 - ETA: 0s - loss: 0.1883 - accuracy: 0.91 - ETA: 0s - loss: 0.1875 - accuracy: 0.91 - ETA: 0s - loss: 0.1872 - accuracy: 0.91 - ETA: 0s - loss: 0.1869 - accuracy: 0.91 - ETA: 0s - loss: 0.1858 - accuracy: 0.91 - ETA: 0s - loss: 0.1863 - accuracy: 0.91 - ETA: 0s - loss: 0.1864 - accuracy: 0.91 - ETA: 0s - loss: 0.1863 - accuracy: 0.91 - ETA: 0s - loss: 0.1856 - accuracy: 0.91 - 1s 141us/step - loss: 0.1859 - accuracy: 0.9183 - val_loss: 0.1541 - val_accuracy: 0.9348\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1733 - accuracy: 0.92 - ETA: 1s - loss: 0.1832 - accuracy: 0.91 - ETA: 1s - loss: 0.1803 - accuracy: 0.91 - ETA: 1s - loss: 0.1817 - accuracy: 0.92 - ETA: 0s - loss: 0.1807 - accuracy: 0.92 - ETA: 0s - loss: 0.1796 - accuracy: 0.92 - ETA: 0s - loss: 0.1813 - accuracy: 0.92 - ETA: 0s - loss: 0.1837 - accuracy: 0.91 - ETA: 0s - loss: 0.1840 - accuracy: 0.91 - ETA: 0s - loss: 0.1844 - accuracy: 0.91 - ETA: 0s - loss: 0.1843 - accuracy: 0.91 - ETA: 0s - loss: 0.1861 - accuracy: 0.91 - ETA: 0s - loss: 0.1850 - accuracy: 0.91 - ETA: 0s - loss: 0.1852 - accuracy: 0.91 - ETA: 0s - loss: 0.1849 - accuracy: 0.91 - ETA: 0s - loss: 0.1840 - accuracy: 0.91 - ETA: 0s - loss: 0.1847 - accuracy: 0.91 - ETA: 0s - loss: 0.1850 - accuracy: 0.91 - ETA: 0s - loss: 0.1847 - accuracy: 0.91 - ETA: 0s - loss: 0.1846 - accuracy: 0.91 - ETA: 0s - loss: 0.1843 - accuracy: 0.91 - ETA: 0s - loss: 0.1841 - accuracy: 0.91 - 1s 136us/step - loss: 0.1840 - accuracy: 0.9177 - val_loss: 0.1533 - val_accuracy: 0.9368\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 125us/step\n",
            "\n",
            "Accuracy on test data: 0.93\n",
            "\n",
            "Loss on test data: 0.15\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEaCAYAAADjQbcAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deVhUZfvA8e9sIKugiCsKKqgoKphLloVamllZvYRW4oJlrtmGS2mZO27l676V+tpmluVSmlLuqLkkiOGuqYCCLMq+zPz+4OcIITLAwDDj/bmuuS7OmTPnuR+Ve26f85zzKHQ6nQ4hhBBmTWnqAIQQQpSfJHMhhLAAksyFEMICSDIXQggLIMlcCCEsgCRzIYSwAJLMHyLp6el8/vnn9OzZk9atW9OtWzdmzZrF7du3jdrGW2+9hY+PD6+99lq5zvXjjz/SsWNHI0VWVLNmzWjWrBmnTp0q8l50dDTNmjXj5ZdfNvh8R44c4e+//y72/Yruj3i4qU0dgKgcqampvPrqq9ja2vLRRx/h4eHB5cuXCQ0N5ejRo6xfv55q1aqVu51du3Zx8OBBvvnmG1xdXct1rmeffZYnn3yy3DE9iEajYdeuXbRq1arQ/p07d6JQKEp1rqCgIJYtW0aLFi3u+35l9Ec8vKQyf0jMnTsXrVbL2rVreeKJJ3Bzc6NLly6sXLmS6OhofvjhB6O0c+fOHVxcXGjVqlW5k3m1atWoWbOmUeIqTocOHQgLCyuy/7fffqNt27ZGbasy+iMeXpLMHwLZ2dls2bKF/v37F6m+69aty7p163j22WcB0Ol0rFu3jp49e+Lj40OfPn3Ys2eP/vjx48czefJkJkyYgK+vL926dWPJkiUALFy4kClTphATE0OzZs348ccfGT9+PG+//XahNrt168b69esBuHHjBsOGDaNdu3Y88sgjvP3229y6dQsoOixx+fJlhg8fTvv27enYsSMTJ04kNTUVgGvXrtGsWTO2b99Or1698PX1JSgoiIsXLz7wz+app57i3LlzXL16Vb/vypUr3Lx5s8iQyL59+wgMDKR169a0adOGAQMGcOHCBX2fAIYNG8b48eM5fPgwHTt2JDQ0lHbt2vHxxx8X6s/ixYvx9fUlNjYWgOvXr+Pn58dXX331wHiFKI4k84fA1atXSU1NxcfH577v+/n54ezsDMCyZctYuHAhb7/9Nps3b+app55i+PDhREdH64/fuHEjtWvX5ocffiAgIIAFCxZw6tQpgoODee+996hTpw779+/Xf0E8yOTJk1EqlWzcuJH169dz/fp1Zs2aVeS45ORkXnvtNTQaDV999RULFy7k2LFjfPjhh4WOW7RoEVOmTGHt2rXEx8cze/bsB7Zft25dWrZsWag637FjB926dUOtvjcKef36dYYPH84zzzzDtm3bWLt2LSkpKcyZM0f/ZwIwe/ZsPvroI33Mly9fZtOmTQQHBxdq96233qJRo0ZMmzYNnU7Hhx9+SJs2bcp9nUE8vCSZPwRSUlIAcHBweOBxOp2OtWvXMmzYMHr37o2HhwejR4+mc+fOrFy5Un+cm5sb77zzDo0bN2bEiBE4OTkRFRWFnZ0ddnZ2qFQqatWqZdAY/PXr13F0dKR+/fo0b96c+fPnM3jw4CLHbd26Fa1Wy+zZs/Hy8qJDhw7MmjWLHTt2cOnSJf1xdyv31q1b89prr9334ua/9ejRg127dum3d+7cSY8ePQodk5eXx7hx4wgODsbNzY22bdvSp08fzp8/D0CNGjUAcHR0LPTn/NZbb9GwYUPc3d0LnU+tVjNjxgx2795NSEgIUVFRzJgxo9Tj9ELcJcn8IXC36r6b1Itz69YtkpKSiowVt2vXTp+0ABo1alTofTs7O3Jzc8sU25gxY/jll1/o1KkTI0eO5MSJE3h5eRU57ty5c7Ro0aLQF4SPjw8ajUY/1AEUSpr29vYGxfX0009z/PhxkpKSiIuL4+LFizz22GOFjmnYsCE9evRgxYoVjB07loCAAObPn49Wq33guRs2bFjse97e3gwcOJAtW7bwwQcfULdu3RJjFaI4kswfAo0aNcLJyYnIyMj7vj9z5kxWrVpVbCWt0+kKJS0rK6v7HnM/96s0CybY7t27s3v3biZMmIBKpWLy5MkMHTq0yGceVOUXjE2j0RgUV0GNGzfG3d2dP/74g507d+Lv71+kj2fPnuWZZ54hIiKCli1bMm7cON55550Sz21tbf3A98+cOYNKpeLgwYMlnkuIB5Fk/hBQKpX06dOH9evXk5WVVei9a9eu8d1332FlZYW9vT2urq789ddfhY45ceIEjRs3LlPbGo2GO3fu6LfT0tJITEwE8hNtaGgoN2/e5JVXXuG///0vixYt4sCBA/qLoHc1adKE6OhoMjMz9ftOnTpFTk5OmWMr6Omnn2bXrl389ttvRYZYADZt2oS3tzeLFi1i4MCBtG/fnmvXrhn0ZVGcjRs3cvz4cVatWsXvv//Ojh07ytMF8ZCTZP6QGDFiBFqtlgEDBrB//36uXr3Krl27GDJkCM2aNaNv374ADB06lGXLlrFt2zYuX77MkiVL2L9/P0FBQWVq18fHh8OHD7Nr1y4uXrzIxIkTUSrz/9kpFAouXLjAlClTOH36NFeuXGHbtm3Ur19fPzR01/PPP4+1tTVjx47l7NmzHD16lI8++ojOnTvTtGnT8v3hkJ/MDxw4QFRUFE888USR952dnbl48SJHjx7l6tWrrFmzhu+//57s7Gz9Mba2tpw7d47k5OQS27t58yahoaGMGTOGzp07M2TIEKZMmWLQZ4W4H7lp6CHh5OTE119/zZIlS/j4449JSEjA1dWVHj16MHz4cP1wQP/+/UlPT2fOnDncunULLy8vli1bxiOPPFKmdvv06cNff/3F2LFjsba2ZvDgwSQlJenfnz59OlOnTmXw4MFkZmbi6+vLihUr9An/LhsbG1atWsWMGTMICAjA1taWnj17EhISUvY/lAJatWpFzZo1admyJTY2NkXeDwoK4syZMwwbNgyFQoG3tzeTJ09m0qRJxMXFUadOHYYMGcLixYs5efIkAwYMeGB7kydPpn79+vovyeHDh7Nt2zamT5+unyEjRGkoZKUhIYQwfzLMIoQQFkCGWYQQohKtW7eOO3fuMHLkSCIiIli3bh3Z2dl07tyZfv36Afl3Oy9btoyMjAxatGjBm2++iUqleuB5pTIXQohKEhkZqX88RnZ2NkuXLmXs2LF89tlnXLhwgRMnTgD5j8YIDg5mwYIF6HS6+z4/6N8kmQshRCVITU3l22+/5aWXXgLg/Pnz1K1bF1dXV1QqFV26dCE8PJz4+Hiys7P1N8/5+/sTHh5e4vllmEUIIcooLS2NtLS0IvvvPtqioBUrVtCvXz/9PRSJiYk4OTnp33dyciIxMZGkpKRC+52dnfX3ZjyIJHMhhChgm6aZwcemfTVV/5C1ggICAggMDNRvh4WFUbNmTXx8fNi9ezeQf9Pcv++QVigUaLXaQvvvd9z9mE0yX7en5GPMxYD/X5+gS599pg3EyPb93AWAx5+3nL+s/Vvy/7IsqU9g+f0qD4XG8Ied9e7dG39//yL7/12VHzx4kOTkZEJCQkhNTSUzM5OEhIRC91MkJyfj7OxMzZo1C92LcXd/ScwmmQshRGVQqg1P5vcbTrmfSZMm6X/evXs3UVFRvPnmm4wZM4a4uDhcXV3Zv38/Xbt2pVatWlhZWREdHU3z5s3Zu3cvvr6+JbYhyVwIIQpQaCpnXoiVlRUjRoxg3rx5ZGdn4+vrS6dOnQAYPXo0y5cvJyMjAw8PD3r16lXi+SSZCyFEAaWpzMvC399fPzTj4+Nz38c3uLu7M3PmzFKdV5K5EEIUoLIxzxnbksyFEKKA0lwArUokmQshRAEVPcxSUSSZCyFEAQqVJHMhhDB7SknmQghh/hRKSeZCCGH2VFYPftRsVSXJXAghCpDKXAghLICMmQshhAWQ2SxCCGEBFEq5A1QIIcyeqpIetGVsD2Uyv37xJL//OJegD/5H3NW/+e2bqSiUKtRqK54PDsXe0YXDO9dw+s9tADTxeZInnh9l4qhLT6mEsSM9aVjfhjwtzPzvWWLiMk0dVrkoFPD+cE+aetiTk6Nl1sIzXI817z6BZfbLXPtkrhdAzfMrqBzCt69k27qJ5OZkAbDz2+n0eHUSQR/8j2a+TxO+fSVJ8Vc5dWQzA8d/y6Dx33Hp9H5uXIs2ceSl91j7mgCMGB/B6q+vMCq4sYkjKr8unVywslIyLOQEy9ZeZFRwE1OHZBSW2C9z7ZNCqTT4VZVUrWgqgXOthgQMX6jffvHN+dRxawGAVpuHWmONo3MdXn17FUqlCoVSSV5eLmqNtalCLrN9h28xZ/E5AOrUsiYpOdvEEZVfa+/qHD6Wvx5i1Jk7NPd0MHFExmGJ/TLXPimUCoNfVclDl8ybt+uJUnVvdMnByRWAaxeOc/SP9XR4ahAqtQZbhxrodDp2fR9KHTdvatb2MFXI5ZKnhQ/HePHO0CbsPphg6nDKzc5WRVp6nn5bq9WhsoB/xZbYL3Ptk1KlMPhVlVTImHlCwoOThouLS0U0W2an//yFA78spe/oFdg51AAgNyeLrWs/xMrajmde/8TEEZbPjAVnWbZWw/I5bQkadYzMLK2pQyqztPQ8bG3u3aGnUCjIM9/u6Fliv8y1T1Wt4jZUhSTzmTNnEhcXh7OzMzqdrtB7CoWCRYsWVUSzZRJ56GdO7P2O/h/8Dxs7JyB/NezvF4+gUfOOdH5mqIkjLLue/q7UqmnF+h+ukZmlRavLr47MWeTfKTzWoSa/74+nZTMHLl5JM3VIRmGJ/TLXPinVcju/3tSpU/nkk08YMmQIzZs3r4gmjEKrzeO3b6fjWKMuG5eOBqChV3tqu7Xgytkj5OZmc+HUPgC6vvQeDZqUvKhqVbInPIEJb3uxcEZr1CoFC1ddIDvHvJP53vAE2rd1ZunstigUCmYsML8L0/djif0y1z5JZV6Ara0tb731FmFhYVUymTu5NGDwhA0AvP/5kfseM35JZGWGVCEys7R8Msc8foEMpdPB3CXnTB2G0Vliv8y1T5LM/6Vp06Y0bdq0ok4vhBAVoqpNOTTUQ3nTkBBCFKeqzVIxlCRzIYQoQIZZhBDCAshsFiGEsABSmQshhAWQC6BCCGEBpDIXQggLIJW5EEJYAIU5PA3sPiSZCyFEAVKZCyGEBZAxcyGEsABSmQshhAWQylwIISyAJHMhhLAACpXczi+EEGavosbMv/vuOw4dOoRCoaBbt24899xz7Nq1i19//RWAJk2aMHToUNRqNZcvX2bZsmVkZGTQokUL3nzzTVQlfMmY50i/EEJUEIVSYfDLUKdPn+bUqVPMnTuXWbNm8euvvxITE8PmzZuZOnUqc+fORavVsn37dgAWLlxIcHAwCxYsQKfTERYWVmIbZlOZD3jS1BEY376fu5g6hAqxf4vl/WVZYp/AcvtVLqWozNPS0khLK7q2qZ2dHXZ2dvptb29vPvnkE1QqFYmJiWi1WjQaDW+88Qa2trYANGzYkISEBOLj48nOzsbLywsAf39/NmzYQI8ePR4Yi9kkcyGEqAylqbi3bdvGxo0bi+wPCAggMDCw0D61Ws2GDRvYsmULnTp1wsXFhVq1agFw+/ZtduzYwYgRI0hKSsLJyUn/OWdnZxITE0uMxWySeZc++0wdgtHcrcg3HckzcSTG9VKH/DG9x5/fY+JIjOdu5WpJfQLL71d5KBSGV+a9e/fG39+/yP6CVXlBgYGB9OnTh9DQUMLCwnjqqadITExkxowZdO3alZYtWxIdHY1Cce8LRafTFdoujtkkcyGEqAyKUixO8e/hlOJcv36dnJwc3N3dsba2pkOHDly5coXr168zffp0evXqxfPPPw9AzZo1SUpK0n82OTkZZ2fnEtuQC6BCCFFARVwAvXHjBsuXLycnJ4fc3FyOHj2Kp6cn06ZNo1+/fvpEDlCrVi2srKyIjo4GYO/evfj6+pbYhlTmQghRUCmGWQzl5+fH+fPnGTt2LEqlko4dO3L79m1SUlLYsmULW7ZsAeCRRx6hb9++jB49muXLl5ORkYGHhwe9evUqsQ1J5kIIUUBF3QEaGBhY5KLoc889d99j3d3dmTlzZqnOL8lcCCEKkgdtCSGE+ZPb+YUQwgLIg7aEEMISVMAF0MogyVwIIQqSylwIIcxfae4ArUokmQshREFSmQshhPmT2SxCCGEJZJ65EEJYAAOeUFgVSTIXQogCKmrZuIomyVwIIQqS2SzmS6VSMGG0J3Vcq6HRKFn3/T8cOFLyyh5VzT/nT/Lrd/N566O13Lh+nh+/mAw6HXUbNuOFAR+hVKrYvXUVJ8O3YW1jz5O9h9DC19/UYZeJt5cDwwc1ZvSHJ00dilEoFPD+cE+aetiTk6Nl1sIzXI/NNHVY5WK2fZLZLOarp78rKXdymfZ5BI4Oar74zNfskvmeras5fmAzVtY2AOzY8Dk9X3mHxs0fYcPyDzl9/A9cajfkr4PbGDn5WwCWTnmNJt4d9Z8xF6+97EbPrq5kZmpNHYrRdOnkgpWVkmEhJ2jZzIFRwU2YMD3K1GGVi7n2yVxns1TY/yf+/PNPfv31V+Li4grt37VrV0U1WWZ/HIhn1ddX9Nt5eToTRlM2NWq7ETRmgX67/5gFNG7+CLm52aSmJODgWJObMRdo3KI9GitrNFbWuNRpRNzVsyaMumyux2Xw0YzTpg7DqFp7V+fwsfwCIurMHZp7Opg4ovIz2z4plIa/qpAKiearr75i+/btxMbGMmnSJPbu3at/b+fOnRXRZLlkZGrJyMjDxkbF1HEtWPnVlZI/VMX4tO+BUqXRbyuVKpISrvPZ+BdIS03Cpa4HdRp4cenMUbIy0ki7k8yVc3+RnZVuwqjLZs/BBHLzLKcqB7CzVZGWfm9NWK1Wh6pq5YpSM9s+KRSGv6qQChlmOX78OLNnz0alUtGrVy+mTZuGRqPh0UcfRaermlWvq4sV0yd4s+mXWHbtjTd1OEbh7FKfkLnbObJ7I9u+DiXwrZl0fup1vpj7FjVdG+LWpDW29iWvLSgqXlp6HrY29/57r1AoMPfvK7Ptk5nOZqmwqO+uJl23bl3Gjx/PmjVriIqKMmiV6crmXF3DvMk+LFt7mV/Cbpg6HKNYO38kCXGXAbCuZodCoSD1diJpqUkMn7SeF4ImkHIrljpunqYNVAAQ+XcKnR6pAUDLZg5cvJJm4ojKz2z7ZKbDLBVSmXfq1InJkyczYMAAmjZtipubG++++y5z584lJyenIposl6BX3HCwVzMw0I2BgW4AfDAliuxscygj7s//uTf4fsVHqNQaNFbV+M8bU7FzcCbx5lUWfRyISq2h16shKJXmebHH0uwNT6B9W2eWzm6LQqFgxoJoU4dUbmbbJzO9AKrQVdC4R2RkJM7OzjRo0EC/LyEhga1btzJo0KBSn69Ln31GjM609v3cBYBNR/JKONK8vNQh/5fg8ef3mDgS49m/5UnAsvoElt+v8sjcvNjgY6u9MLLc7RlLhU1N9PHxKbLPxcWlTIlcCCEqjZmOmcs8cyGEKKgKXtczhCRzIYQoqIpd2DSUJHMhhChIhlmEEMICmOkML0nmQghRkIyZCyGEBZBhFiGEMH86qcyFEMICyGwWIYSwAJLMhRDC/OlkNosQQlgASxszT01NfeAH7e3tjR6MEEKYnKXNZhkyZMgDP/jdd98ZPRghhDA1i5vNIslaCPFQqqALoN9//z3h4eEA+Pn50b9/f/1727dv59ChQ0yePBmAy5cvs2zZMjIyMmjRogVvvvkmqhKes15i1Fqtls2bN7N48WIyMjLYtGkTWq35LtoghBAPolOqDH4ZKiIigoiICGbPns3s2bO5ePEiR44cAeDatWv89NNPhY5fuHAhwcHBLFiwAJ1OR1hYWIltlJjM169fzz///MP58+fR6XT89ddfrFmzxuBOCCGEOdEplAa/DOXs7ExQUBBqtRq1Wk39+vVJSEggJyeHFStWEBgYqD82Pj6e7OxsvLy8APD399dX9A9S4myWyMhIQkNDGT9+PLa2tkycOJGxY8ca3Aljubs6jyW5uzKPpTHGai9VjSX2CSy3X+VSijHztLQ00tKKrm1qZ2eHnZ2dftvNzU3/c2xsLOHh4UydOpWvv/6arl274urqqn8/KSkJJycn/bazszOJiYklxlJiMler1SgLXN3VaDSFtoUQwqKUouLetm0bGzduLLI/ICCgULV919WrV5k1axb9+/cnPj6ehIQEBg4cSFRUlP4YrVZbaOF7nU5XaLs4JSZzNzc3tm/fjlarJSYmhq1bt+Lu7l7iiY3NEtcAfeKl/SaOxLj2bnocgF9sm5s4EuN5Nj1/EeIeQSdMHIlx/fY/XwCefPmgiSMxrj0/di73OUozm6V37974+/sX2V+wKr8rOjqaefPmMWjQIB577DGWLFnCtWvXCAkJITMzk+TkZD777DP69+9PUlKS/nPJyck4OzuXGEuJyXzQoEGsXbuWlJQUJk2aRJs2bRg8eHCJJxZCCLNUisr838MpxUlISGDOnDm8++67tGrVCoARI0bo34+KiuL777/n3XffBcDKyoro6GiaN2/O3r178fX1LbGNEpO5ra0tw4cPL/FEQghhCbQK41/L2rJlCzk5Oaxdu1a/7+mnn6ZHjx73PX706NEsX76cjIwMPDw86NWrV4ltlJjMU1JS+PLLL4mMjESlUuHr68uAAQMM+jYSQgizUwHzzAcPHvzAEY2WLVvSsmVL/ba7uzszZ84sVRslRr18+XJq167NjBkz+PTTT7Gzs2PFihWlakQIIcyFTqEw+FWVlJjM4+PjefXVV6lduzZ169ZlwIABXLt2rTJiE0KISlcR88wrQ4nRODs7c/PmTf32rVu3DLqyKoQQZkmhMPxVhRQ7Zj5r1iwUCgW3b98mJCQEHx8flEolUVFRNGrUqDJjFEKISlMRF0ArQ7HJvFOnTvfd7+fnV2HBCCGEqVW14RNDFZvM7zcRHvLvRoqLi6uoeIQQwrSq2PCJoUqcmrhz507Wr19PZmamfp+joyMrV66s0MCEEMIUdCVfSqySSkzmP/30ExMnTuTHH3+kX79+HDt2jFu3blVGbEIIUemq2pRDQ5X4FWRvb4+npyfu7u6kpKTw8ssvc/r06cqITQghKp3FTk1Uq9WkpqZSt25dzp8/DyCLUwghLJZWoTL4VZWUmMy7d+9OaGgofn5+7Ny5k/Hjx1O/fv3KiE0IISqdud4BWuKYebdu3ejcuTPVqlVj+vTpXLhwgTZt2lRGbEIIUel0VK0kbagSkzlAtWrVAKhRowY1atRg0qRJTJ06tUIDq0wqlYIJoz2p41oNjUbJuu//4cCRklf2MAdO1TWsmtuW9yaf4p/rGaYOp3SUSnyWTMXO0wPy8oh460PU1R1o9d/JaLOyuR0RzekPpuPg0wzv2R/qP+bUoQ3H+o4kYad5PC++eRNbhvStR8iM8zRtZMOU9xpz/UYWAFvDEthzONnEEZbd6y/X57H2NVCrFfy0PY5fwm6W/CETq2pj4YYyKJn/25UrV4wdh0n19Hcl5U4u0z6PwNFBzRef+VpEMlepFHwwrClZ2eZ5jaN2764AHOr+GjW6dKBF6Hiq1atN1PvTST58Aq9PxlCv73PEfLuFw88MAKDOSz3Jir1pNon8ld6uPPVYDTKz8v+Omrrb8sP2eH74teonvZK0belIq2YOjPwwkmrWSvr2MY/hWXOtzMv0FWTIEkaxsbH6devCwsL44osvOHiwaq5q8seBeFZ9fe8LKi9PZ8JojGfkIA9+3hFLQmK2qUMpkxtbwjg18mMAbBrWI+vmLarVr03y4fxVf5LCj1Ojczv98SpbGzwnjibqg2kmibcsYm9k8emCS/ptTw8bOrZ1ZN5Hnrz3RkNsqplnlQjQvq0TF/9JZ9q45syc0ILwo+ZRIJnrbJYyVeYl2bp1q36puVatWnHr1i06dOjAH3/8QUxMDAEBARXRbJllZOZXRTY2KqaOa8HKr8z/fx7PdHUlOSWHP/9Kpv9/3Er+QBWly8uj9YpZ1H7hKU68PgYHb09qPN6exP1/4vpsV1S2NvpjGwwMIG7TDnJumc+wxP6jKdR2sdJvn7mQzvbdtzh3OYNXX6hN/5fqsPKbGBNGWHZOjhpq17Jm/Iy/qetqzYwJLQgaXfWX36tqs1QMVWwy/+KLL4r9UG5u7gNP+scffzB//nxSUlJ47733WL16NVZWVnTv3p0JEyZUuWQO4OpixfQJ3mz6JZZde+NNHU659e5eGx3Qro0TTT3s+GiMFxNmnCYxOcfUoZVaxNDxWE1y4bE933H0lRE0n/YBjd8bQsqxU2iz7v2vo36/5zj+2hgTRlp+B46lkJael//z0RRGDmhg4ojKLuVODleuZ5Cbq+NqTCbZOVqcqmtITqna/wbNdZil2GTu4OBQ7IdefPHFB55Up9Oh0WioVasWzz//PFZW9yqPvLy8MoRZsZyra5g32YfPV1zgWIT5VHUPMnpipP7nBVN9mLfsvNkl8nqvvoBN/TpcmLsCbXoGOq0O12f8iRj2EVmxN/GeN5H43/YCoHa0R2ltReZ1835u0MyxTVi87hpnLqbj29Kec5fTTR1SmUX+fYeA5+qyYXMMNZ01VLNWcvtO1f83WNWmHBqq2GT+yiuvlPmkHTt2ZPLkyXzyyScEBgYCcPnyZZYvX07nzuVfPdvYgl5xw8FezcBANwYG5g9JfDAlimwzvXBoKW78vJPWy2fQ6bf/odBoOD12Bmh1tN+0nLz0TG7tPUz8jvxkbufpTvqV6yaOuPz+++VVRg5sQG6ujqSUXD5f/Y+pQyqz8GNJtPF2ZPns1igU8PnKS5jD/YY6nXkmc4VOp6uQq32nT5/G29tbvx0TE8ONGzcMWmX6frr02Wes0Exu389dAHjiJfOYcWGovZseB+AX2+YmjsR4nk2PBqBHUNUf6y2N3/6X/3v45MtVc1JCWe35sfzF4rkLhl8z82xSddZ2qJALoEChRA5Qr1496tWrV1HNCSGEUWgt9amJQgjxMDHXC6AlfgVptVo2b97MokWLyAY0tlIAABnCSURBVMjIYNOmTfKgLSGExdKhMPhVlZRYma9fv57bt29z4cIFdDodf/31F0lJSQQHB1dGfEIIUanM9QJoiZV5ZGQkI0aMQKPRYGtry8SJE4mMjCzpY0IIYZYstjJXq9UolfdyvkajKbQthBCWpKolaUOVmMzd3Nz0t+bHxMSwdetW3N3dKyE0IYSofFqdeRarJUY9aNAgLl26REpKCpMmTSIzM5NBgwZVQmhCCFH5tCgMflUlJVbmtra2DB8+vDJiEUIIk7PYYZbiHrgls1mEEJbIYmezODg46F82Njb8/fffBj3PXAghzJHFzmb59wO3XnzxRWbPnl1hAQkhhCmZa2Ve6tv5bWxs9CsICSGEpTHX2SylHjO/ePEi9eubx1p+QghRWub6sJISk3nBRSoUCgVPPPEEjz/+eIUGJYQQpmKxwyw3btxg1KhRlRGLEEKYXEVe2ExPT2fSpEmMGzcOV1dXzp49y9q1a8nIyKBhw4aMGjUKtVrN5cuXWbZsGRkZGbRo0YI333wTlerBa5OWODh05coVKmj9CiGEqHJ0OoXBr9I4d+4cH3/8MTEx+Qt0p6enM3fuXIYOHcr8+fMB+P333wFYuHAhwcHBLFiwAJ1OR1hYWInnL7Eyd3Jy4r333sPT05Nq1arp91f2PPO7q/NYkrsr81iau6vzWJK7K/NYGmOszGNp8kqRpNPS0khLSyuy387ODjs7u0L7wsLCGDJkCIsWLQIgIiICLy8vGjXKX60oODgYrVZLfHw82dnZeHl5AeDv78+GDRvo0aPHA2MpNpnn5OSg0Wjw8vLSn1QIISxdaYZZtm3bysaNG4vsDwgI0K9/fNewYcMKbcfFxVGtWjU+//xzrl+/TrNmzRgwYACXL1/GyclJf5yzs7NBMwiLTeYTJ04kNDS0XAs7G9Pjz+8xdQhGs3/Lk4Bl9Qnu9eu18ddMHInxfD2rAQCXLpw3cSTG5dGkKQDjVmSYOBLjCh1qU+5zlGb4pHfv3vj7+xfZ/++q/H60Wi0nT55k+vTpuLi4sHTpUn766Sdat25d6MZMnU5n0I2axSZzGScXQjyMSpP67jecYignJyc8PT1xdXUF4NFHH2XHjh107dqVpKQk/XHJyck4OzuXeL4HDrNcunSp2KTeuHHj0sYuhBBVXmU9DbF169Zs2LCBhIQEXFxcOH78OB4eHtSqVQsrKyuio6Np3rw5e/fuxde35Gs2xSbzGzduMG/evPsmc4VCoR/EF0IIS1JZ88xdXFwYOnQooaGh5OTk4O7uTlBQEACjR49m+fLlZGRk4OHhQa9evUo8X7HJvEGDBvIMFiHEQ0dbwcl88eLF+p/9/Pzw8/Mrcoy7uzszZ84s1XlL/WwWIYSwZFozvVxYbDJv0aJFZcYhhBBVgsXdzj948ODKjEMIIaoEc53IJ8MsQghRQFVb29NQksyFEKIAqcyFEMIC5GmlMhdCCLMnlbkQQliAqrZQs6EkmQshRAEWN89cCCEeRjLMIoQQFkAugAohhAWQytyMKRTw/nBPmnrYk5OjZdbCM1yPzTR1WOVmaf1ytFMyfbQrM1cnkKfVMeyVGuh0cO1GDl/+nGwWv4S5ubnM/+xzbty8SU5ODq/260ujhg2ZO/8zFAoF7o0aMXLEcJRKJZu3bGXnrl0oFApef/VVOnbsYOrwDdLOS0U7r/zFhzUqBXVrKpi2PpPMbGjbREXnVmqW/Jxl4iiLZw7/ju5HkjnQpZMLVlZKhoWcoGUzB0YFN2HC9ChTh1VultQvlRKGvOxMdk7+b1r/3k5s+O02f1/MIvhFJ9p5V+NoVNX/ovr99z9wdHRkbMgH3L59m5Gj36ZxYw8GDgiiTevW/HfhIsIPHaJVy5Zs3baNJYsWkp2dzdBhw+nQob1BK86Y2rGzeRw7mwdAn8c0/HlGS2Y21K2poH1zVZWfK2KuF0CVldHIunXrKqOZMmvtXZ3Dx/LX2Is6c4fmng4mjsg4LKlfr/euTtihVJLuaAHwqG/F3xfzq7uTZzNp1bTagz5eZXTp8jgDgvrrt1UqJefPX6C1jw8A7R9px4kTf1G9enWWLl6EWq0mKSkJezs7s0jkBdV3UVDbWcGR6DxsraFXBw1bDuaYOqwS6XQKg19VidEr8yVLlhTZd+zYMVJTUwEYMWKEsZssNztbFWnpefptrVaHSgl5WhMGZQSW0q8n2tlyO01LxLksXuiav69gXsvI0mFbrWr9YhXHxiZ/jcr09HSmzZjBwKABrFy9Wp+obWxsSUvPX+1dpVKxecsW/rf+K/q88ILJYi6rbr4adh3LRaGAgCet2BqeQ06uqaMqmbkOsxi9Mre3t+f48eO4u7vj7e2Nt7c31tbW+p+rorT0PGxtVPpthUJhdgnvfiylX08+YodP02pMHFqLRnU1DA+sgaPdvX+6NtYK0jPM5zcwPj6eceMn0L1bN7p29UdZ4JspIyMdezt7/fYLzz/P1+v/x6lTpzh58qQpwi2TalZQy0nBxVgt9V0UuDgqePFxDa91t8LVWcHzj2pMHWKx8rSGv6oSoyfzAQMGMGbMGA4cOECtWrXw9/fH3t4ef3//+65iXRVE/p1Cp0dqANCymQMXr6SZOCLjsJR+TV0ez9QV8UxbEc+V2ByWbkjk5NlMWjS2BqCNVzWiL1fdC2oFJSUl8eHEiQQHD6Znjx4ANGnShJMREQD8efQYrVq25Oq1a0yZNg2dTodarUaj0aBQVsqoqFF41FVy/np+trsWr2P+xixWbM3m67Bsbibp2BJedYdbdDrDX1VJhVwA9fHxwcPDgxUrVnDs2DG02ir2FfYve8MTaN/WmaWz26JQKJixINrUIRmFpfYLYP22FN582Rm1Cq7H53I4MsPUIRnk2+82kJqaytfffMvX33wLwPC3hrJ02XK+zF1LQzc3Hn/8MVQqFY09GvPue++DQkH7R9rpx9XNQa3qShJvV+3f++KY6wVQhe5+KzYbUVhYGOHh4UycOLFc53n8+T1Gisj09m95ErCsPsG9fr02/pqJIzGer2c1AODShfMmjsS4PJo0BWDcCvP4EjRU6FCbcp9j5S7Dj33zqXI3ZzQVPjWxe/fudO/evaKbEUIIo6jiAwnFknnmQghRgCRzIYSwAOY6Zi7JXAghCijdZcSqc3+DJHMhhCigqk05NJQkcyGEKEDGzIUQwgJIZS6EEBagqt2mbyhJ5kIIUYCuVNNZ5AKoEEJUSTI1UQghLICMmQshhAXQmmlpLslcCCEKkMpcCCEsQJ5U5kIIYf50FTQ1ce/evfz0008AtG3blgEDBhAREcG6devIzs6mc+fO9OvXr8znl2QuhBAFVMQSD1lZWXz55ZcsWLAAOzs7Jk2axNGjR1m9ejWffvopNWvWZNasWZw4cQJfX98ytWE+61AJIUQl0GoNfxl+Ti06nY6srCzy8vLIy8vD1taWunXr4urqikqlokuXLoSHh5c5brOpzO+uYmNJLLFPcG91Hktyd2UeS2OMlXksTWkq87S0NNLSiq6ta2dnh52dnX7bxsaGvn378s477+gXuE9MTMTJyUl/jJOTE4mJiWWO22ySuRBCVIa8PMOT+bZt29i4cWOR/QEBAQQGBuq3r1y5wh9//MGSJUuwtbVl4cKFxMbGolAUvoP039ulYTbJvEuffaYOwWj2/dwFsNw1QC3x78o/oOz//a2Kdm98FIBtmmYmjsS4euecKfc5SjNk3rt3b/z9/YvsL1iVA5w8eZJWrVpRvXp1APz9/dmyZQtK5b2R7uTkZJydncsUM5hRMhdCiMpQmpuG/j2cUpxGjRqxb98+MjMzsba25ujRozRt2pT9+/cTFxeHq6sr+/fvp2vXrmWOW5K5EEIUUBGzWdq0acOlS5cYP348KpWKpk2b8sorr9C6dWvmzZtHdnY2vr6+dOrUqcxtSDIXQogCKmqe+YsvvsiLL75YaJ+Pjw9z5swxyvklmQshRAFaM72fX5K5EEIUkGemq1NIMhdCiALMtDCXZC6EEAWVbqWhqkOSuRBCFCBj5kIIYQGkMhdCCAsgyVwIISxAaZ7NUpVIMhdCiAIq4g7QyiDJXAghCpAFnYUQwgJIZS6EEBZALoCaMaUSxo70pGF9G/K0MPO/Z4mJyzR1WOWmUMD7wz1p6mFPTo6WWQvPcD3WvPulUimYMNqTOq7V0GiUrPv+Hw4cKfvqLFXFM/61eKZrLQCsNEqautvx8htHSU3PM3FkhrOqVYPHD//I4V7B6HJzabN6Fuh03Ik6x6nRn4JOh9uQV2j4Zj90ubmcn7GUm7/sNnXYRcjt/GbssfY1ARgxPoK2raozKrgxH844beKoyq9LJxesrJQMCzlBy2YOjApuwoTpUaYOq1x6+ruScieXaZ9H4Oig5ovPfC0imW/fHc/23fEAjHnDg19+v2lWiVyhVuOzZAp5GfnFgvecCZz5+HMS9x6h1eJPqf1Cd5IP/YX7qCAOdPwPymrWPLrnaxJ2HUCbnWPi6AuTyryA8+fP07Rp/pqJkZGRnDhxApVKRYcOHfD09KyIJstl3+FbHPzzFgB1almTlJxt4oiMo7V3dQ4fy090UWfu0NzTwcQRld8fB+L542CCfttcp5EVp1kTOzzcbFiw6pKpQymVFrPHcWXFtzQdNxSA6n4tSdx7BID47XtxefoxdHlakg6eQJudgzY7h/Tz/+DQujkpRyNNGXoR5jpmriz5kNJbuXIlANu3b2fNmjXUrFmT6tWrs2LFCrZv314RTZZbnhY+HOPFO0ObsLtAsjBndrYq0gpUd1qtDlWF/I1XnoxMLRkZedjYqJg6rgUrv7pi6pCM6vWX67NmwzVTh1EqDQa8RHZ8Igk799/bWWAty9w7aWiqO6BxtCc35c69/alpqB3tKzNUg2i1OoNfVUmFDrOEhYUxefJkHBzyK8Lu3bszYcIEnnnmmYpstsxmLDjLsrUals9pS9CoY2RmmefY2V1p6XnY2qj02wqFAjMdDizE1cWK6RO82fRLLLv2xps6HKOxt1XRsJ4Nf0XdNnUopdJg0H9Ap8Ol+6M4tmlB2y9DsXKtoX9f7WBHTvJtcm6nona4t8Sa2t6uUHKvKsx1mKVC6rTc3Fy0Wi0ODg5oNBr9frVaXa7VpytKT39X+v+nAQCZWVq0OvOda1pQ5N8pdHok/5eqZTMHLl5JM3FE5edcXcO8yT4sW3uZX8JumDoco2rt7cixyBRTh1Fqh7r151D3IA49NYDbJ//mr8HjiN++lxpPdACg1jNPkLj/KCl/RuD8eDuU1laoHe2xb96EO6fOmjj6onQ6ncGvqqRCKnNHR0dGjBgBwOrVqxk5ciSnTp1i/fr1PProoxXRZLnsCU9gwtteLJzRGrVKwcJVF8jOqVp/UWWxNzyB9m2dWTq7LQqFghkLok0dUrkFveKGg72agYFuDAx0A+CDKVFkZ5v/fznc6tkQe8O8Zxvd9ffYUHyWTUVppSE1+iKxP+wArZbLi/7Ho7u/RqFUcObjz9BmVb3rU3m55nPhuSCFrgK/XmJiYkhNTcXLy4vo6GjS09Px8/Mr07m69Nln5OhMZ9/PXQB4/Pk9Jo7EuPZveRKwzL8r/4BwE0diXLs35hdV2zTNTByJcfXOOVPucwS+f9ngYzfMcy93e8ZSoWPm9erV0//cvHnzimxKCCGMwlzHzGWeuRBCFCDJXAghLIBWZ57XXySZCyFEAVKZCyGEBdCa6c0YksyFEKIArVaSuRBCmD0ZZhFCCAugkwugQghh/qQyF0IIC5CXZ56380syF0KIAqQyF0IIC6CT2SxCCGH+pDIXQggLILNZhBDCApjrwjSSzIUQogBtBS1OsX//fn744Qfy8vJ49tlnjb58piRzIYQooCKGWRITE/nmm28IDQ1FrVYzadIkWrVqRYMGDYzWRoWuNCSEEOamNCtlbf/aj7S0omvr2tnZYWd3b/Hq3bt38/fffzN8+HAANm7cCEBAQEA5o71HKnMhhCjg7lKBhtiwYYM+MRcUEBBAYGCgfjspKQlnZ2f9trOzM+fPny9foP8iyVwIIcqod+/e+Pv7F9lfsCoH+PcAiE6nQ6FQGDUWSeZCCFFG/x5OKU6NGjWIjo7WbycnJ1OjRg2jxqI06tmEEEIU0bp1ayIjI7l9+zZZWVkcPnyYtm3bGrUNuQAqhBCVYP/+/WzatInc3Fy6detGnz59jHp+SeZCCGEBZJhFCCEsgCRzIYSwAJLMhRDCAkgyF0IICyDzzAtIT09n0qRJjBs3DldXV1OHU27ff/894eHhAPj5+dG/f38TR2Qc3333HYcOHUKhUNCtWzeee+45U4dkNOvWrePOnTuMHDnS1KEYxaeffkpKSgoqlQqAoUOH4unpaeKoLJMk8/937tw5li9fTkxMjKlDMYqIiAgiIiKYPXs2ADNmzODIkSN06NDBxJGVz+nTpzl16hRz584lLy+Pd999Fz8/P+rVq2fq0MotMjKSPXv24OfnZ+pQjEKn0xETE8OSJUv0yVxUHBlm+X9hYWEMGTLE6HdlmYqzszNBQUGo1WrUajX169cnISHB1GGVm7e3N5988gkqlYqUlBS0Wi3W1tamDqvcUlNT+fbbb3nppZdMHYrR3C2Mpk2bRkhICNu3bzdxRJZNKvP/N2zYMFOHYFRubm76n2NjYwkPD2fq1KkmjMh41Go1GzZsYMuWLXTq1MkivoBXrFhBv379uHXrlqlDMZq0tDR8fHwIDg4mNzeXTz/9lHr16tG6dWtTh2aRpDK3cFevXmXatGn079+funXrmjocowkMDGTVqlXcunWLsLAwU4dTLmFhYdSsWRMfHx9Th2JUXl5ejBo1CltbWxwdHenatSvHjx83dVgWSypzCxYdHc28efMYNGgQjz32mKnDMYrr16+Tk5ODu7s71tbWdOjQgStXrpg6rHI5ePAgycnJhISEkJqaSmZmJmvWrGHQoEGmDq1coqOjycnJKfQlpVZLyqkoUplbqISEBObMmcOYMWMsJpED3Lhxg+XLl5OTk0Nubi5Hjx6lefPmpg6rXCZNmsS8efOYM2cOffv25ZFHHjH7RA75wyzr168nOzubjIwM9uzZY/YX4Ksy+Zq0UFu2bCEnJ4e1a9fq9z399NP06NHDhFGVn5+fH+fPn2fs2LEolUo6duxoUV9WlqRdu3acO3eOcePGodVq6dmzJ15eXqYOy2LJg7aEEMICyDCLEEJYAEnmQghhASSZCyGEBZBkLoQQFkCSuRBCWABJ5qKImzdv0rdvX0JCQgq9fv/993Kfe9asWezevRuAkJAQ0tLSij02PT2dTz/9tNRtHDp0iMmTJxfZf/PmTYKCgkp9vsDAQG7fvl2qzyxevJjNmzeXui0hykrmmYv7srKyYs6cOfrtxMRE3n//fZo0aUKjRo2M0kbB899Pamoq58+fN0pbQlg6SebCIDVq1KBOnTrExsZy6dIlfv/9d7KysrC1teWTTz7h999/Z8eOHeh0OhwcHAgODqZ+/fokJiayePFikpKSqFWrFikpKfpz3n2+iqOjI5s2bWLPnj2oVCrq1KnDyJEjWbp0KdnZ2YSEhBAaGkpMTAxr1qzhzp07aLVaevXqRbdu3YD8Z5zv378fe3v7Mj2DJiYmhtWrV5OZmUlSUhLu7u688847WFlZAfDtt99y4cIFtFot/fr1o127dgDF9luIyibJXBjk7NmzxMXF0bRpU06dOsXVq1dZvHgxtra2nD59mj179jBlyhSsra05efIkc+fO5bPPPmP16tV4enrSr18/4uLiCAkJKXLuo0ePsnv3bqZPn469vT1r165l+/btDB8+nPfff585c+aQl5fH/PnzGTVqFI0bNyY9PZ2PPvqIBg0akJKSwuHDh5k9e3aR/1EYKiwsjCeffJInnniC3Nxcxo8fz/Hjx+nUqRMArq6uDB06lH/++YfJkyfz+eefc+3atWL7LURlk2Qu7utuRQyg1WpxcHDg7bffxsXFBYBGjRpha2sLwPHjx4mLi2PixIn6z6emppKamkpkZKR+nLpOnTq0atWqSFsRERE8+uij2NvbAzBw4EAgf4z7rtjYWG7cuMHSpUsLxXj58mWuXbtGhw4dsLGxAaBr1678+uuvperv66+/TkREBD///DOxsbEkJSWRmZmpf//uYxAaNmxIgwYNOHv2LNHR0cX2W4jKJslc3FdJFW61atX0P2u1Wrp06aJflk6r1ZKUlISdnR0KhaLQ5+634sy/96WlpRW5MKrVarG1tS0UU3JyMra2tqxfv77ENkqyYMEC8vLy6Ny5M35+fkUW8lAq780V0Ol0qFSqB/ZbiMoms1lEubVp04YDBw6QlJQEwM6dO5kyZYr+vV27dgH5T3KMiooq8nkfHx+OHDlCeno6kL926datW/UJU6fTUa9ePaysrNi7d6/+XO+//z4XL16kbdu2hIeHk5aWhlar1R9TGidPniQgIIDOnTsD+csIarVa/ft3Z+BcvHiRuLg4PD09H9hvISqbVOai3Nq0aUOfPn2YNm0aCoUCGxsbPvjgAxQKBW+88QZLlizh3XffpUaNGri7uxf5vJ+fH9euXWPSpElA/ipJb731FtbW1jRt2pT33nuPKVOmEBISwpo1a9i8eTN5eXn07dtX//jbf/75h/Hjx2Nvb0+jRo2KnUqYlZVVZHri9OnTefXVV5k7dy7W1tbY2tri7e1NXFyc/pgbN24wduxYFAoFY8aMwd7e/oH9FqKyyVMThRDCAsgwixBCWABJ5kIIYQEkmQshhAWQZC6EEBZAkrkQQlgASeZCCGEBJJkLIYQFkGQuhBAW4P8AcckYlKASEccAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       125\n",
            "           1       0.95      0.98      0.97       142\n",
            "           2       0.90      0.94      0.92       424\n",
            "           3       0.90      0.64      0.75       317\n",
            "           4       0.83      0.97      0.90       412\n",
            "\n",
            "    accuracy                           0.89      1420\n",
            "   macro avg       0.91      0.90      0.90      1420\n",
            "weighted avg       0.89      0.89      0.88      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [    6    21    23 ... 14181 14192 14196]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1507 - accuracy: 0.93 - ETA: 1s - loss: 0.1766 - accuracy: 0.91 - ETA: 1s - loss: 0.1776 - accuracy: 0.91 - ETA: 1s - loss: 0.1771 - accuracy: 0.92 - ETA: 1s - loss: 0.1818 - accuracy: 0.91 - ETA: 1s - loss: 0.1874 - accuracy: 0.91 - ETA: 1s - loss: 0.1907 - accuracy: 0.91 - ETA: 0s - loss: 0.1895 - accuracy: 0.91 - ETA: 0s - loss: 0.1891 - accuracy: 0.91 - ETA: 0s - loss: 0.1892 - accuracy: 0.91 - ETA: 0s - loss: 0.1888 - accuracy: 0.91 - ETA: 0s - loss: 0.1891 - accuracy: 0.91 - ETA: 0s - loss: 0.1888 - accuracy: 0.91 - ETA: 0s - loss: 0.1891 - accuracy: 0.91 - ETA: 0s - loss: 0.1881 - accuracy: 0.91 - ETA: 0s - loss: 0.1879 - accuracy: 0.91 - ETA: 0s - loss: 0.1881 - accuracy: 0.91 - ETA: 0s - loss: 0.1883 - accuracy: 0.91 - ETA: 0s - loss: 0.1884 - accuracy: 0.91 - ETA: 0s - loss: 0.1878 - accuracy: 0.91 - ETA: 0s - loss: 0.1875 - accuracy: 0.91 - ETA: 0s - loss: 0.1870 - accuracy: 0.91 - ETA: 0s - loss: 0.1876 - accuracy: 0.91 - ETA: 0s - loss: 0.1877 - accuracy: 0.91 - ETA: 0s - loss: 0.1880 - accuracy: 0.91 - 2s 153us/step - loss: 0.1880 - accuracy: 0.9152 - val_loss: 0.1687 - val_accuracy: 0.9218\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1737 - accuracy: 0.93 - ETA: 1s - loss: 0.1946 - accuracy: 0.91 - ETA: 1s - loss: 0.2069 - accuracy: 0.90 - ETA: 1s - loss: 0.1988 - accuracy: 0.91 - ETA: 1s - loss: 0.1968 - accuracy: 0.91 - ETA: 1s - loss: 0.1973 - accuracy: 0.91 - ETA: 0s - loss: 0.1934 - accuracy: 0.91 - ETA: 0s - loss: 0.1952 - accuracy: 0.91 - ETA: 0s - loss: 0.1918 - accuracy: 0.91 - ETA: 0s - loss: 0.1905 - accuracy: 0.91 - ETA: 0s - loss: 0.1896 - accuracy: 0.91 - ETA: 0s - loss: 0.1893 - accuracy: 0.91 - ETA: 0s - loss: 0.1903 - accuracy: 0.91 - ETA: 0s - loss: 0.1898 - accuracy: 0.91 - ETA: 0s - loss: 0.1890 - accuracy: 0.91 - ETA: 0s - loss: 0.1877 - accuracy: 0.91 - ETA: 0s - loss: 0.1881 - accuracy: 0.91 - ETA: 0s - loss: 0.1873 - accuracy: 0.91 - ETA: 0s - loss: 0.1868 - accuracy: 0.91 - ETA: 0s - loss: 0.1861 - accuracy: 0.91 - ETA: 0s - loss: 0.1858 - accuracy: 0.91 - ETA: 0s - loss: 0.1860 - accuracy: 0.91 - ETA: 0s - loss: 0.1873 - accuracy: 0.91 - 1s 146us/step - loss: 0.1877 - accuracy: 0.9159 - val_loss: 0.1511 - val_accuracy: 0.9359\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1768 - accuracy: 0.93 - ETA: 1s - loss: 0.1900 - accuracy: 0.92 - ETA: 1s - loss: 0.1839 - accuracy: 0.92 - ETA: 1s - loss: 0.1792 - accuracy: 0.92 - ETA: 1s - loss: 0.1792 - accuracy: 0.92 - ETA: 0s - loss: 0.1788 - accuracy: 0.92 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1812 - accuracy: 0.92 - ETA: 0s - loss: 0.1827 - accuracy: 0.91 - ETA: 0s - loss: 0.1819 - accuracy: 0.91 - ETA: 0s - loss: 0.1809 - accuracy: 0.92 - ETA: 0s - loss: 0.1814 - accuracy: 0.92 - ETA: 0s - loss: 0.1804 - accuracy: 0.92 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1805 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.92 - ETA: 0s - loss: 0.1797 - accuracy: 0.92 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1800 - accuracy: 0.92 - ETA: 0s - loss: 0.1804 - accuracy: 0.92 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.92 - 1s 140us/step - loss: 0.1806 - accuracy: 0.9208 - val_loss: 0.1502 - val_accuracy: 0.9334\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1800 - accuracy: 0.92 - ETA: 1s - loss: 0.2003 - accuracy: 0.90 - ETA: 1s - loss: 0.1895 - accuracy: 0.91 - ETA: 1s - loss: 0.1867 - accuracy: 0.91 - ETA: 1s - loss: 0.1820 - accuracy: 0.91 - ETA: 0s - loss: 0.1812 - accuracy: 0.91 - ETA: 0s - loss: 0.1798 - accuracy: 0.92 - ETA: 0s - loss: 0.1794 - accuracy: 0.91 - ETA: 0s - loss: 0.1787 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1801 - accuracy: 0.91 - ETA: 0s - loss: 0.1804 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1804 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1788 - accuracy: 0.91 - ETA: 0s - loss: 0.1788 - accuracy: 0.91 - ETA: 0s - loss: 0.1787 - accuracy: 0.91 - ETA: 0s - loss: 0.1814 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1815 - accuracy: 0.91 - ETA: 0s - loss: 0.1822 - accuracy: 0.91 - ETA: 0s - loss: 0.1823 - accuracy: 0.91 - 1s 141us/step - loss: 0.1823 - accuracy: 0.9179 - val_loss: 0.1500 - val_accuracy: 0.9392\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2103 - accuracy: 0.89 - ETA: 1s - loss: 0.1783 - accuracy: 0.91 - ETA: 1s - loss: 0.1774 - accuracy: 0.91 - ETA: 1s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1799 - accuracy: 0.91 - ETA: 0s - loss: 0.1789 - accuracy: 0.91 - ETA: 0s - loss: 0.1794 - accuracy: 0.91 - ETA: 0s - loss: 0.1776 - accuracy: 0.91 - ETA: 0s - loss: 0.1773 - accuracy: 0.91 - ETA: 0s - loss: 0.1766 - accuracy: 0.91 - ETA: 0s - loss: 0.1780 - accuracy: 0.91 - ETA: 0s - loss: 0.1781 - accuracy: 0.91 - ETA: 0s - loss: 0.1790 - accuracy: 0.91 - ETA: 0s - loss: 0.1796 - accuracy: 0.91 - ETA: 0s - loss: 0.1798 - accuracy: 0.91 - ETA: 0s - loss: 0.1804 - accuracy: 0.91 - ETA: 0s - loss: 0.1811 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1810 - accuracy: 0.91 - ETA: 0s - loss: 0.1809 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1819 - accuracy: 0.91 - ETA: 0s - loss: 0.1814 - accuracy: 0.91 - ETA: 0s - loss: 0.1812 - accuracy: 0.91 - 1s 145us/step - loss: 0.1813 - accuracy: 0.9176 - val_loss: 0.1511 - val_accuracy: 0.9345\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2124 - accuracy: 0.90 - ETA: 1s - loss: 0.1901 - accuracy: 0.91 - ETA: 1s - loss: 0.1802 - accuracy: 0.91 - ETA: 1s - loss: 0.1751 - accuracy: 0.92 - ETA: 1s - loss: 0.1767 - accuracy: 0.92 - ETA: 0s - loss: 0.1789 - accuracy: 0.91 - ETA: 0s - loss: 0.1782 - accuracy: 0.92 - ETA: 0s - loss: 0.1796 - accuracy: 0.91 - ETA: 0s - loss: 0.1808 - accuracy: 0.91 - ETA: 0s - loss: 0.1816 - accuracy: 0.91 - ETA: 0s - loss: 0.1814 - accuracy: 0.91 - ETA: 0s - loss: 0.1815 - accuracy: 0.91 - ETA: 0s - loss: 0.1805 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1804 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1816 - accuracy: 0.91 - ETA: 0s - loss: 0.1810 - accuracy: 0.91 - ETA: 0s - loss: 0.1812 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1820 - accuracy: 0.91 - ETA: 0s - loss: 0.1812 - accuracy: 0.91 - 1s 139us/step - loss: 0.1815 - accuracy: 0.9198 - val_loss: 0.1569 - val_accuracy: 0.9263\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2000 - accuracy: 0.91 - ETA: 1s - loss: 0.1878 - accuracy: 0.90 - ETA: 1s - loss: 0.1943 - accuracy: 0.90 - ETA: 1s - loss: 0.1881 - accuracy: 0.91 - ETA: 1s - loss: 0.1854 - accuracy: 0.91 - ETA: 0s - loss: 0.1826 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1815 - accuracy: 0.91 - ETA: 0s - loss: 0.1808 - accuracy: 0.91 - ETA: 0s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1797 - accuracy: 0.91 - ETA: 0s - loss: 0.1781 - accuracy: 0.91 - ETA: 0s - loss: 0.1781 - accuracy: 0.91 - ETA: 0s - loss: 0.1775 - accuracy: 0.91 - ETA: 0s - loss: 0.1772 - accuracy: 0.92 - ETA: 0s - loss: 0.1777 - accuracy: 0.91 - ETA: 0s - loss: 0.1781 - accuracy: 0.91 - ETA: 0s - loss: 0.1778 - accuracy: 0.91 - ETA: 0s - loss: 0.1780 - accuracy: 0.91 - ETA: 0s - loss: 0.1776 - accuracy: 0.91 - ETA: 0s - loss: 0.1779 - accuracy: 0.91 - 1s 142us/step - loss: 0.1784 - accuracy: 0.9190 - val_loss: 0.1468 - val_accuracy: 0.9383\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2078 - accuracy: 0.89 - ETA: 1s - loss: 0.1718 - accuracy: 0.92 - ETA: 1s - loss: 0.1744 - accuracy: 0.92 - ETA: 0s - loss: 0.1748 - accuracy: 0.91 - ETA: 0s - loss: 0.1775 - accuracy: 0.91 - ETA: 0s - loss: 0.1752 - accuracy: 0.92 - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - ETA: 0s - loss: 0.1752 - accuracy: 0.92 - ETA: 0s - loss: 0.1754 - accuracy: 0.92 - ETA: 0s - loss: 0.1773 - accuracy: 0.91 - ETA: 0s - loss: 0.1774 - accuracy: 0.91 - ETA: 0s - loss: 0.1778 - accuracy: 0.91 - ETA: 0s - loss: 0.1772 - accuracy: 0.91 - ETA: 0s - loss: 0.1765 - accuracy: 0.92 - ETA: 0s - loss: 0.1768 - accuracy: 0.91 - ETA: 0s - loss: 0.1769 - accuracy: 0.91 - ETA: 0s - loss: 0.1774 - accuracy: 0.91 - ETA: 0s - loss: 0.1784 - accuracy: 0.91 - ETA: 0s - loss: 0.1783 - accuracy: 0.91 - ETA: 0s - loss: 0.1784 - accuracy: 0.91 - ETA: 0s - loss: 0.1795 - accuracy: 0.91 - ETA: 0s - loss: 0.1793 - accuracy: 0.91 - 1s 136us/step - loss: 0.1793 - accuracy: 0.9188 - val_loss: 0.1468 - val_accuracy: 0.9347\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1790 - accuracy: 0.92 - ETA: 1s - loss: 0.1919 - accuracy: 0.91 - ETA: 1s - loss: 0.1824 - accuracy: 0.91 - ETA: 1s - loss: 0.1776 - accuracy: 0.92 - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - ETA: 0s - loss: 0.1770 - accuracy: 0.92 - ETA: 0s - loss: 0.1764 - accuracy: 0.92 - ETA: 0s - loss: 0.1785 - accuracy: 0.91 - ETA: 0s - loss: 0.1770 - accuracy: 0.92 - ETA: 0s - loss: 0.1775 - accuracy: 0.91 - ETA: 0s - loss: 0.1770 - accuracy: 0.92 - ETA: 0s - loss: 0.1760 - accuracy: 0.92 - ETA: 0s - loss: 0.1767 - accuracy: 0.92 - ETA: 0s - loss: 0.1768 - accuracy: 0.92 - ETA: 0s - loss: 0.1770 - accuracy: 0.92 - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - ETA: 0s - loss: 0.1773 - accuracy: 0.91 - ETA: 0s - loss: 0.1775 - accuracy: 0.91 - ETA: 0s - loss: 0.1773 - accuracy: 0.91 - ETA: 0s - loss: 0.1776 - accuracy: 0.91 - ETA: 0s - loss: 0.1778 - accuracy: 0.91 - 1s 134us/step - loss: 0.1781 - accuracy: 0.9194 - val_loss: 0.1449 - val_accuracy: 0.9383\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2051 - accuracy: 0.91 - ETA: 1s - loss: 0.1730 - accuracy: 0.92 - ETA: 1s - loss: 0.1807 - accuracy: 0.92 - ETA: 1s - loss: 0.1731 - accuracy: 0.92 - ETA: 1s - loss: 0.1720 - accuracy: 0.92 - ETA: 0s - loss: 0.1739 - accuracy: 0.92 - ETA: 0s - loss: 0.1769 - accuracy: 0.92 - ETA: 0s - loss: 0.1771 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - ETA: 0s - loss: 0.1764 - accuracy: 0.92 - ETA: 0s - loss: 0.1760 - accuracy: 0.92 - ETA: 0s - loss: 0.1767 - accuracy: 0.92 - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - ETA: 0s - loss: 0.1762 - accuracy: 0.92 - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - ETA: 0s - loss: 0.1751 - accuracy: 0.92 - ETA: 0s - loss: 0.1752 - accuracy: 0.92 - ETA: 0s - loss: 0.1747 - accuracy: 0.92 - ETA: 0s - loss: 0.1761 - accuracy: 0.92 - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - 1s 135us/step - loss: 0.1772 - accuracy: 0.9201 - val_loss: 0.1537 - val_accuracy: 0.9279\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2068 - accuracy: 0.91 - ETA: 1s - loss: 0.1982 - accuracy: 0.91 - ETA: 1s - loss: 0.1897 - accuracy: 0.91 - ETA: 1s - loss: 0.1809 - accuracy: 0.92 - ETA: 1s - loss: 0.1784 - accuracy: 0.92 - ETA: 0s - loss: 0.1771 - accuracy: 0.92 - ETA: 0s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1798 - accuracy: 0.91 - ETA: 0s - loss: 0.1796 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1800 - accuracy: 0.91 - ETA: 0s - loss: 0.1808 - accuracy: 0.91 - ETA: 0s - loss: 0.1814 - accuracy: 0.91 - ETA: 0s - loss: 0.1831 - accuracy: 0.91 - ETA: 0s - loss: 0.1834 - accuracy: 0.91 - ETA: 0s - loss: 0.1812 - accuracy: 0.91 - ETA: 0s - loss: 0.1807 - accuracy: 0.91 - ETA: 0s - loss: 0.1803 - accuracy: 0.91 - ETA: 0s - loss: 0.1801 - accuracy: 0.91 - ETA: 0s - loss: 0.1799 - accuracy: 0.91 - ETA: 0s - loss: 0.1804 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1813 - accuracy: 0.91 - 1s 143us/step - loss: 0.1810 - accuracy: 0.9189 - val_loss: 0.1438 - val_accuracy: 0.9414\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2006 - accuracy: 0.91 - ETA: 1s - loss: 0.1805 - accuracy: 0.91 - ETA: 1s - loss: 0.1813 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1780 - accuracy: 0.91 - ETA: 0s - loss: 0.1781 - accuracy: 0.91 - ETA: 0s - loss: 0.1784 - accuracy: 0.92 - ETA: 0s - loss: 0.1791 - accuracy: 0.92 - ETA: 0s - loss: 0.1776 - accuracy: 0.92 - ETA: 0s - loss: 0.1774 - accuracy: 0.92 - ETA: 0s - loss: 0.1777 - accuracy: 0.92 - ETA: 0s - loss: 0.1773 - accuracy: 0.92 - ETA: 0s - loss: 0.1775 - accuracy: 0.92 - ETA: 0s - loss: 0.1784 - accuracy: 0.92 - ETA: 0s - loss: 0.1785 - accuracy: 0.92 - ETA: 0s - loss: 0.1795 - accuracy: 0.92 - ETA: 0s - loss: 0.1781 - accuracy: 0.92 - ETA: 0s - loss: 0.1763 - accuracy: 0.92 - ETA: 0s - loss: 0.1762 - accuracy: 0.92 - ETA: 0s - loss: 0.1772 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - ETA: 0s - loss: 0.1758 - accuracy: 0.92 - ETA: 0s - loss: 0.1767 - accuracy: 0.92 - 1s 138us/step - loss: 0.1767 - accuracy: 0.9213 - val_loss: 0.1430 - val_accuracy: 0.9383\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1463 - accuracy: 0.94 - ETA: 1s - loss: 0.1829 - accuracy: 0.91 - ETA: 1s - loss: 0.1793 - accuracy: 0.91 - ETA: 1s - loss: 0.1844 - accuracy: 0.91 - ETA: 1s - loss: 0.1843 - accuracy: 0.91 - ETA: 1s - loss: 0.1806 - accuracy: 0.91 - ETA: 0s - loss: 0.1802 - accuracy: 0.91 - ETA: 0s - loss: 0.1779 - accuracy: 0.91 - ETA: 0s - loss: 0.1777 - accuracy: 0.92 - ETA: 0s - loss: 0.1789 - accuracy: 0.91 - ETA: 0s - loss: 0.1767 - accuracy: 0.92 - ETA: 0s - loss: 0.1764 - accuracy: 0.92 - ETA: 0s - loss: 0.1772 - accuracy: 0.91 - ETA: 0s - loss: 0.1779 - accuracy: 0.91 - ETA: 0s - loss: 0.1777 - accuracy: 0.91 - ETA: 0s - loss: 0.1772 - accuracy: 0.91 - ETA: 0s - loss: 0.1762 - accuracy: 0.92 - ETA: 0s - loss: 0.1760 - accuracy: 0.92 - ETA: 0s - loss: 0.1757 - accuracy: 0.92 - ETA: 0s - loss: 0.1753 - accuracy: 0.92 - ETA: 0s - loss: 0.1754 - accuracy: 0.92 - ETA: 0s - loss: 0.1748 - accuracy: 0.92 - 1s 140us/step - loss: 0.1753 - accuracy: 0.9214 - val_loss: 0.1422 - val_accuracy: 0.9392\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2007 - accuracy: 0.92 - ETA: 1s - loss: 0.1584 - accuracy: 0.93 - ETA: 1s - loss: 0.1629 - accuracy: 0.93 - ETA: 1s - loss: 0.1685 - accuracy: 0.92 - ETA: 0s - loss: 0.1722 - accuracy: 0.92 - ETA: 0s - loss: 0.1712 - accuracy: 0.92 - ETA: 0s - loss: 0.1727 - accuracy: 0.92 - ETA: 0s - loss: 0.1723 - accuracy: 0.92 - ETA: 0s - loss: 0.1732 - accuracy: 0.92 - ETA: 0s - loss: 0.1733 - accuracy: 0.92 - ETA: 0s - loss: 0.1739 - accuracy: 0.92 - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - ETA: 0s - loss: 0.1753 - accuracy: 0.92 - ETA: 0s - loss: 0.1761 - accuracy: 0.92 - ETA: 0s - loss: 0.1770 - accuracy: 0.91 - ETA: 0s - loss: 0.1766 - accuracy: 0.91 - ETA: 0s - loss: 0.1754 - accuracy: 0.91 - ETA: 0s - loss: 0.1759 - accuracy: 0.91 - ETA: 0s - loss: 0.1756 - accuracy: 0.92 - ETA: 0s - loss: 0.1764 - accuracy: 0.92 - ETA: 0s - loss: 0.1753 - accuracy: 0.92 - ETA: 0s - loss: 0.1752 - accuracy: 0.92 - 1s 137us/step - loss: 0.1751 - accuracy: 0.9206 - val_loss: 0.1423 - val_accuracy: 0.9354\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1507 - accuracy: 0.93 - ETA: 1s - loss: 0.1602 - accuracy: 0.92 - ETA: 1s - loss: 0.1579 - accuracy: 0.93 - ETA: 1s - loss: 0.1612 - accuracy: 0.93 - ETA: 1s - loss: 0.1611 - accuracy: 0.93 - ETA: 1s - loss: 0.1582 - accuracy: 0.93 - ETA: 0s - loss: 0.1623 - accuracy: 0.92 - ETA: 0s - loss: 0.1661 - accuracy: 0.92 - ETA: 0s - loss: 0.1669 - accuracy: 0.92 - ETA: 0s - loss: 0.1682 - accuracy: 0.92 - ETA: 0s - loss: 0.1679 - accuracy: 0.92 - ETA: 0s - loss: 0.1673 - accuracy: 0.92 - ETA: 0s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1678 - accuracy: 0.92 - ETA: 0s - loss: 0.1681 - accuracy: 0.92 - ETA: 0s - loss: 0.1681 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1693 - accuracy: 0.92 - ETA: 0s - loss: 0.1694 - accuracy: 0.92 - ETA: 0s - loss: 0.1694 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1707 - accuracy: 0.92 - ETA: 0s - loss: 0.1704 - accuracy: 0.92 - 1s 138us/step - loss: 0.1703 - accuracy: 0.9228 - val_loss: 0.1401 - val_accuracy: 0.9405\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1806 - accuracy: 0.92 - ETA: 1s - loss: 0.1737 - accuracy: 0.92 - ETA: 1s - loss: 0.1768 - accuracy: 0.92 - ETA: 1s - loss: 0.1763 - accuracy: 0.92 - ETA: 1s - loss: 0.1747 - accuracy: 0.92 - ETA: 0s - loss: 0.1745 - accuracy: 0.92 - ETA: 0s - loss: 0.1774 - accuracy: 0.92 - ETA: 0s - loss: 0.1764 - accuracy: 0.92 - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - ETA: 0s - loss: 0.1735 - accuracy: 0.92 - ETA: 0s - loss: 0.1735 - accuracy: 0.92 - ETA: 0s - loss: 0.1728 - accuracy: 0.92 - ETA: 0s - loss: 0.1721 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1726 - accuracy: 0.92 - ETA: 0s - loss: 0.1730 - accuracy: 0.92 - ETA: 0s - loss: 0.1729 - accuracy: 0.92 - ETA: 0s - loss: 0.1727 - accuracy: 0.92 - ETA: 0s - loss: 0.1722 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1718 - accuracy: 0.92 - ETA: 0s - loss: 0.1717 - accuracy: 0.92 - ETA: 0s - loss: 0.1718 - accuracy: 0.92 - 1s 142us/step - loss: 0.1719 - accuracy: 0.9223 - val_loss: 0.1398 - val_accuracy: 0.9397\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1963 - accuracy: 0.90 - ETA: 1s - loss: 0.1770 - accuracy: 0.91 - ETA: 1s - loss: 0.1753 - accuracy: 0.91 - ETA: 1s - loss: 0.1771 - accuracy: 0.91 - ETA: 1s - loss: 0.1756 - accuracy: 0.92 - ETA: 0s - loss: 0.1755 - accuracy: 0.91 - ETA: 0s - loss: 0.1745 - accuracy: 0.92 - ETA: 0s - loss: 0.1746 - accuracy: 0.92 - ETA: 0s - loss: 0.1760 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - ETA: 0s - loss: 0.1773 - accuracy: 0.92 - ETA: 0s - loss: 0.1759 - accuracy: 0.92 - ETA: 0s - loss: 0.1748 - accuracy: 0.92 - ETA: 0s - loss: 0.1738 - accuracy: 0.92 - ETA: 0s - loss: 0.1736 - accuracy: 0.92 - ETA: 0s - loss: 0.1739 - accuracy: 0.92 - ETA: 0s - loss: 0.1733 - accuracy: 0.92 - ETA: 0s - loss: 0.1730 - accuracy: 0.92 - ETA: 0s - loss: 0.1741 - accuracy: 0.92 - ETA: 0s - loss: 0.1737 - accuracy: 0.92 - ETA: 0s - loss: 0.1746 - accuracy: 0.92 - ETA: 0s - loss: 0.1756 - accuracy: 0.91 - 1s 135us/step - loss: 0.1757 - accuracy: 0.9198 - val_loss: 0.1391 - val_accuracy: 0.9428\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1477 - accuracy: 0.93 - ETA: 1s - loss: 0.1522 - accuracy: 0.93 - ETA: 1s - loss: 0.1654 - accuracy: 0.92 - ETA: 1s - loss: 0.1662 - accuracy: 0.92 - ETA: 1s - loss: 0.1658 - accuracy: 0.92 - ETA: 0s - loss: 0.1673 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1684 - accuracy: 0.92 - ETA: 0s - loss: 0.1694 - accuracy: 0.92 - ETA: 0s - loss: 0.1690 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - ETA: 0s - loss: 0.1713 - accuracy: 0.92 - ETA: 0s - loss: 0.1711 - accuracy: 0.92 - ETA: 0s - loss: 0.1699 - accuracy: 0.92 - ETA: 0s - loss: 0.1699 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1723 - accuracy: 0.92 - ETA: 0s - loss: 0.1725 - accuracy: 0.92 - ETA: 0s - loss: 0.1720 - accuracy: 0.92 - ETA: 0s - loss: 0.1711 - accuracy: 0.92 - 1s 145us/step - loss: 0.1715 - accuracy: 0.9230 - val_loss: 0.1407 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1560 - accuracy: 0.92 - ETA: 1s - loss: 0.1622 - accuracy: 0.92 - ETA: 1s - loss: 0.1725 - accuracy: 0.91 - ETA: 1s - loss: 0.1713 - accuracy: 0.91 - ETA: 1s - loss: 0.1696 - accuracy: 0.92 - ETA: 1s - loss: 0.1696 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1676 - accuracy: 0.92 - ETA: 0s - loss: 0.1668 - accuracy: 0.92 - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - ETA: 0s - loss: 0.1704 - accuracy: 0.92 - ETA: 0s - loss: 0.1699 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1705 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1705 - accuracy: 0.92 - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - 1s 139us/step - loss: 0.1701 - accuracy: 0.9236 - val_loss: 0.1390 - val_accuracy: 0.9405\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1462 - accuracy: 0.94 - ETA: 1s - loss: 0.1698 - accuracy: 0.92 - ETA: 1s - loss: 0.1662 - accuracy: 0.92 - ETA: 1s - loss: 0.1679 - accuracy: 0.92 - ETA: 0s - loss: 0.1732 - accuracy: 0.92 - ETA: 0s - loss: 0.1749 - accuracy: 0.92 - ETA: 0s - loss: 0.1736 - accuracy: 0.92 - ETA: 0s - loss: 0.1741 - accuracy: 0.92 - ETA: 0s - loss: 0.1722 - accuracy: 0.92 - ETA: 0s - loss: 0.1720 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1713 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1707 - accuracy: 0.92 - ETA: 0s - loss: 0.1703 - accuracy: 0.92 - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - ETA: 0s - loss: 0.1693 - accuracy: 0.92 - ETA: 0s - loss: 0.1691 - accuracy: 0.92 - ETA: 0s - loss: 0.1690 - accuracy: 0.92 - ETA: 0s - loss: 0.1703 - accuracy: 0.92 - ETA: 0s - loss: 0.1698 - accuracy: 0.92 - 1s 136us/step - loss: 0.1704 - accuracy: 0.9236 - val_loss: 0.1434 - val_accuracy: 0.9409\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2032 - accuracy: 0.89 - ETA: 1s - loss: 0.1732 - accuracy: 0.91 - ETA: 1s - loss: 0.1734 - accuracy: 0.91 - ETA: 1s - loss: 0.1717 - accuracy: 0.92 - ETA: 0s - loss: 0.1743 - accuracy: 0.91 - ETA: 0s - loss: 0.1750 - accuracy: 0.92 - ETA: 0s - loss: 0.1756 - accuracy: 0.91 - ETA: 0s - loss: 0.1751 - accuracy: 0.91 - ETA: 0s - loss: 0.1740 - accuracy: 0.91 - ETA: 0s - loss: 0.1731 - accuracy: 0.92 - ETA: 0s - loss: 0.1733 - accuracy: 0.92 - ETA: 0s - loss: 0.1726 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - ETA: 0s - loss: 0.1728 - accuracy: 0.92 - ETA: 0s - loss: 0.1736 - accuracy: 0.92 - ETA: 0s - loss: 0.1722 - accuracy: 0.92 - ETA: 0s - loss: 0.1720 - accuracy: 0.92 - ETA: 0s - loss: 0.1726 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1709 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - 1s 137us/step - loss: 0.1713 - accuracy: 0.9222 - val_loss: 0.1370 - val_accuracy: 0.9405\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2061 - accuracy: 0.91 - ETA: 1s - loss: 0.1726 - accuracy: 0.92 - ETA: 1s - loss: 0.1737 - accuracy: 0.92 - ETA: 1s - loss: 0.1777 - accuracy: 0.92 - ETA: 1s - loss: 0.1732 - accuracy: 0.92 - ETA: 0s - loss: 0.1761 - accuracy: 0.92 - ETA: 0s - loss: 0.1738 - accuracy: 0.92 - ETA: 0s - loss: 0.1758 - accuracy: 0.91 - ETA: 0s - loss: 0.1724 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1704 - accuracy: 0.92 - ETA: 0s - loss: 0.1696 - accuracy: 0.92 - ETA: 0s - loss: 0.1694 - accuracy: 0.92 - ETA: 0s - loss: 0.1679 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1664 - accuracy: 0.92 - ETA: 0s - loss: 0.1653 - accuracy: 0.92 - ETA: 0s - loss: 0.1652 - accuracy: 0.92 - ETA: 0s - loss: 0.1647 - accuracy: 0.92 - ETA: 0s - loss: 0.1651 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - 1s 145us/step - loss: 0.1660 - accuracy: 0.9264 - val_loss: 0.1349 - val_accuracy: 0.9405\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1766 - accuracy: 0.92 - ETA: 1s - loss: 0.1700 - accuracy: 0.92 - ETA: 1s - loss: 0.1723 - accuracy: 0.92 - ETA: 1s - loss: 0.1716 - accuracy: 0.92 - ETA: 1s - loss: 0.1711 - accuracy: 0.92 - ETA: 1s - loss: 0.1677 - accuracy: 0.92 - ETA: 1s - loss: 0.1698 - accuracy: 0.92 - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - ETA: 0s - loss: 0.1711 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1723 - accuracy: 0.92 - ETA: 0s - loss: 0.1731 - accuracy: 0.92 - ETA: 0s - loss: 0.1719 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1720 - accuracy: 0.92 - ETA: 0s - loss: 0.1718 - accuracy: 0.92 - ETA: 0s - loss: 0.1708 - accuracy: 0.92 - ETA: 0s - loss: 0.1712 - accuracy: 0.92 - ETA: 0s - loss: 0.1710 - accuracy: 0.92 - ETA: 0s - loss: 0.1707 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1697 - accuracy: 0.92 - ETA: 0s - loss: 0.1698 - accuracy: 0.92 - 1s 146us/step - loss: 0.1698 - accuracy: 0.9246 - val_loss: 0.1347 - val_accuracy: 0.9425\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1794 - accuracy: 0.92 - ETA: 1s - loss: 0.1694 - accuracy: 0.92 - ETA: 1s - loss: 0.1743 - accuracy: 0.92 - ETA: 1s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1642 - accuracy: 0.92 - ETA: 0s - loss: 0.1628 - accuracy: 0.92 - ETA: 0s - loss: 0.1638 - accuracy: 0.92 - ETA: 0s - loss: 0.1629 - accuracy: 0.92 - ETA: 0s - loss: 0.1635 - accuracy: 0.92 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - ETA: 0s - loss: 0.1678 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1682 - accuracy: 0.92 - ETA: 0s - loss: 0.1688 - accuracy: 0.92 - ETA: 0s - loss: 0.1684 - accuracy: 0.92 - ETA: 0s - loss: 0.1700 - accuracy: 0.92 - ETA: 0s - loss: 0.1698 - accuracy: 0.92 - 1s 141us/step - loss: 0.1693 - accuracy: 0.9241 - val_loss: 0.1353 - val_accuracy: 0.9445\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1621 - accuracy: 0.92 - ETA: 1s - loss: 0.1597 - accuracy: 0.92 - ETA: 1s - loss: 0.1649 - accuracy: 0.92 - ETA: 1s - loss: 0.1696 - accuracy: 0.92 - ETA: 1s - loss: 0.1703 - accuracy: 0.92 - ETA: 0s - loss: 0.1690 - accuracy: 0.92 - ETA: 0s - loss: 0.1697 - accuracy: 0.92 - ETA: 0s - loss: 0.1707 - accuracy: 0.92 - ETA: 0s - loss: 0.1690 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1692 - accuracy: 0.92 - ETA: 0s - loss: 0.1713 - accuracy: 0.92 - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1716 - accuracy: 0.92 - ETA: 0s - loss: 0.1714 - accuracy: 0.92 - ETA: 0s - loss: 0.1707 - accuracy: 0.92 - ETA: 0s - loss: 0.1706 - accuracy: 0.92 - ETA: 0s - loss: 0.1703 - accuracy: 0.92 - ETA: 0s - loss: 0.1700 - accuracy: 0.92 - ETA: 0s - loss: 0.1701 - accuracy: 0.92 - ETA: 0s - loss: 0.1698 - accuracy: 0.92 - ETA: 0s - loss: 0.1693 - accuracy: 0.92 - ETA: 0s - loss: 0.1700 - accuracy: 0.92 - 1s 142us/step - loss: 0.1700 - accuracy: 0.9220 - val_loss: 0.1361 - val_accuracy: 0.9380\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1831 - accuracy: 0.92 - ETA: 1s - loss: 0.1647 - accuracy: 0.93 - ETA: 1s - loss: 0.1692 - accuracy: 0.92 - ETA: 1s - loss: 0.1695 - accuracy: 0.92 - ETA: 1s - loss: 0.1667 - accuracy: 0.92 - ETA: 0s - loss: 0.1710 - accuracy: 0.92 - ETA: 0s - loss: 0.1692 - accuracy: 0.92 - ETA: 0s - loss: 0.1690 - accuracy: 0.92 - ETA: 0s - loss: 0.1683 - accuracy: 0.92 - ETA: 0s - loss: 0.1683 - accuracy: 0.92 - ETA: 0s - loss: 0.1689 - accuracy: 0.92 - ETA: 0s - loss: 0.1687 - accuracy: 0.92 - ETA: 0s - loss: 0.1696 - accuracy: 0.92 - ETA: 0s - loss: 0.1692 - accuracy: 0.92 - ETA: 0s - loss: 0.1697 - accuracy: 0.92 - ETA: 0s - loss: 0.1699 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1664 - accuracy: 0.92 - ETA: 0s - loss: 0.1676 - accuracy: 0.92 - ETA: 0s - loss: 0.1678 - accuracy: 0.92 - ETA: 0s - loss: 0.1673 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1660 - accuracy: 0.92 - 2s 155us/step - loss: 0.1662 - accuracy: 0.9253 - val_loss: 0.1326 - val_accuracy: 0.9422\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1653 - accuracy: 0.93 - ETA: 1s - loss: 0.1693 - accuracy: 0.92 - ETA: 1s - loss: 0.1643 - accuracy: 0.92 - ETA: 1s - loss: 0.1657 - accuracy: 0.92 - ETA: 1s - loss: 0.1669 - accuracy: 0.92 - ETA: 0s - loss: 0.1662 - accuracy: 0.92 - ETA: 0s - loss: 0.1668 - accuracy: 0.92 - ETA: 0s - loss: 0.1681 - accuracy: 0.92 - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - ETA: 0s - loss: 0.1658 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1664 - accuracy: 0.92 - ETA: 0s - loss: 0.1674 - accuracy: 0.92 - ETA: 0s - loss: 0.1685 - accuracy: 0.92 - ETA: 0s - loss: 0.1681 - accuracy: 0.92 - ETA: 0s - loss: 0.1672 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1678 - accuracy: 0.92 - ETA: 0s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1670 - accuracy: 0.92 - ETA: 0s - loss: 0.1668 - accuracy: 0.92 - 1s 138us/step - loss: 0.1663 - accuracy: 0.9245 - val_loss: 0.1344 - val_accuracy: 0.9451\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1899 - accuracy: 0.92 - ETA: 1s - loss: 0.1665 - accuracy: 0.92 - ETA: 1s - loss: 0.1665 - accuracy: 0.92 - ETA: 1s - loss: 0.1655 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1667 - accuracy: 0.92 - ETA: 0s - loss: 0.1673 - accuracy: 0.92 - ETA: 0s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1670 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1668 - accuracy: 0.92 - ETA: 0s - loss: 0.1663 - accuracy: 0.92 - ETA: 0s - loss: 0.1661 - accuracy: 0.92 - ETA: 0s - loss: 0.1663 - accuracy: 0.92 - ETA: 0s - loss: 0.1669 - accuracy: 0.92 - ETA: 0s - loss: 0.1663 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1681 - accuracy: 0.92 - 1s 139us/step - loss: 0.1683 - accuracy: 0.9237 - val_loss: 0.1343 - val_accuracy: 0.9400\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1640 - accuracy: 0.92 - ETA: 1s - loss: 0.1703 - accuracy: 0.92 - ETA: 1s - loss: 0.1712 - accuracy: 0.92 - ETA: 1s - loss: 0.1662 - accuracy: 0.92 - ETA: 0s - loss: 0.1644 - accuracy: 0.92 - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - ETA: 0s - loss: 0.1656 - accuracy: 0.92 - ETA: 0s - loss: 0.1633 - accuracy: 0.92 - ETA: 0s - loss: 0.1634 - accuracy: 0.92 - ETA: 0s - loss: 0.1638 - accuracy: 0.92 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - ETA: 0s - loss: 0.1635 - accuracy: 0.92 - ETA: 0s - loss: 0.1639 - accuracy: 0.92 - ETA: 0s - loss: 0.1644 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1651 - accuracy: 0.92 - ETA: 0s - loss: 0.1648 - accuracy: 0.92 - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - ETA: 0s - loss: 0.1663 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1674 - accuracy: 0.92 - 1s 142us/step - loss: 0.1676 - accuracy: 0.9248 - val_loss: 0.1338 - val_accuracy: 0.9420\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1364 - accuracy: 0.93 - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1632 - accuracy: 0.92 - ETA: 1s - loss: 0.1667 - accuracy: 0.92 - ETA: 1s - loss: 0.1648 - accuracy: 0.92 - ETA: 0s - loss: 0.1639 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1643 - accuracy: 0.92 - ETA: 0s - loss: 0.1641 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1658 - accuracy: 0.92 - ETA: 0s - loss: 0.1660 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1646 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1652 - accuracy: 0.92 - ETA: 0s - loss: 0.1647 - accuracy: 0.92 - ETA: 0s - loss: 0.1649 - accuracy: 0.92 - ETA: 0s - loss: 0.1642 - accuracy: 0.92 - ETA: 0s - loss: 0.1638 - accuracy: 0.92 - ETA: 0s - loss: 0.1641 - accuracy: 0.92 - ETA: 0s - loss: 0.1646 - accuracy: 0.92 - 1s 140us/step - loss: 0.1650 - accuracy: 0.9244 - val_loss: 0.1335 - val_accuracy: 0.9376\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1954 - accuracy: 0.91 - ETA: 1s - loss: 0.1706 - accuracy: 0.91 - ETA: 1s - loss: 0.1694 - accuracy: 0.91 - ETA: 1s - loss: 0.1676 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1672 - accuracy: 0.92 - ETA: 0s - loss: 0.1699 - accuracy: 0.92 - ETA: 0s - loss: 0.1683 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1660 - accuracy: 0.92 - ETA: 0s - loss: 0.1661 - accuracy: 0.92 - ETA: 0s - loss: 0.1651 - accuracy: 0.92 - ETA: 0s - loss: 0.1636 - accuracy: 0.92 - ETA: 0s - loss: 0.1632 - accuracy: 0.92 - ETA: 0s - loss: 0.1628 - accuracy: 0.92 - ETA: 0s - loss: 0.1631 - accuracy: 0.92 - ETA: 0s - loss: 0.1627 - accuracy: 0.92 - ETA: 0s - loss: 0.1634 - accuracy: 0.92 - ETA: 0s - loss: 0.1627 - accuracy: 0.92 - ETA: 0s - loss: 0.1629 - accuracy: 0.92 - ETA: 0s - loss: 0.1630 - accuracy: 0.92 - ETA: 0s - loss: 0.1641 - accuracy: 0.92 - 1s 141us/step - loss: 0.1637 - accuracy: 0.9253 - val_loss: 0.1315 - val_accuracy: 0.9459\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2014 - accuracy: 0.90 - ETA: 1s - loss: 0.1563 - accuracy: 0.92 - ETA: 1s - loss: 0.1614 - accuracy: 0.92 - ETA: 1s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1729 - accuracy: 0.92 - ETA: 0s - loss: 0.1708 - accuracy: 0.92 - ETA: 0s - loss: 0.1693 - accuracy: 0.92 - ETA: 0s - loss: 0.1673 - accuracy: 0.92 - ETA: 0s - loss: 0.1662 - accuracy: 0.92 - ETA: 0s - loss: 0.1661 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1668 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1672 - accuracy: 0.92 - ETA: 0s - loss: 0.1670 - accuracy: 0.92 - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - ETA: 0s - loss: 0.1662 - accuracy: 0.92 - ETA: 0s - loss: 0.1665 - accuracy: 0.92 - ETA: 0s - loss: 0.1658 - accuracy: 0.92 - ETA: 0s - loss: 0.1651 - accuracy: 0.92 - 1s 141us/step - loss: 0.1646 - accuracy: 0.9267 - val_loss: 0.1291 - val_accuracy: 0.9428\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1915 - accuracy: 0.89 - ETA: 1s - loss: 0.1739 - accuracy: 0.91 - ETA: 1s - loss: 0.1700 - accuracy: 0.91 - ETA: 1s - loss: 0.1658 - accuracy: 0.92 - ETA: 1s - loss: 0.1648 - accuracy: 0.92 - ETA: 0s - loss: 0.1603 - accuracy: 0.92 - ETA: 0s - loss: 0.1573 - accuracy: 0.92 - ETA: 0s - loss: 0.1573 - accuracy: 0.92 - ETA: 0s - loss: 0.1574 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1597 - accuracy: 0.92 - ETA: 0s - loss: 0.1595 - accuracy: 0.92 - ETA: 0s - loss: 0.1609 - accuracy: 0.92 - ETA: 0s - loss: 0.1613 - accuracy: 0.92 - ETA: 0s - loss: 0.1630 - accuracy: 0.92 - ETA: 0s - loss: 0.1623 - accuracy: 0.92 - ETA: 0s - loss: 0.1623 - accuracy: 0.92 - ETA: 0s - loss: 0.1626 - accuracy: 0.92 - ETA: 0s - loss: 0.1625 - accuracy: 0.92 - ETA: 0s - loss: 0.1621 - accuracy: 0.92 - ETA: 0s - loss: 0.1625 - accuracy: 0.92 - ETA: 0s - loss: 0.1619 - accuracy: 0.92 - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - 1s 146us/step - loss: 0.1618 - accuracy: 0.9274 - val_loss: 0.1284 - val_accuracy: 0.9444\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1446 - accuracy: 0.93 - ETA: 1s - loss: 0.1497 - accuracy: 0.93 - ETA: 1s - loss: 0.1545 - accuracy: 0.92 - ETA: 1s - loss: 0.1569 - accuracy: 0.92 - ETA: 0s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1599 - accuracy: 0.92 - ETA: 0s - loss: 0.1617 - accuracy: 0.92 - ETA: 0s - loss: 0.1619 - accuracy: 0.92 - ETA: 0s - loss: 0.1616 - accuracy: 0.92 - ETA: 0s - loss: 0.1619 - accuracy: 0.92 - ETA: 0s - loss: 0.1607 - accuracy: 0.92 - ETA: 0s - loss: 0.1646 - accuracy: 0.92 - ETA: 0s - loss: 0.1642 - accuracy: 0.92 - ETA: 0s - loss: 0.1647 - accuracy: 0.92 - ETA: 0s - loss: 0.1636 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.92 - ETA: 0s - loss: 0.1672 - accuracy: 0.92 - ETA: 0s - loss: 0.1664 - accuracy: 0.92 - ETA: 0s - loss: 0.1661 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - ETA: 0s - loss: 0.1655 - accuracy: 0.92 - 1s 144us/step - loss: 0.1654 - accuracy: 0.9242 - val_loss: 0.1288 - val_accuracy: 0.9491\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1552 - accuracy: 0.93 - ETA: 1s - loss: 0.1580 - accuracy: 0.93 - ETA: 1s - loss: 0.1604 - accuracy: 0.93 - ETA: 1s - loss: 0.1601 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1560 - accuracy: 0.93 - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - ETA: 0s - loss: 0.1561 - accuracy: 0.93 - ETA: 0s - loss: 0.1573 - accuracy: 0.93 - ETA: 0s - loss: 0.1576 - accuracy: 0.93 - ETA: 0s - loss: 0.1573 - accuracy: 0.93 - ETA: 0s - loss: 0.1583 - accuracy: 0.93 - ETA: 0s - loss: 0.1591 - accuracy: 0.92 - ETA: 0s - loss: 0.1579 - accuracy: 0.93 - ETA: 0s - loss: 0.1583 - accuracy: 0.92 - ETA: 0s - loss: 0.1583 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1576 - accuracy: 0.93 - ETA: 0s - loss: 0.1586 - accuracy: 0.92 - ETA: 0s - loss: 0.1586 - accuracy: 0.92 - ETA: 0s - loss: 0.1595 - accuracy: 0.92 - ETA: 0s - loss: 0.1598 - accuracy: 0.92 - ETA: 0s - loss: 0.1596 - accuracy: 0.92 - 1s 144us/step - loss: 0.1599 - accuracy: 0.9292 - val_loss: 0.1295 - val_accuracy: 0.9423\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1249 - accuracy: 0.95 - ETA: 1s - loss: 0.1541 - accuracy: 0.92 - ETA: 1s - loss: 0.1694 - accuracy: 0.92 - ETA: 0s - loss: 0.1703 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1680 - accuracy: 0.92 - ETA: 0s - loss: 0.1651 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1637 - accuracy: 0.92 - ETA: 0s - loss: 0.1631 - accuracy: 0.92 - ETA: 0s - loss: 0.1635 - accuracy: 0.92 - ETA: 0s - loss: 0.1627 - accuracy: 0.92 - ETA: 0s - loss: 0.1627 - accuracy: 0.92 - ETA: 0s - loss: 0.1626 - accuracy: 0.92 - ETA: 0s - loss: 0.1622 - accuracy: 0.92 - ETA: 0s - loss: 0.1617 - accuracy: 0.92 - ETA: 0s - loss: 0.1616 - accuracy: 0.92 - ETA: 0s - loss: 0.1614 - accuracy: 0.92 - ETA: 0s - loss: 0.1613 - accuracy: 0.92 - ETA: 0s - loss: 0.1609 - accuracy: 0.92 - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - ETA: 0s - loss: 0.1615 - accuracy: 0.92 - 1s 137us/step - loss: 0.1615 - accuracy: 0.9276 - val_loss: 0.1276 - val_accuracy: 0.9442\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1495 - accuracy: 0.93 - ETA: 1s - loss: 0.1633 - accuracy: 0.92 - ETA: 1s - loss: 0.1592 - accuracy: 0.92 - ETA: 1s - loss: 0.1564 - accuracy: 0.92 - ETA: 1s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1652 - accuracy: 0.92 - ETA: 0s - loss: 0.1642 - accuracy: 0.92 - ETA: 0s - loss: 0.1625 - accuracy: 0.92 - ETA: 0s - loss: 0.1638 - accuracy: 0.92 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - ETA: 0s - loss: 0.1636 - accuracy: 0.92 - ETA: 0s - loss: 0.1646 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1676 - accuracy: 0.92 - ETA: 0s - loss: 0.1683 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1675 - accuracy: 0.92 - ETA: 0s - loss: 0.1670 - accuracy: 0.92 - ETA: 0s - loss: 0.1657 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1643 - accuracy: 0.92 - ETA: 0s - loss: 0.1649 - accuracy: 0.92 - 1s 140us/step - loss: 0.1651 - accuracy: 0.9254 - val_loss: 0.1270 - val_accuracy: 0.9512\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1326 - accuracy: 0.94 - ETA: 1s - loss: 0.1694 - accuracy: 0.92 - ETA: 1s - loss: 0.1627 - accuracy: 0.92 - ETA: 0s - loss: 0.1696 - accuracy: 0.92 - ETA: 0s - loss: 0.1682 - accuracy: 0.92 - ETA: 0s - loss: 0.1653 - accuracy: 0.92 - ETA: 0s - loss: 0.1623 - accuracy: 0.92 - ETA: 0s - loss: 0.1618 - accuracy: 0.92 - ETA: 0s - loss: 0.1643 - accuracy: 0.92 - ETA: 0s - loss: 0.1636 - accuracy: 0.92 - ETA: 0s - loss: 0.1633 - accuracy: 0.92 - ETA: 0s - loss: 0.1622 - accuracy: 0.92 - ETA: 0s - loss: 0.1628 - accuracy: 0.92 - ETA: 0s - loss: 0.1648 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1656 - accuracy: 0.92 - ETA: 0s - loss: 0.1644 - accuracy: 0.92 - ETA: 0s - loss: 0.1639 - accuracy: 0.92 - ETA: 0s - loss: 0.1636 - accuracy: 0.92 - ETA: 0s - loss: 0.1647 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - 1s 134us/step - loss: 0.1645 - accuracy: 0.9257 - val_loss: 0.1257 - val_accuracy: 0.9462\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1650 - accuracy: 0.92 - ETA: 1s - loss: 0.1800 - accuracy: 0.91 - ETA: 1s - loss: 0.1720 - accuracy: 0.92 - ETA: 1s - loss: 0.1662 - accuracy: 0.92 - ETA: 1s - loss: 0.1679 - accuracy: 0.92 - ETA: 1s - loss: 0.1663 - accuracy: 0.92 - ETA: 0s - loss: 0.1645 - accuracy: 0.92 - ETA: 0s - loss: 0.1666 - accuracy: 0.92 - ETA: 0s - loss: 0.1654 - accuracy: 0.92 - ETA: 0s - loss: 0.1686 - accuracy: 0.92 - ETA: 0s - loss: 0.1684 - accuracy: 0.92 - ETA: 0s - loss: 0.1677 - accuracy: 0.92 - ETA: 0s - loss: 0.1664 - accuracy: 0.92 - ETA: 0s - loss: 0.1660 - accuracy: 0.92 - ETA: 0s - loss: 0.1659 - accuracy: 0.92 - ETA: 0s - loss: 0.1650 - accuracy: 0.92 - ETA: 0s - loss: 0.1656 - accuracy: 0.92 - ETA: 0s - loss: 0.1649 - accuracy: 0.92 - ETA: 0s - loss: 0.1644 - accuracy: 0.92 - ETA: 0s - loss: 0.1640 - accuracy: 0.92 - ETA: 0s - loss: 0.1637 - accuracy: 0.92 - ETA: 0s - loss: 0.1646 - accuracy: 0.92 - ETA: 0s - loss: 0.1643 - accuracy: 0.92 - 1s 141us/step - loss: 0.1643 - accuracy: 0.9252 - val_loss: 0.1254 - val_accuracy: 0.9495\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1458 - accuracy: 0.93 - ETA: 1s - loss: 0.1530 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - ETA: 0s - loss: 0.1500 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1527 - accuracy: 0.93 - ETA: 0s - loss: 0.1528 - accuracy: 0.92 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1527 - accuracy: 0.93 - ETA: 0s - loss: 0.1536 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - 1s 142us/step - loss: 0.1544 - accuracy: 0.9308 - val_loss: 0.1265 - val_accuracy: 0.9512\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1649 - accuracy: 0.92 - ETA: 1s - loss: 0.1887 - accuracy: 0.91 - ETA: 1s - loss: 0.1721 - accuracy: 0.92 - ETA: 1s - loss: 0.1683 - accuracy: 0.92 - ETA: 0s - loss: 0.1621 - accuracy: 0.92 - ETA: 0s - loss: 0.1604 - accuracy: 0.92 - ETA: 0s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1591 - accuracy: 0.93 - ETA: 0s - loss: 0.1591 - accuracy: 0.93 - ETA: 0s - loss: 0.1587 - accuracy: 0.93 - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - ETA: 0s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1576 - accuracy: 0.93 - ETA: 0s - loss: 0.1586 - accuracy: 0.93 - ETA: 0s - loss: 0.1590 - accuracy: 0.93 - ETA: 0s - loss: 0.1586 - accuracy: 0.93 - ETA: 0s - loss: 0.1583 - accuracy: 0.93 - ETA: 0s - loss: 0.1582 - accuracy: 0.93 - ETA: 0s - loss: 0.1586 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1591 - accuracy: 0.92 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - 1s 136us/step - loss: 0.1599 - accuracy: 0.9293 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1561 - accuracy: 0.92 - ETA: 1s - loss: 0.1588 - accuracy: 0.92 - ETA: 1s - loss: 0.1647 - accuracy: 0.92 - ETA: 0s - loss: 0.1578 - accuracy: 0.92 - ETA: 0s - loss: 0.1556 - accuracy: 0.93 - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - ETA: 0s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1556 - accuracy: 0.93 - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - ETA: 0s - loss: 0.1572 - accuracy: 0.93 - ETA: 0s - loss: 0.1573 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - 1s 138us/step - loss: 0.1569 - accuracy: 0.9302 - val_loss: 0.1230 - val_accuracy: 0.9473\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1527 - accuracy: 0.94 - ETA: 1s - loss: 0.1549 - accuracy: 0.93 - ETA: 1s - loss: 0.1599 - accuracy: 0.92 - ETA: 1s - loss: 0.1571 - accuracy: 0.92 - ETA: 1s - loss: 0.1579 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - ETA: 0s - loss: 0.1614 - accuracy: 0.92 - ETA: 0s - loss: 0.1598 - accuracy: 0.92 - ETA: 0s - loss: 0.1588 - accuracy: 0.92 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1587 - accuracy: 0.92 - ETA: 0s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - 1s 144us/step - loss: 0.1592 - accuracy: 0.9271 - val_loss: 0.1235 - val_accuracy: 0.9455\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1376 - accuracy: 0.93 - ETA: 1s - loss: 0.1523 - accuracy: 0.92 - ETA: 1s - loss: 0.1595 - accuracy: 0.92 - ETA: 1s - loss: 0.1590 - accuracy: 0.92 - ETA: 1s - loss: 0.1567 - accuracy: 0.92 - ETA: 1s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1552 - accuracy: 0.92 - ETA: 0s - loss: 0.1558 - accuracy: 0.92 - ETA: 0s - loss: 0.1536 - accuracy: 0.93 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - ETA: 0s - loss: 0.1545 - accuracy: 0.93 - ETA: 0s - loss: 0.1579 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1579 - accuracy: 0.92 - ETA: 0s - loss: 0.1590 - accuracy: 0.92 - ETA: 0s - loss: 0.1579 - accuracy: 0.92 - ETA: 0s - loss: 0.1577 - accuracy: 0.92 - ETA: 0s - loss: 0.1573 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1588 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - 1s 140us/step - loss: 0.1589 - accuracy: 0.9286 - val_loss: 0.1219 - val_accuracy: 0.9519\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1478 - accuracy: 0.93 - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1529 - accuracy: 0.93 - ETA: 1s - loss: 0.1541 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.92 - ETA: 0s - loss: 0.1567 - accuracy: 0.92 - ETA: 0s - loss: 0.1591 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.92 - ETA: 0s - loss: 0.1578 - accuracy: 0.92 - ETA: 0s - loss: 0.1574 - accuracy: 0.92 - ETA: 0s - loss: 0.1576 - accuracy: 0.92 - ETA: 0s - loss: 0.1569 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1578 - accuracy: 0.92 - ETA: 0s - loss: 0.1579 - accuracy: 0.92 - ETA: 0s - loss: 0.1576 - accuracy: 0.92 - ETA: 0s - loss: 0.1583 - accuracy: 0.92 - ETA: 0s - loss: 0.1573 - accuracy: 0.93 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1583 - accuracy: 0.92 - ETA: 0s - loss: 0.1577 - accuracy: 0.93 - 1s 144us/step - loss: 0.1583 - accuracy: 0.9296 - val_loss: 0.1229 - val_accuracy: 0.9510\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1582 - accuracy: 0.92 - ETA: 1s - loss: 0.1450 - accuracy: 0.93 - ETA: 1s - loss: 0.1458 - accuracy: 0.93 - ETA: 1s - loss: 0.1476 - accuracy: 0.93 - ETA: 1s - loss: 0.1594 - accuracy: 0.93 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1579 - accuracy: 0.93 - ETA: 0s - loss: 0.1575 - accuracy: 0.93 - ETA: 0s - loss: 0.1565 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1556 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - ETA: 0s - loss: 0.1576 - accuracy: 0.93 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1574 - accuracy: 0.92 - 1s 144us/step - loss: 0.1571 - accuracy: 0.9301 - val_loss: 0.1238 - val_accuracy: 0.9469\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1438 - accuracy: 0.94 - ETA: 1s - loss: 0.1535 - accuracy: 0.92 - ETA: 1s - loss: 0.1594 - accuracy: 0.92 - ETA: 1s - loss: 0.1555 - accuracy: 0.93 - ETA: 0s - loss: 0.1535 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1542 - accuracy: 0.93 - ETA: 0s - loss: 0.1542 - accuracy: 0.93 - ETA: 0s - loss: 0.1533 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - ETA: 0s - loss: 0.1527 - accuracy: 0.93 - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1518 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - 2s 149us/step - loss: 0.1525 - accuracy: 0.9333 - val_loss: 0.1196 - val_accuracy: 0.9520\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1661 - accuracy: 0.92 - ETA: 1s - loss: 0.1576 - accuracy: 0.92 - ETA: 1s - loss: 0.1539 - accuracy: 0.93 - ETA: 1s - loss: 0.1539 - accuracy: 0.93 - ETA: 1s - loss: 0.1583 - accuracy: 0.92 - ETA: 0s - loss: 0.1623 - accuracy: 0.92 - ETA: 0s - loss: 0.1614 - accuracy: 0.92 - ETA: 0s - loss: 0.1603 - accuracy: 0.92 - ETA: 0s - loss: 0.1586 - accuracy: 0.92 - ETA: 0s - loss: 0.1577 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1574 - accuracy: 0.93 - ETA: 0s - loss: 0.1567 - accuracy: 0.93 - ETA: 0s - loss: 0.1561 - accuracy: 0.93 - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - ETA: 0s - loss: 0.1565 - accuracy: 0.93 - 1s 142us/step - loss: 0.1570 - accuracy: 0.9310 - val_loss: 0.1194 - val_accuracy: 0.9520\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1340 - accuracy: 0.93 - ETA: 1s - loss: 0.1383 - accuracy: 0.93 - ETA: 1s - loss: 0.1462 - accuracy: 0.93 - ETA: 1s - loss: 0.1555 - accuracy: 0.93 - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - ETA: 0s - loss: 0.1585 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1570 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1565 - accuracy: 0.93 - ETA: 0s - loss: 0.1566 - accuracy: 0.93 - ETA: 0s - loss: 0.1561 - accuracy: 0.93 - ETA: 0s - loss: 0.1560 - accuracy: 0.93 - ETA: 0s - loss: 0.1565 - accuracy: 0.93 - ETA: 0s - loss: 0.1559 - accuracy: 0.93 - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - ETA: 0s - loss: 0.1550 - accuracy: 0.93 - ETA: 0s - loss: 0.1547 - accuracy: 0.93 - ETA: 0s - loss: 0.1547 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - 1s 138us/step - loss: 0.1538 - accuracy: 0.9318 - val_loss: 0.1185 - val_accuracy: 0.9531\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1498 - accuracy: 0.92 - ETA: 1s - loss: 0.1653 - accuracy: 0.92 - ETA: 1s - loss: 0.1653 - accuracy: 0.92 - ETA: 1s - loss: 0.1586 - accuracy: 0.92 - ETA: 0s - loss: 0.1620 - accuracy: 0.92 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1563 - accuracy: 0.93 - ETA: 0s - loss: 0.1562 - accuracy: 0.93 - ETA: 0s - loss: 0.1552 - accuracy: 0.93 - ETA: 0s - loss: 0.1542 - accuracy: 0.93 - ETA: 0s - loss: 0.1545 - accuracy: 0.93 - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - ETA: 0s - loss: 0.1546 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.93 - ETA: 0s - loss: 0.1535 - accuracy: 0.93 - ETA: 0s - loss: 0.1534 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - 1s 137us/step - loss: 0.1532 - accuracy: 0.9315 - val_loss: 0.1193 - val_accuracy: 0.9526\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - 0s 111us/step\n",
            "\n",
            "Accuracy on test data: 0.95\n",
            "\n",
            "Loss on test data: 0.11\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       114\n",
            "           1       0.99      0.99      0.99       145\n",
            "           2       0.95      0.93      0.94       436\n",
            "           3       0.90      0.73      0.80       283\n",
            "           4       0.87      0.98      0.92       442\n",
            "\n",
            "    accuracy                           0.92      1420\n",
            "   macro avg       0.93      0.92      0.92      1420\n",
            "weighted avg       0.92      0.92      0.91      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [    5     9    18 ... 14151 14159 14189]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 2s - loss: 0.1631 - accuracy: 0.93 - ETA: 1s - loss: 0.1629 - accuracy: 0.92 - ETA: 1s - loss: 0.1633 - accuracy: 0.92 - ETA: 1s - loss: 0.1615 - accuracy: 0.92 - ETA: 1s - loss: 0.1574 - accuracy: 0.92 - ETA: 1s - loss: 0.1559 - accuracy: 0.92 - ETA: 1s - loss: 0.1526 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1498 - accuracy: 0.93 - ETA: 0s - loss: 0.1504 - accuracy: 0.93 - ETA: 0s - loss: 0.1498 - accuracy: 0.93 - ETA: 0s - loss: 0.1502 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1501 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1526 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1528 - accuracy: 0.93 - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - 1s 144us/step - loss: 0.1523 - accuracy: 0.9320 - val_loss: 0.1160 - val_accuracy: 0.9534\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2379 - accuracy: 0.88 - ETA: 1s - loss: 0.1707 - accuracy: 0.91 - ETA: 1s - loss: 0.1587 - accuracy: 0.92 - ETA: 1s - loss: 0.1557 - accuracy: 0.92 - ETA: 1s - loss: 0.1564 - accuracy: 0.92 - ETA: 1s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1493 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1499 - accuracy: 0.93 - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1531 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - ETA: 0s - loss: 0.1553 - accuracy: 0.92 - ETA: 0s - loss: 0.1550 - accuracy: 0.92 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - 1s 145us/step - loss: 0.1555 - accuracy: 0.9295 - val_loss: 0.1186 - val_accuracy: 0.9489\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1350 - accuracy: 0.95 - ETA: 1s - loss: 0.1583 - accuracy: 0.92 - ETA: 1s - loss: 0.1531 - accuracy: 0.92 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - ETA: 0s - loss: 0.1552 - accuracy: 0.92 - ETA: 0s - loss: 0.1566 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - ETA: 0s - loss: 0.1528 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1508 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - ETA: 0s - loss: 0.1530 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - 1s 138us/step - loss: 0.1545 - accuracy: 0.9314 - val_loss: 0.1163 - val_accuracy: 0.9541\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1489 - accuracy: 0.93 - ETA: 1s - loss: 0.1732 - accuracy: 0.92 - ETA: 1s - loss: 0.1587 - accuracy: 0.92 - ETA: 1s - loss: 0.1594 - accuracy: 0.92 - ETA: 1s - loss: 0.1584 - accuracy: 0.92 - ETA: 1s - loss: 0.1599 - accuracy: 0.92 - ETA: 1s - loss: 0.1600 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1588 - accuracy: 0.92 - ETA: 0s - loss: 0.1585 - accuracy: 0.92 - ETA: 0s - loss: 0.1577 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.92 - ETA: 0s - loss: 0.1570 - accuracy: 0.92 - ETA: 0s - loss: 0.1557 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - ETA: 0s - loss: 0.1572 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.92 - ETA: 0s - loss: 0.1568 - accuracy: 0.92 - 1s 141us/step - loss: 0.1566 - accuracy: 0.9285 - val_loss: 0.1159 - val_accuracy: 0.9542\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1589 - accuracy: 0.91 - ETA: 1s - loss: 0.1617 - accuracy: 0.92 - ETA: 1s - loss: 0.1603 - accuracy: 0.92 - ETA: 1s - loss: 0.1592 - accuracy: 0.92 - ETA: 0s - loss: 0.1588 - accuracy: 0.92 - ETA: 0s - loss: 0.1577 - accuracy: 0.92 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - ETA: 0s - loss: 0.1594 - accuracy: 0.92 - ETA: 0s - loss: 0.1592 - accuracy: 0.92 - ETA: 0s - loss: 0.1605 - accuracy: 0.92 - ETA: 0s - loss: 0.1597 - accuracy: 0.92 - ETA: 0s - loss: 0.1607 - accuracy: 0.92 - ETA: 0s - loss: 0.1602 - accuracy: 0.92 - ETA: 0s - loss: 0.1587 - accuracy: 0.92 - ETA: 0s - loss: 0.1585 - accuracy: 0.92 - ETA: 0s - loss: 0.1585 - accuracy: 0.92 - ETA: 0s - loss: 0.1596 - accuracy: 0.92 - ETA: 0s - loss: 0.1588 - accuracy: 0.92 - ETA: 0s - loss: 0.1584 - accuracy: 0.92 - ETA: 0s - loss: 0.1581 - accuracy: 0.92 - ETA: 0s - loss: 0.1582 - accuracy: 0.92 - 1s 139us/step - loss: 0.1583 - accuracy: 0.9278 - val_loss: 0.1153 - val_accuracy: 0.9543\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1558 - accuracy: 0.92 - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1482 - accuracy: 0.93 - ETA: 1s - loss: 0.1486 - accuracy: 0.93 - ETA: 1s - loss: 0.1510 - accuracy: 0.93 - ETA: 1s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1527 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1511 - accuracy: 0.93 - ETA: 0s - loss: 0.1507 - accuracy: 0.93 - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1495 - accuracy: 0.93 - ETA: 0s - loss: 0.1493 - accuracy: 0.93 - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1499 - accuracy: 0.93 - ETA: 0s - loss: 0.1507 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1528 - accuracy: 0.93 - ETA: 0s - loss: 0.1531 - accuracy: 0.93 - ETA: 0s - loss: 0.1536 - accuracy: 0.93 - 1s 142us/step - loss: 0.1544 - accuracy: 0.9317 - val_loss: 0.1142 - val_accuracy: 0.9574\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1504 - accuracy: 0.93 - ETA: 1s - loss: 0.1563 - accuracy: 0.92 - ETA: 1s - loss: 0.1520 - accuracy: 0.93 - ETA: 1s - loss: 0.1512 - accuracy: 0.93 - ETA: 1s - loss: 0.1484 - accuracy: 0.93 - ETA: 0s - loss: 0.1534 - accuracy: 0.93 - ETA: 0s - loss: 0.1507 - accuracy: 0.93 - ETA: 0s - loss: 0.1484 - accuracy: 0.93 - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - ETA: 0s - loss: 0.1507 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - ETA: 0s - loss: 0.1526 - accuracy: 0.93 - ETA: 0s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1518 - accuracy: 0.93 - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1546 - accuracy: 0.93 - 1s 144us/step - loss: 0.1547 - accuracy: 0.9299 - val_loss: 0.1142 - val_accuracy: 0.9540\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1584 - accuracy: 0.93 - ETA: 1s - loss: 0.1487 - accuracy: 0.93 - ETA: 1s - loss: 0.1513 - accuracy: 0.93 - ETA: 1s - loss: 0.1580 - accuracy: 0.92 - ETA: 1s - loss: 0.1564 - accuracy: 0.93 - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1531 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1547 - accuracy: 0.93 - ETA: 0s - loss: 0.1555 - accuracy: 0.92 - ETA: 0s - loss: 0.1552 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.93 - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - ETA: 0s - loss: 0.1542 - accuracy: 0.93 - ETA: 0s - loss: 0.1534 - accuracy: 0.93 - 1s 141us/step - loss: 0.1532 - accuracy: 0.9317 - val_loss: 0.1154 - val_accuracy: 0.9568\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2530 - accuracy: 0.88 - ETA: 1s - loss: 0.1606 - accuracy: 0.93 - ETA: 1s - loss: 0.1481 - accuracy: 0.94 - ETA: 1s - loss: 0.1464 - accuracy: 0.93 - ETA: 1s - loss: 0.1427 - accuracy: 0.93 - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - ETA: 0s - loss: 0.1484 - accuracy: 0.93 - ETA: 0s - loss: 0.1518 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1510 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1511 - accuracy: 0.93 - ETA: 0s - loss: 0.1501 - accuracy: 0.93 - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1499 - accuracy: 0.93 - ETA: 0s - loss: 0.1510 - accuracy: 0.93 - ETA: 0s - loss: 0.1511 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - 1s 146us/step - loss: 0.1519 - accuracy: 0.9331 - val_loss: 0.1145 - val_accuracy: 0.9530\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1450 - accuracy: 0.93 - ETA: 1s - loss: 0.1514 - accuracy: 0.93 - ETA: 1s - loss: 0.1594 - accuracy: 0.92 - ETA: 0s - loss: 0.1508 - accuracy: 0.93 - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - ETA: 0s - loss: 0.1501 - accuracy: 0.93 - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - ETA: 0s - loss: 0.1516 - accuracy: 0.93 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - ETA: 0s - loss: 0.1528 - accuracy: 0.93 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1536 - accuracy: 0.93 - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - ETA: 0s - loss: 0.1538 - accuracy: 0.93 - ETA: 0s - loss: 0.1535 - accuracy: 0.93 - ETA: 0s - loss: 0.1534 - accuracy: 0.93 - 1s 139us/step - loss: 0.1531 - accuracy: 0.9317 - val_loss: 0.1182 - val_accuracy: 0.9495\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1316 - accuracy: 0.94 - ETA: 1s - loss: 0.1544 - accuracy: 0.93 - ETA: 1s - loss: 0.1407 - accuracy: 0.93 - ETA: 1s - loss: 0.1397 - accuracy: 0.93 - ETA: 1s - loss: 0.1392 - accuracy: 0.93 - ETA: 1s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1433 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1467 - accuracy: 0.93 - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - 1s 142us/step - loss: 0.1483 - accuracy: 0.9335 - val_loss: 0.1134 - val_accuracy: 0.9509\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1581 - accuracy: 0.92 - ETA: 1s - loss: 0.1407 - accuracy: 0.93 - ETA: 1s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1517 - accuracy: 0.93 - ETA: 0s - loss: 0.1611 - accuracy: 0.92 - ETA: 0s - loss: 0.1571 - accuracy: 0.93 - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - ETA: 0s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1500 - accuracy: 0.93 - ETA: 0s - loss: 0.1492 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1478 - accuracy: 0.93 - ETA: 0s - loss: 0.1478 - accuracy: 0.93 - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - ETA: 0s - loss: 0.1484 - accuracy: 0.93 - ETA: 0s - loss: 0.1484 - accuracy: 0.93 - ETA: 0s - loss: 0.1488 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1497 - accuracy: 0.93 - 1s 138us/step - loss: 0.1498 - accuracy: 0.9336 - val_loss: 0.1116 - val_accuracy: 0.9549\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1682 - accuracy: 0.93 - ETA: 1s - loss: 0.1654 - accuracy: 0.92 - ETA: 1s - loss: 0.1642 - accuracy: 0.92 - ETA: 1s - loss: 0.1577 - accuracy: 0.92 - ETA: 1s - loss: 0.1562 - accuracy: 0.92 - ETA: 0s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1556 - accuracy: 0.92 - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1510 - accuracy: 0.93 - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.93 - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - ETA: 0s - loss: 0.1515 - accuracy: 0.93 - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1521 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - 1s 142us/step - loss: 0.1521 - accuracy: 0.9319 - val_loss: 0.1111 - val_accuracy: 0.9562\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1497 - accuracy: 0.94 - ETA: 1s - loss: 0.1390 - accuracy: 0.94 - ETA: 1s - loss: 0.1352 - accuracy: 0.94 - ETA: 1s - loss: 0.1404 - accuracy: 0.93 - ETA: 0s - loss: 0.1504 - accuracy: 0.93 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1518 - accuracy: 0.93 - ETA: 0s - loss: 0.1500 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1495 - accuracy: 0.93 - ETA: 0s - loss: 0.1489 - accuracy: 0.93 - ETA: 0s - loss: 0.1502 - accuracy: 0.93 - ETA: 0s - loss: 0.1497 - accuracy: 0.93 - ETA: 0s - loss: 0.1488 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - ETA: 0s - loss: 0.1498 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - 1s 141us/step - loss: 0.1513 - accuracy: 0.9323 - val_loss: 0.1116 - val_accuracy: 0.9592\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1229 - accuracy: 0.95 - ETA: 1s - loss: 0.1603 - accuracy: 0.92 - ETA: 1s - loss: 0.1449 - accuracy: 0.93 - ETA: 1s - loss: 0.1497 - accuracy: 0.93 - ETA: 1s - loss: 0.1496 - accuracy: 0.93 - ETA: 1s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1489 - accuracy: 0.93 - ETA: 0s - loss: 0.1475 - accuracy: 0.93 - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1472 - accuracy: 0.93 - ETA: 0s - loss: 0.1472 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1484 - accuracy: 0.93 - 1s 143us/step - loss: 0.1483 - accuracy: 0.9342 - val_loss: 0.1122 - val_accuracy: 0.9517\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1373 - accuracy: 0.95 - ETA: 1s - loss: 0.1462 - accuracy: 0.93 - ETA: 1s - loss: 0.1486 - accuracy: 0.93 - ETA: 1s - loss: 0.1487 - accuracy: 0.93 - ETA: 0s - loss: 0.1496 - accuracy: 0.93 - ETA: 0s - loss: 0.1502 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - ETA: 0s - loss: 0.1495 - accuracy: 0.93 - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - ETA: 0s - loss: 0.1508 - accuracy: 0.93 - ETA: 0s - loss: 0.1501 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - ETA: 0s - loss: 0.1508 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - 1s 140us/step - loss: 0.1519 - accuracy: 0.9321 - val_loss: 0.1108 - val_accuracy: 0.9581\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1325 - accuracy: 0.94 - ETA: 1s - loss: 0.1417 - accuracy: 0.94 - ETA: 1s - loss: 0.1398 - accuracy: 0.93 - ETA: 1s - loss: 0.1418 - accuracy: 0.93 - ETA: 1s - loss: 0.1399 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1440 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1467 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1482 - accuracy: 0.93 - 1s 142us/step - loss: 0.1486 - accuracy: 0.9330 - val_loss: 0.1137 - val_accuracy: 0.9530\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1555 - accuracy: 0.93 - ETA: 1s - loss: 0.1483 - accuracy: 0.93 - ETA: 1s - loss: 0.1456 - accuracy: 0.93 - ETA: 1s - loss: 0.1394 - accuracy: 0.94 - ETA: 1s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1425 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1468 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1478 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1479 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - 1s 141us/step - loss: 0.1482 - accuracy: 0.9331 - val_loss: 0.1094 - val_accuracy: 0.9607\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1964 - accuracy: 0.91 - ETA: 1s - loss: 0.1524 - accuracy: 0.93 - ETA: 1s - loss: 0.1457 - accuracy: 0.93 - ETA: 1s - loss: 0.1468 - accuracy: 0.93 - ETA: 1s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1475 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - ETA: 0s - loss: 0.1477 - accuracy: 0.93 - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - ETA: 0s - loss: 0.1491 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1479 - accuracy: 0.93 - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1493 - accuracy: 0.93 - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - 1s 137us/step - loss: 0.1485 - accuracy: 0.9342 - val_loss: 0.1090 - val_accuracy: 0.9608\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1119 - accuracy: 0.95 - ETA: 1s - loss: 0.1377 - accuracy: 0.94 - ETA: 1s - loss: 0.1467 - accuracy: 0.93 - ETA: 1s - loss: 0.1409 - accuracy: 0.93 - ETA: 1s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1427 - accuracy: 0.93 - ETA: 0s - loss: 0.1431 - accuracy: 0.93 - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - ETA: 0s - loss: 0.1467 - accuracy: 0.93 - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - ETA: 0s - loss: 0.1468 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - 1s 141us/step - loss: 0.1466 - accuracy: 0.9348 - val_loss: 0.1089 - val_accuracy: 0.9602\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1466 - accuracy: 0.92 - ETA: 1s - loss: 0.1465 - accuracy: 0.93 - ETA: 1s - loss: 0.1502 - accuracy: 0.92 - ETA: 1s - loss: 0.1496 - accuracy: 0.93 - ETA: 0s - loss: 0.1543 - accuracy: 0.92 - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - ETA: 0s - loss: 0.1539 - accuracy: 0.92 - ETA: 0s - loss: 0.1499 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1467 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1491 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1482 - accuracy: 0.93 - ETA: 0s - loss: 0.1493 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1477 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - 1s 140us/step - loss: 0.1486 - accuracy: 0.9341 - val_loss: 0.1150 - val_accuracy: 0.9480\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1461 - accuracy: 0.92 - ETA: 1s - loss: 0.1461 - accuracy: 0.93 - ETA: 1s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1447 - accuracy: 0.93 - ETA: 0s - loss: 0.1478 - accuracy: 0.93 - ETA: 0s - loss: 0.1468 - accuracy: 0.93 - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1461 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1489 - accuracy: 0.93 - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1475 - accuracy: 0.93 - ETA: 0s - loss: 0.1475 - accuracy: 0.93 - ETA: 0s - loss: 0.1468 - accuracy: 0.93 - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - 1s 138us/step - loss: 0.1464 - accuracy: 0.9340 - val_loss: 0.1087 - val_accuracy: 0.9577\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1561 - accuracy: 0.93 - ETA: 1s - loss: 0.1483 - accuracy: 0.93 - ETA: 1s - loss: 0.1390 - accuracy: 0.93 - ETA: 1s - loss: 0.1448 - accuracy: 0.93 - ETA: 1s - loss: 0.1447 - accuracy: 0.93 - ETA: 0s - loss: 0.1440 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1497 - accuracy: 0.93 - ETA: 0s - loss: 0.1489 - accuracy: 0.93 - ETA: 0s - loss: 0.1489 - accuracy: 0.93 - ETA: 0s - loss: 0.1485 - accuracy: 0.93 - ETA: 0s - loss: 0.1479 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - ETA: 0s - loss: 0.1486 - accuracy: 0.93 - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - 1s 145us/step - loss: 0.1480 - accuracy: 0.9347 - val_loss: 0.1091 - val_accuracy: 0.9559\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1421 - accuracy: 0.93 - ETA: 1s - loss: 0.1441 - accuracy: 0.93 - ETA: 1s - loss: 0.1377 - accuracy: 0.93 - ETA: 1s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1402 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1458 - accuracy: 0.93 - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1438 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1431 - accuracy: 0.93 - 1s 138us/step - loss: 0.1429 - accuracy: 0.9381 - val_loss: 0.1066 - val_accuracy: 0.9598\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1262 - accuracy: 0.95 - ETA: 1s - loss: 0.1449 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.92 - ETA: 1s - loss: 0.1681 - accuracy: 0.92 - ETA: 1s - loss: 0.1640 - accuracy: 0.92 - ETA: 0s - loss: 0.1610 - accuracy: 0.92 - ETA: 0s - loss: 0.1580 - accuracy: 0.92 - ETA: 0s - loss: 0.1559 - accuracy: 0.93 - ETA: 0s - loss: 0.1558 - accuracy: 0.92 - ETA: 0s - loss: 0.1566 - accuracy: 0.92 - ETA: 0s - loss: 0.1565 - accuracy: 0.92 - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - ETA: 0s - loss: 0.1490 - accuracy: 0.93 - ETA: 0s - loss: 0.1498 - accuracy: 0.93 - ETA: 0s - loss: 0.1496 - accuracy: 0.93 - 1s 141us/step - loss: 0.1496 - accuracy: 0.9333 - val_loss: 0.1071 - val_accuracy: 0.9601\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1282 - accuracy: 0.94 - ETA: 1s - loss: 0.1510 - accuracy: 0.93 - ETA: 1s - loss: 0.1468 - accuracy: 0.93 - ETA: 1s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1397 - accuracy: 0.93 - ETA: 0s - loss: 0.1402 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1398 - accuracy: 0.93 - ETA: 0s - loss: 0.1400 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1412 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1425 - accuracy: 0.93 - ETA: 0s - loss: 0.1431 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1427 - accuracy: 0.93 - 1s 145us/step - loss: 0.1426 - accuracy: 0.9370 - val_loss: 0.1097 - val_accuracy: 0.9521\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1884 - accuracy: 0.90 - ETA: 1s - loss: 0.1359 - accuracy: 0.94 - ETA: 1s - loss: 0.1424 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.93 - ETA: 1s - loss: 0.1503 - accuracy: 0.93 - ETA: 1s - loss: 0.1527 - accuracy: 0.93 - ETA: 1s - loss: 0.1510 - accuracy: 0.93 - ETA: 0s - loss: 0.1511 - accuracy: 0.93 - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - ETA: 0s - loss: 0.1505 - accuracy: 0.93 - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - ETA: 0s - loss: 0.1488 - accuracy: 0.93 - ETA: 0s - loss: 0.1478 - accuracy: 0.93 - ETA: 0s - loss: 0.1469 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1458 - accuracy: 0.93 - ETA: 0s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1449 - accuracy: 0.93 - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - ETA: 0s - loss: 0.1449 - accuracy: 0.93 - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 2s 148us/step - loss: 0.1446 - accuracy: 0.9366 - val_loss: 0.1066 - val_accuracy: 0.9574\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1437 - accuracy: 0.94 - ETA: 1s - loss: 0.1378 - accuracy: 0.93 - ETA: 1s - loss: 0.1531 - accuracy: 0.93 - ETA: 1s - loss: 0.1498 - accuracy: 0.93 - ETA: 1s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1482 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1433 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - 1s 145us/step - loss: 0.1430 - accuracy: 0.9373 - val_loss: 0.1090 - val_accuracy: 0.9621\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1469 - accuracy: 0.94 - ETA: 1s - loss: 0.1429 - accuracy: 0.93 - ETA: 1s - loss: 0.1326 - accuracy: 0.94 - ETA: 1s - loss: 0.1400 - accuracy: 0.93 - ETA: 1s - loss: 0.1394 - accuracy: 0.93 - ETA: 1s - loss: 0.1451 - accuracy: 0.93 - ETA: 1s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1418 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1425 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - 2s 154us/step - loss: 0.1421 - accuracy: 0.9374 - val_loss: 0.1053 - val_accuracy: 0.9603\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1322 - accuracy: 0.94 - ETA: 1s - loss: 0.1494 - accuracy: 0.93 - ETA: 1s - loss: 0.1476 - accuracy: 0.93 - ETA: 1s - loss: 0.1531 - accuracy: 0.93 - ETA: 1s - loss: 0.1459 - accuracy: 0.93 - ETA: 1s - loss: 0.1491 - accuracy: 0.93 - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1406 - accuracy: 0.93 - ETA: 0s - loss: 0.1404 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - 1s 147us/step - loss: 0.1425 - accuracy: 0.9361 - val_loss: 0.1065 - val_accuracy: 0.9549\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1628 - accuracy: 0.92 - ETA: 1s - loss: 0.1528 - accuracy: 0.93 - ETA: 1s - loss: 0.1560 - accuracy: 0.92 - ETA: 1s - loss: 0.1492 - accuracy: 0.93 - ETA: 1s - loss: 0.1542 - accuracy: 0.93 - ETA: 1s - loss: 0.1488 - accuracy: 0.93 - ETA: 0s - loss: 0.1461 - accuracy: 0.93 - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - ETA: 0s - loss: 0.1471 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - ETA: 0s - loss: 0.1455 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1454 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - 1s 146us/step - loss: 0.1408 - accuracy: 0.9388 - val_loss: 0.1043 - val_accuracy: 0.9595\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1558 - accuracy: 0.95 - ETA: 1s - loss: 0.1425 - accuracy: 0.93 - ETA: 1s - loss: 0.1375 - accuracy: 0.94 - ETA: 1s - loss: 0.1360 - accuracy: 0.94 - ETA: 1s - loss: 0.1365 - accuracy: 0.94 - ETA: 0s - loss: 0.1367 - accuracy: 0.94 - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - ETA: 0s - loss: 0.1378 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1387 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1404 - accuracy: 0.93 - ETA: 0s - loss: 0.1398 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - 1s 145us/step - loss: 0.1407 - accuracy: 0.9383 - val_loss: 0.1041 - val_accuracy: 0.9573\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1123 - accuracy: 0.96 - ETA: 1s - loss: 0.1335 - accuracy: 0.94 - ETA: 1s - loss: 0.1358 - accuracy: 0.94 - ETA: 1s - loss: 0.1440 - accuracy: 0.93 - ETA: 1s - loss: 0.1402 - accuracy: 0.94 - ETA: 1s - loss: 0.1404 - accuracy: 0.94 - ETA: 1s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1403 - accuracy: 0.93 - 1s 145us/step - loss: 0.1406 - accuracy: 0.9388 - val_loss: 0.1046 - val_accuracy: 0.9628\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1494 - accuracy: 0.91 - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1509 - accuracy: 0.93 - ETA: 1s - loss: 0.1451 - accuracy: 0.93 - ETA: 1s - loss: 0.1517 - accuracy: 0.93 - ETA: 1s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1398 - accuracy: 0.94 - ETA: 0s - loss: 0.1406 - accuracy: 0.94 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1447 - accuracy: 0.93 - ETA: 0s - loss: 0.1459 - accuracy: 0.93 - ETA: 0s - loss: 0.1455 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - 1s 146us/step - loss: 0.1423 - accuracy: 0.9384 - val_loss: 0.1027 - val_accuracy: 0.9588\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1175 - accuracy: 0.95 - ETA: 1s - loss: 0.1379 - accuracy: 0.94 - ETA: 1s - loss: 0.1386 - accuracy: 0.93 - ETA: 1s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1438 - accuracy: 0.93 - ETA: 0s - loss: 0.1454 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1454 - accuracy: 0.93 - ETA: 0s - loss: 0.1476 - accuracy: 0.93 - ETA: 0s - loss: 0.1481 - accuracy: 0.93 - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - ETA: 0s - loss: 0.1449 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - 1s 145us/step - loss: 0.1444 - accuracy: 0.9361 - val_loss: 0.1027 - val_accuracy: 0.9617\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1800 - accuracy: 0.92 - ETA: 1s - loss: 0.1573 - accuracy: 0.92 - ETA: 1s - loss: 0.1497 - accuracy: 0.93 - ETA: 0s - loss: 0.1477 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1461 - accuracy: 0.93 - ETA: 0s - loss: 0.1477 - accuracy: 0.93 - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - ETA: 0s - loss: 0.1447 - accuracy: 0.93 - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - ETA: 0s - loss: 0.1458 - accuracy: 0.93 - ETA: 0s - loss: 0.1436 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1427 - accuracy: 0.93 - 1s 137us/step - loss: 0.1427 - accuracy: 0.9382 - val_loss: 0.1025 - val_accuracy: 0.9580\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1567 - accuracy: 0.92 - ETA: 1s - loss: 0.1386 - accuracy: 0.93 - ETA: 1s - loss: 0.1363 - accuracy: 0.94 - ETA: 1s - loss: 0.1417 - accuracy: 0.93 - ETA: 1s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1389 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1447 - accuracy: 0.93 - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1418 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - 1s 137us/step - loss: 0.1417 - accuracy: 0.9385 - val_loss: 0.1022 - val_accuracy: 0.9599\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1124 - accuracy: 0.95 - ETA: 1s - loss: 0.1510 - accuracy: 0.92 - ETA: 1s - loss: 0.1484 - accuracy: 0.93 - ETA: 1s - loss: 0.1447 - accuracy: 0.93 - ETA: 1s - loss: 0.1463 - accuracy: 0.93 - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1438 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1433 - accuracy: 0.93 - 1s 144us/step - loss: 0.1433 - accuracy: 0.9359 - val_loss: 0.1040 - val_accuracy: 0.9601\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1383 - accuracy: 0.93 - ETA: 1s - loss: 0.1271 - accuracy: 0.94 - ETA: 1s - loss: 0.1384 - accuracy: 0.93 - ETA: 1s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.93 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1406 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - 1s 140us/step - loss: 0.1413 - accuracy: 0.9372 - val_loss: 0.1011 - val_accuracy: 0.9629\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1069 - accuracy: 0.95 - ETA: 1s - loss: 0.1237 - accuracy: 0.94 - ETA: 1s - loss: 0.1267 - accuracy: 0.94 - ETA: 1s - loss: 0.1299 - accuracy: 0.94 - ETA: 1s - loss: 0.1299 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1385 - accuracy: 0.94 - ETA: 0s - loss: 0.1381 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1371 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1385 - accuracy: 0.94 - ETA: 0s - loss: 0.1391 - accuracy: 0.94 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - 1s 144us/step - loss: 0.1388 - accuracy: 0.9398 - val_loss: 0.1066 - val_accuracy: 0.9554\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1668 - accuracy: 0.92 - ETA: 1s - loss: 0.1413 - accuracy: 0.94 - ETA: 1s - loss: 0.1401 - accuracy: 0.93 - ETA: 1s - loss: 0.1448 - accuracy: 0.93 - ETA: 1s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1449 - accuracy: 0.93 - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - 1s 143us/step - loss: 0.1447 - accuracy: 0.9361 - val_loss: 0.1051 - val_accuracy: 0.9560\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1413 - accuracy: 0.94 - ETA: 1s - loss: 0.1450 - accuracy: 0.93 - ETA: 1s - loss: 0.1368 - accuracy: 0.94 - ETA: 1s - loss: 0.1399 - accuracy: 0.93 - ETA: 1s - loss: 0.1449 - accuracy: 0.93 - ETA: 1s - loss: 0.1443 - accuracy: 0.93 - ETA: 1s - loss: 0.1423 - accuracy: 0.93 - ETA: 1s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1441 - accuracy: 0.93 - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1412 - accuracy: 0.93 - ETA: 0s - loss: 0.1412 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1390 - accuracy: 0.93 - ETA: 0s - loss: 0.1403 - accuracy: 0.93 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - 2s 163us/step - loss: 0.1403 - accuracy: 0.9387 - val_loss: 0.1020 - val_accuracy: 0.9597\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1273 - accuracy: 0.95 - ETA: 1s - loss: 0.1333 - accuracy: 0.94 - ETA: 1s - loss: 0.1299 - accuracy: 0.94 - ETA: 1s - loss: 0.1309 - accuracy: 0.94 - ETA: 1s - loss: 0.1340 - accuracy: 0.94 - ETA: 1s - loss: 0.1366 - accuracy: 0.94 - ETA: 1s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1374 - accuracy: 0.94 - ETA: 0s - loss: 0.1374 - accuracy: 0.94 - ETA: 0s - loss: 0.1389 - accuracy: 0.94 - ETA: 0s - loss: 0.1394 - accuracy: 0.94 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1397 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1403 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1390 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - 1s 146us/step - loss: 0.1402 - accuracy: 0.9386 - val_loss: 0.1010 - val_accuracy: 0.9581\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1190 - accuracy: 0.95 - ETA: 1s - loss: 0.1410 - accuracy: 0.93 - ETA: 1s - loss: 0.1395 - accuracy: 0.93 - ETA: 1s - loss: 0.1437 - accuracy: 0.93 - ETA: 1s - loss: 0.1357 - accuracy: 0.94 - ETA: 1s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1376 - accuracy: 0.94 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - ETA: 0s - loss: 0.1400 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1410 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1413 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1427 - accuracy: 0.93 - ETA: 0s - loss: 0.1424 - accuracy: 0.93 - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1418 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - 1s 141us/step - loss: 0.1405 - accuracy: 0.9385 - val_loss: 0.1044 - val_accuracy: 0.9578\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1436 - accuracy: 0.94 - ETA: 1s - loss: 0.1371 - accuracy: 0.94 - ETA: 1s - loss: 0.1305 - accuracy: 0.94 - ETA: 1s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1365 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1364 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - 1s 141us/step - loss: 0.1342 - accuracy: 0.9417 - val_loss: 0.0987 - val_accuracy: 0.9635\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1158 - accuracy: 0.95 - ETA: 1s - loss: 0.1236 - accuracy: 0.94 - ETA: 1s - loss: 0.1323 - accuracy: 0.93 - ETA: 1s - loss: 0.1375 - accuracy: 0.93 - ETA: 1s - loss: 0.1378 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1381 - accuracy: 0.93 - ETA: 0s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.93 - ETA: 0s - loss: 0.1365 - accuracy: 0.93 - ETA: 0s - loss: 0.1381 - accuracy: 0.93 - ETA: 0s - loss: 0.1389 - accuracy: 0.93 - ETA: 0s - loss: 0.1388 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - ETA: 0s - loss: 0.1399 - accuracy: 0.93 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1399 - accuracy: 0.93 - ETA: 0s - loss: 0.1402 - accuracy: 0.93 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - ETA: 0s - loss: 0.1385 - accuracy: 0.93 - 1s 141us/step - loss: 0.1390 - accuracy: 0.9395 - val_loss: 0.0987 - val_accuracy: 0.9679\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2928 - accuracy: 0.87 - ETA: 1s - loss: 0.1570 - accuracy: 0.93 - ETA: 1s - loss: 0.1604 - accuracy: 0.92 - ETA: 1s - loss: 0.1540 - accuracy: 0.93 - ETA: 0s - loss: 0.1477 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1450 - accuracy: 0.93 - ETA: 0s - loss: 0.1439 - accuracy: 0.93 - ETA: 0s - loss: 0.1430 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1420 - accuracy: 0.93 - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1406 - accuracy: 0.93 - ETA: 0s - loss: 0.1403 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1415 - accuracy: 0.93 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - 1s 138us/step - loss: 0.1406 - accuracy: 0.9391 - val_loss: 0.0987 - val_accuracy: 0.9667\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1472 - accuracy: 0.93 - ETA: 1s - loss: 0.1240 - accuracy: 0.94 - ETA: 1s - loss: 0.1191 - accuracy: 0.94 - ETA: 1s - loss: 0.1227 - accuracy: 0.94 - ETA: 1s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1358 - accuracy: 0.93 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1361 - accuracy: 0.93 - ETA: 0s - loss: 0.1384 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1381 - accuracy: 0.93 - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.93 - ETA: 0s - loss: 0.1375 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.93 - 1s 141us/step - loss: 0.1368 - accuracy: 0.9398 - val_loss: 0.0986 - val_accuracy: 0.9667\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1123 - accuracy: 0.95 - ETA: 1s - loss: 0.1422 - accuracy: 0.93 - ETA: 1s - loss: 0.1402 - accuracy: 0.93 - ETA: 1s - loss: 0.1387 - accuracy: 0.93 - ETA: 1s - loss: 0.1335 - accuracy: 0.93 - ETA: 0s - loss: 0.1344 - accuracy: 0.93 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.93 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.93 - ETA: 0s - loss: 0.1354 - accuracy: 0.93 - ETA: 0s - loss: 0.1349 - accuracy: 0.93 - ETA: 0s - loss: 0.1351 - accuracy: 0.93 - ETA: 0s - loss: 0.1372 - accuracy: 0.93 - ETA: 0s - loss: 0.1362 - accuracy: 0.93 - ETA: 0s - loss: 0.1364 - accuracy: 0.93 - ETA: 0s - loss: 0.1373 - accuracy: 0.93 - ETA: 0s - loss: 0.1375 - accuracy: 0.93 - ETA: 0s - loss: 0.1369 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - 1s 141us/step - loss: 0.1382 - accuracy: 0.9380 - val_loss: 0.1248 - val_accuracy: 0.9434\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1427 - accuracy: 0.93 - ETA: 1s - loss: 0.1377 - accuracy: 0.94 - ETA: 1s - loss: 0.1304 - accuracy: 0.94 - ETA: 1s - loss: 0.1290 - accuracy: 0.94 - ETA: 1s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.93 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1381 - accuracy: 0.93 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - 1s 143us/step - loss: 0.1390 - accuracy: 0.9383 - val_loss: 0.0992 - val_accuracy: 0.9685\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 121us/step\n",
            "\n",
            "Accuracy on test data: 0.96\n",
            "\n",
            "Loss on test data: 0.10\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       128\n",
            "           1       0.96      0.95      0.96       127\n",
            "           2       0.95      0.93      0.94       394\n",
            "           3       0.89      0.89      0.89       306\n",
            "           4       0.94      0.96      0.95       465\n",
            "\n",
            "    accuracy                           0.94      1420\n",
            "   macro avg       0.95      0.95      0.95      1420\n",
            "weighted avg       0.94      0.94      0.94      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14196 14197 14198] \n",
            "\n",
            "Test Index:  [    8    11    14 ... 14187 14194 14199]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1528 - accuracy: 0.93 - ETA: 1s - loss: 0.1489 - accuracy: 0.93 - ETA: 1s - loss: 0.1382 - accuracy: 0.94 - ETA: 1s - loss: 0.1391 - accuracy: 0.93 - ETA: 1s - loss: 0.1392 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1377 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1358 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1377 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1399 - accuracy: 0.93 - 1s 142us/step - loss: 0.1398 - accuracy: 0.9384 - val_loss: 0.1019 - val_accuracy: 0.9606\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1262 - accuracy: 0.94 - ETA: 1s - loss: 0.1323 - accuracy: 0.94 - ETA: 1s - loss: 0.1351 - accuracy: 0.93 - ETA: 1s - loss: 0.1367 - accuracy: 0.94 - ETA: 1s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - ETA: 0s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.93 - ETA: 0s - loss: 0.1366 - accuracy: 0.93 - ETA: 0s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1377 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.93 - ETA: 0s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1365 - accuracy: 0.93 - ETA: 0s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - ETA: 0s - loss: 0.1388 - accuracy: 0.93 - 1s 138us/step - loss: 0.1387 - accuracy: 0.9388 - val_loss: 0.0999 - val_accuracy: 0.9621\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1418 - accuracy: 0.94 - ETA: 1s - loss: 0.1424 - accuracy: 0.93 - ETA: 1s - loss: 0.1358 - accuracy: 0.94 - ETA: 1s - loss: 0.1412 - accuracy: 0.93 - ETA: 0s - loss: 0.1405 - accuracy: 0.93 - ETA: 0s - loss: 0.1404 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.94 - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - ETA: 0s - loss: 0.1361 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - 1s 140us/step - loss: 0.1359 - accuracy: 0.9400 - val_loss: 0.0975 - val_accuracy: 0.9642\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1079 - accuracy: 0.95 - ETA: 1s - loss: 0.1288 - accuracy: 0.93 - ETA: 1s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1361 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1377 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1367 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - ETA: 0s - loss: 0.1361 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - 1s 138us/step - loss: 0.1365 - accuracy: 0.9411 - val_loss: 0.1006 - val_accuracy: 0.9665\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1135 - accuracy: 0.95 - ETA: 1s - loss: 0.1415 - accuracy: 0.93 - ETA: 1s - loss: 0.1430 - accuracy: 0.93 - ETA: 1s - loss: 0.1415 - accuracy: 0.93 - ETA: 1s - loss: 0.1410 - accuracy: 0.93 - ETA: 1s - loss: 0.1388 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1408 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1384 - accuracy: 0.93 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.94 - ETA: 0s - loss: 0.1378 - accuracy: 0.94 - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - ETA: 0s - loss: 0.1389 - accuracy: 0.93 - ETA: 0s - loss: 0.1385 - accuracy: 0.93 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.94 - ETA: 0s - loss: 0.1384 - accuracy: 0.94 - ETA: 0s - loss: 0.1382 - accuracy: 0.94 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - 1s 140us/step - loss: 0.1392 - accuracy: 0.9397 - val_loss: 0.1011 - val_accuracy: 0.9581\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1592 - accuracy: 0.93 - ETA: 1s - loss: 0.1632 - accuracy: 0.92 - ETA: 1s - loss: 0.1567 - accuracy: 0.92 - ETA: 1s - loss: 0.1504 - accuracy: 0.92 - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - ETA: 0s - loss: 0.1404 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - ETA: 0s - loss: 0.1369 - accuracy: 0.93 - ETA: 0s - loss: 0.1377 - accuracy: 0.93 - ETA: 0s - loss: 0.1384 - accuracy: 0.93 - ETA: 0s - loss: 0.1380 - accuracy: 0.93 - ETA: 0s - loss: 0.1376 - accuracy: 0.93 - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1390 - accuracy: 0.93 - 1s 142us/step - loss: 0.1401 - accuracy: 0.9390 - val_loss: 0.0983 - val_accuracy: 0.9717\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1695 - accuracy: 0.93 - ETA: 1s - loss: 0.1416 - accuracy: 0.93 - ETA: 1s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - ETA: 0s - loss: 0.1406 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.94 - ETA: 0s - loss: 0.1378 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1377 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - ETA: 0s - loss: 0.1379 - accuracy: 0.94 - ETA: 0s - loss: 0.1368 - accuracy: 0.94 - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - 1s 139us/step - loss: 0.1352 - accuracy: 0.9413 - val_loss: 0.0980 - val_accuracy: 0.9614\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1242 - accuracy: 0.95 - ETA: 1s - loss: 0.1235 - accuracy: 0.94 - ETA: 1s - loss: 0.1226 - accuracy: 0.94 - ETA: 1s - loss: 0.1352 - accuracy: 0.94 - ETA: 1s - loss: 0.1307 - accuracy: 0.94 - ETA: 1s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1347 - accuracy: 0.94 - 1s 138us/step - loss: 0.1350 - accuracy: 0.9418 - val_loss: 0.0972 - val_accuracy: 0.9667\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1296 - accuracy: 0.94 - ETA: 1s - loss: 0.1459 - accuracy: 0.93 - ETA: 1s - loss: 0.1410 - accuracy: 0.93 - ETA: 1s - loss: 0.1377 - accuracy: 0.93 - ETA: 0s - loss: 0.1369 - accuracy: 0.93 - ETA: 0s - loss: 0.1358 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1364 - accuracy: 0.94 - ETA: 0s - loss: 0.1376 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1372 - accuracy: 0.93 - ETA: 0s - loss: 0.1366 - accuracy: 0.93 - ETA: 0s - loss: 0.1358 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.93 - ETA: 0s - loss: 0.1380 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1365 - accuracy: 0.94 - 1s 142us/step - loss: 0.1357 - accuracy: 0.9410 - val_loss: 0.0967 - val_accuracy: 0.9674\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1115 - accuracy: 0.95 - ETA: 1s - loss: 0.1330 - accuracy: 0.94 - ETA: 1s - loss: 0.1380 - accuracy: 0.94 - ETA: 1s - loss: 0.1507 - accuracy: 0.93 - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - ETA: 0s - loss: 0.1465 - accuracy: 0.93 - ETA: 0s - loss: 0.1462 - accuracy: 0.93 - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - ETA: 0s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1414 - accuracy: 0.93 - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - ETA: 0s - loss: 0.1412 - accuracy: 0.93 - ETA: 0s - loss: 0.1403 - accuracy: 0.94 - ETA: 0s - loss: 0.1400 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.94 - ETA: 0s - loss: 0.1390 - accuracy: 0.94 - ETA: 0s - loss: 0.1382 - accuracy: 0.94 - ETA: 0s - loss: 0.1379 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - 1s 145us/step - loss: 0.1379 - accuracy: 0.9407 - val_loss: 0.0986 - val_accuracy: 0.9656\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1362 - accuracy: 0.94 - ETA: 1s - loss: 0.1608 - accuracy: 0.93 - ETA: 1s - loss: 0.1467 - accuracy: 0.93 - ETA: 1s - loss: 0.1466 - accuracy: 0.93 - ETA: 1s - loss: 0.1435 - accuracy: 0.93 - ETA: 1s - loss: 0.1437 - accuracy: 0.93 - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1399 - accuracy: 0.93 - ETA: 0s - loss: 0.1394 - accuracy: 0.94 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1376 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - ETA: 0s - loss: 0.1364 - accuracy: 0.94 - ETA: 0s - loss: 0.1369 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - 1s 143us/step - loss: 0.1362 - accuracy: 0.9415 - val_loss: 0.0953 - val_accuracy: 0.9667\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1499 - accuracy: 0.92 - ETA: 1s - loss: 0.1186 - accuracy: 0.94 - ETA: 1s - loss: 0.1263 - accuracy: 0.94 - ETA: 1s - loss: 0.1328 - accuracy: 0.93 - ETA: 1s - loss: 0.1341 - accuracy: 0.93 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - 1s 145us/step - loss: 0.1347 - accuracy: 0.9421 - val_loss: 0.0949 - val_accuracy: 0.9695\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1188 - accuracy: 0.95 - ETA: 1s - loss: 0.1234 - accuracy: 0.94 - ETA: 1s - loss: 0.1244 - accuracy: 0.94 - ETA: 1s - loss: 0.1310 - accuracy: 0.94 - ETA: 1s - loss: 0.1330 - accuracy: 0.94 - ETA: 1s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - 1s 141us/step - loss: 0.1345 - accuracy: 0.9415 - val_loss: 0.0961 - val_accuracy: 0.9673\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1331 - accuracy: 0.93 - ETA: 1s - loss: 0.1295 - accuracy: 0.94 - ETA: 1s - loss: 0.1329 - accuracy: 0.94 - ETA: 1s - loss: 0.1346 - accuracy: 0.94 - ETA: 1s - loss: 0.1385 - accuracy: 0.93 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.93 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - 1s 141us/step - loss: 0.1338 - accuracy: 0.9415 - val_loss: 0.0951 - val_accuracy: 0.9625\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1185 - accuracy: 0.95 - ETA: 1s - loss: 0.1194 - accuracy: 0.94 - ETA: 1s - loss: 0.1174 - accuracy: 0.95 - ETA: 1s - loss: 0.1206 - accuracy: 0.94 - ETA: 1s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - 1s 141us/step - loss: 0.1339 - accuracy: 0.9418 - val_loss: 0.0950 - val_accuracy: 0.9701\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1360 - accuracy: 0.94 - ETA: 1s - loss: 0.1437 - accuracy: 0.94 - ETA: 1s - loss: 0.1400 - accuracy: 0.94 - ETA: 1s - loss: 0.1418 - accuracy: 0.93 - ETA: 0s - loss: 0.1391 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1355 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1347 - accuracy: 0.94 - ETA: 0s - loss: 0.1366 - accuracy: 0.94 - 1s 142us/step - loss: 0.1365 - accuracy: 0.9404 - val_loss: 0.0986 - val_accuracy: 0.9620\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1945 - accuracy: 0.90 - ETA: 1s - loss: 0.1377 - accuracy: 0.94 - ETA: 1s - loss: 0.1325 - accuracy: 0.94 - ETA: 0s - loss: 0.1373 - accuracy: 0.93 - ETA: 0s - loss: 0.1362 - accuracy: 0.93 - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1374 - accuracy: 0.94 - ETA: 0s - loss: 0.1386 - accuracy: 0.93 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - ETA: 0s - loss: 0.1385 - accuracy: 0.93 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - 1s 139us/step - loss: 0.1352 - accuracy: 0.9422 - val_loss: 0.0947 - val_accuracy: 0.9699\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1121 - accuracy: 0.95 - ETA: 1s - loss: 0.1521 - accuracy: 0.93 - ETA: 1s - loss: 0.1464 - accuracy: 0.93 - ETA: 1s - loss: 0.1366 - accuracy: 0.94 - ETA: 1s - loss: 0.1353 - accuracy: 0.94 - ETA: 1s - loss: 0.1314 - accuracy: 0.94 - ETA: 1s - loss: 0.1289 - accuracy: 0.94 - ETA: 1s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1299 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - 1s 146us/step - loss: 0.1312 - accuracy: 0.9441 - val_loss: 0.0959 - val_accuracy: 0.9623\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1234 - accuracy: 0.94 - ETA: 1s - loss: 0.1407 - accuracy: 0.93 - ETA: 1s - loss: 0.1340 - accuracy: 0.94 - ETA: 1s - loss: 0.1376 - accuracy: 0.93 - ETA: 1s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1325 - accuracy: 0.94 - ETA: 0s - loss: 0.1325 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - 1s 143us/step - loss: 0.1320 - accuracy: 0.9429 - val_loss: 0.0934 - val_accuracy: 0.9652\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1161 - accuracy: 0.94 - ETA: 1s - loss: 0.1392 - accuracy: 0.93 - ETA: 1s - loss: 0.1284 - accuracy: 0.94 - ETA: 1s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.93 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1346 - accuracy: 0.93 - ETA: 0s - loss: 0.1351 - accuracy: 0.93 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.93 - ETA: 0s - loss: 0.1346 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - 1s 138us/step - loss: 0.1341 - accuracy: 0.9406 - val_loss: 0.0976 - val_accuracy: 0.9619\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1251 - accuracy: 0.95 - ETA: 1s - loss: 0.1294 - accuracy: 0.94 - ETA: 1s - loss: 0.1227 - accuracy: 0.94 - ETA: 1s - loss: 0.1292 - accuracy: 0.94 - ETA: 1s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - ETA: 0s - loss: 0.1267 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1311 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - 1s 141us/step - loss: 0.1313 - accuracy: 0.9448 - val_loss: 0.0930 - val_accuracy: 0.9662\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1183 - accuracy: 0.94 - ETA: 1s - loss: 0.1224 - accuracy: 0.94 - ETA: 1s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1383 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1365 - accuracy: 0.94 - ETA: 0s - loss: 0.1404 - accuracy: 0.94 - ETA: 0s - loss: 0.1391 - accuracy: 0.94 - ETA: 0s - loss: 0.1389 - accuracy: 0.94 - ETA: 0s - loss: 0.1381 - accuracy: 0.94 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.94 - ETA: 0s - loss: 0.1384 - accuracy: 0.94 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1371 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - 1s 138us/step - loss: 0.1353 - accuracy: 0.9411 - val_loss: 0.0926 - val_accuracy: 0.9673\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1390 - accuracy: 0.94 - ETA: 1s - loss: 0.1381 - accuracy: 0.94 - ETA: 1s - loss: 0.1345 - accuracy: 0.94 - ETA: 1s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1357 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1341 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - 1s 137us/step - loss: 0.1333 - accuracy: 0.9441 - val_loss: 0.0917 - val_accuracy: 0.9709\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1374 - accuracy: 0.93 - ETA: 1s - loss: 0.1414 - accuracy: 0.93 - ETA: 1s - loss: 0.1343 - accuracy: 0.94 - ETA: 1s - loss: 0.1322 - accuracy: 0.94 - ETA: 1s - loss: 0.1314 - accuracy: 0.94 - ETA: 1s - loss: 0.1309 - accuracy: 0.94 - ETA: 1s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - 1s 143us/step - loss: 0.1317 - accuracy: 0.9433 - val_loss: 0.0937 - val_accuracy: 0.9685\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1281 - accuracy: 0.94 - ETA: 1s - loss: 0.1217 - accuracy: 0.95 - ETA: 1s - loss: 0.1226 - accuracy: 0.94 - ETA: 2s - loss: 0.1212 - accuracy: 0.94 - ETA: 1s - loss: 0.1289 - accuracy: 0.94 - ETA: 1s - loss: 0.1361 - accuracy: 0.93 - ETA: 1s - loss: 0.1396 - accuracy: 0.93 - ETA: 1s - loss: 0.1354 - accuracy: 0.94 - ETA: 1s - loss: 0.1347 - accuracy: 0.94 - ETA: 1s - loss: 0.1355 - accuracy: 0.93 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1358 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - 1s 146us/step - loss: 0.1341 - accuracy: 0.9411 - val_loss: 0.0982 - val_accuracy: 0.9606\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1376 - accuracy: 0.94 - ETA: 0s - loss: 0.1376 - accuracy: 0.94 - ETA: 0s - loss: 0.1373 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1371 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1374 - accuracy: 0.94 - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1351 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - 1s 124us/step - loss: 0.1349 - accuracy: 0.9422 - val_loss: 0.0919 - val_accuracy: 0.9705\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1304 - accuracy: 0.93 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1262 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - 1s 124us/step - loss: 0.1262 - accuracy: 0.9465 - val_loss: 0.0923 - val_accuracy: 0.9669\n",
            "Epoch 28/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1130 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1291 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - 1s 126us/step - loss: 0.1302 - accuracy: 0.9450 - val_loss: 0.0924 - val_accuracy: 0.9718\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1398 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1325 - accuracy: 0.94 - 1s 121us/step - loss: 0.1325 - accuracy: 0.9441 - val_loss: 0.0909 - val_accuracy: 0.9674\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 1s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1371 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1311 - accuracy: 0.94 - 1s 118us/step - loss: 0.1311 - accuracy: 0.9437 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 1s - loss: 0.1421 - accuracy: 0.93 - ETA: 0s - loss: 0.1348 - accuracy: 0.93 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - ETA: 0s - loss: 0.1363 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1395 - accuracy: 0.93 - ETA: 0s - loss: 0.1384 - accuracy: 0.93 - ETA: 0s - loss: 0.1363 - accuracy: 0.93 - ETA: 0s - loss: 0.1366 - accuracy: 0.93 - ETA: 0s - loss: 0.1366 - accuracy: 0.93 - ETA: 0s - loss: 0.1373 - accuracy: 0.93 - ETA: 0s - loss: 0.1367 - accuracy: 0.93 - ETA: 0s - loss: 0.1363 - accuracy: 0.93 - 1s 119us/step - loss: 0.1363 - accuracy: 0.9394 - val_loss: 0.0915 - val_accuracy: 0.9721\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0969 - accuracy: 0.96 - ETA: 1s - loss: 0.1315 - accuracy: 0.94 - ETA: 1s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1350 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - ETA: 0s - loss: 0.1339 - accuracy: 0.94 - 1s 120us/step - loss: 0.1333 - accuracy: 0.9433 - val_loss: 0.0903 - val_accuracy: 0.9688\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1268 - accuracy: 0.93 - ETA: 1s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1282 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - 1s 125us/step - loss: 0.1297 - accuracy: 0.9438 - val_loss: 0.0952 - val_accuracy: 0.9612\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0925 - accuracy: 0.97 - ETA: 1s - loss: 0.1382 - accuracy: 0.93 - ETA: 1s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1370 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1375 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - 1s 124us/step - loss: 0.1334 - accuracy: 0.9426 - val_loss: 0.0917 - val_accuracy: 0.9691\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.93 - ETA: 1s - loss: 0.1234 - accuracy: 0.95 - ETA: 0s - loss: 0.1361 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1303 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1303 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - 1s 122us/step - loss: 0.1308 - accuracy: 0.9439 - val_loss: 0.0895 - val_accuracy: 0.9695\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1291 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1322 - accuracy: 0.94 - 1s 121us/step - loss: 0.1322 - accuracy: 0.9430 - val_loss: 0.1062 - val_accuracy: 0.9543\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1374 - accuracy: 0.94 - ETA: 1s - loss: 0.1513 - accuracy: 0.93 - ETA: 0s - loss: 0.1442 - accuracy: 0.93 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - 1s 119us/step - loss: 0.1297 - accuracy: 0.9451 - val_loss: 0.0888 - val_accuracy: 0.9686\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1050 - accuracy: 0.96 - ETA: 1s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1336 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1262 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1282 - accuracy: 0.94 - 1s 126us/step - loss: 0.1272 - accuracy: 0.9461 - val_loss: 0.0906 - val_accuracy: 0.9705\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0928 - accuracy: 0.96 - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - 1s 125us/step - loss: 0.1303 - accuracy: 0.9436 - val_loss: 0.0955 - val_accuracy: 0.9605\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1545 - accuracy: 0.92 - ETA: 1s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - ETA: 0s - loss: 0.1385 - accuracy: 0.93 - ETA: 0s - loss: 0.1369 - accuracy: 0.94 - ETA: 0s - loss: 0.1392 - accuracy: 0.93 - ETA: 0s - loss: 0.1396 - accuracy: 0.93 - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - ETA: 0s - loss: 0.1373 - accuracy: 0.94 - ETA: 0s - loss: 0.1376 - accuracy: 0.94 - ETA: 0s - loss: 0.1387 - accuracy: 0.94 - ETA: 0s - loss: 0.1391 - accuracy: 0.93 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1365 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1356 - accuracy: 0.94 - 1s 125us/step - loss: 0.1354 - accuracy: 0.9418 - val_loss: 0.0879 - val_accuracy: 0.9708\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1649 - accuracy: 0.93 - ETA: 1s - loss: 0.1404 - accuracy: 0.93 - ETA: 1s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - 1s 124us/step - loss: 0.1304 - accuracy: 0.9440 - val_loss: 0.0894 - val_accuracy: 0.9728\n",
            "Epoch 42/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.91 - ETA: 1s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1408 - accuracy: 0.94 - ETA: 0s - loss: 0.1434 - accuracy: 0.94 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1297 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1325 - accuracy: 0.94 - 1s 126us/step - loss: 0.1320 - accuracy: 0.9434 - val_loss: 0.0898 - val_accuracy: 0.9721\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1037 - accuracy: 0.96 - ETA: 1s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1267 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1252 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - 1s 121us/step - loss: 0.1264 - accuracy: 0.9466 - val_loss: 0.0909 - val_accuracy: 0.9667\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.96 - ETA: 1s - loss: 0.1167 - accuracy: 0.95 - ETA: 1s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - 1s 128us/step - loss: 0.1287 - accuracy: 0.9444 - val_loss: 0.0875 - val_accuracy: 0.9689\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - ETA: 1s - loss: 0.1177 - accuracy: 0.95 - ETA: 1s - loss: 0.1207 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - 1s 127us/step - loss: 0.1316 - accuracy: 0.9436 - val_loss: 0.0899 - val_accuracy: 0.9679\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.94 - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.94 - ETA: 0s - loss: 0.1250 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - 1s 120us/step - loss: 0.1272 - accuracy: 0.9452 - val_loss: 0.0875 - val_accuracy: 0.9710\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0974 - accuracy: 0.95 - ETA: 1s - loss: 0.1181 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1278 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1303 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - 1s 122us/step - loss: 0.1275 - accuracy: 0.9456 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1215 - accuracy: 0.94 - ETA: 1s - loss: 0.1334 - accuracy: 0.94 - ETA: 1s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - 1s 123us/step - loss: 0.1298 - accuracy: 0.9441 - val_loss: 0.0888 - val_accuracy: 0.9682\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1252 - accuracy: 0.95 - ETA: 0s - loss: 0.1231 - accuracy: 0.95 - ETA: 0s - loss: 0.1271 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - ETA: 0s - loss: 0.1245 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1282 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - 1s 119us/step - loss: 0.1312 - accuracy: 0.9440 - val_loss: 0.0872 - val_accuracy: 0.9710\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - ETA: 0s - loss: 0.1262 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - 1s 119us/step - loss: 0.1269 - accuracy: 0.9456 - val_loss: 0.0878 - val_accuracy: 0.9704\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 143us/step\n",
            "\n",
            "Accuracy on test data: 0.97\n",
            "\n",
            "Loss on test data: 0.08\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       141\n",
            "           1       0.98      1.00      0.99       145\n",
            "           2       0.98      0.94      0.96       403\n",
            "           3       0.91      0.87      0.89       303\n",
            "           4       0.91      0.98      0.94       428\n",
            "\n",
            "    accuracy                           0.95      1420\n",
            "   macro avg       0.96      0.96      0.96      1420\n",
            "weighted avg       0.95      0.95      0.95      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14196 14198 14199] \n",
            "\n",
            "Test Index:  [   47    54    66 ... 14171 14186 14197]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.95 - ETA: 1s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1298 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1303 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1282 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - 1s 127us/step - loss: 0.1295 - accuracy: 0.9434 - val_loss: 0.1024 - val_accuracy: 0.9559\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1288 - accuracy: 0.94 - ETA: 1s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1486 - accuracy: 0.93 - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - ETA: 0s - loss: 0.1384 - accuracy: 0.94 - ETA: 0s - loss: 0.1345 - accuracy: 0.94 - ETA: 0s - loss: 0.1330 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1326 - accuracy: 0.94 - ETA: 0s - loss: 0.1338 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - 1s 122us/step - loss: 0.1323 - accuracy: 0.9427 - val_loss: 0.0862 - val_accuracy: 0.9721\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1460 - accuracy: 0.93 - ETA: 1s - loss: 0.1188 - accuracy: 0.94 - ETA: 1s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1317 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - 1s 120us/step - loss: 0.1239 - accuracy: 0.9475 - val_loss: 0.0862 - val_accuracy: 0.9692\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1109 - accuracy: 0.95 - ETA: 1s - loss: 0.1153 - accuracy: 0.94 - ETA: 1s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1244 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1251 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1252 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - 1s 123us/step - loss: 0.1249 - accuracy: 0.9471 - val_loss: 0.0856 - val_accuracy: 0.9696\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1209 - accuracy: 0.94 - ETA: 1s - loss: 0.1252 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - 1s 125us/step - loss: 0.1265 - accuracy: 0.9457 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1576 - accuracy: 0.94 - ETA: 1s - loss: 0.1236 - accuracy: 0.94 - ETA: 1s - loss: 0.1216 - accuracy: 0.94 - ETA: 1s - loss: 0.1175 - accuracy: 0.94 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.94 - ETA: 0s - loss: 0.1192 - accuracy: 0.94 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - 1s 125us/step - loss: 0.1245 - accuracy: 0.9464 - val_loss: 0.0864 - val_accuracy: 0.9758\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1031 - accuracy: 0.96 - ETA: 1s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1201 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.94 - ETA: 0s - loss: 0.1207 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1209 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - 1s 122us/step - loss: 0.1275 - accuracy: 0.9439 - val_loss: 0.0916 - val_accuracy: 0.9634\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.96 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - ETA: 0s - loss: 0.1213 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1244 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1252 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - 1s 122us/step - loss: 0.1276 - accuracy: 0.9448 - val_loss: 0.0850 - val_accuracy: 0.9752\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.96 - ETA: 1s - loss: 0.1416 - accuracy: 0.93 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1335 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1278 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1308 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1297 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - 1s 123us/step - loss: 0.1298 - accuracy: 0.9456 - val_loss: 0.0859 - val_accuracy: 0.9682\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1805 - accuracy: 0.91 - ETA: 1s - loss: 0.1392 - accuracy: 0.94 - ETA: 1s - loss: 0.1374 - accuracy: 0.93 - ETA: 0s - loss: 0.1349 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1292 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1278 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - 1s 128us/step - loss: 0.1282 - accuracy: 0.9446 - val_loss: 0.0860 - val_accuracy: 0.9704\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1046 - accuracy: 0.95 - ETA: 1s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1291 - accuracy: 0.94 - ETA: 0s - loss: 0.1271 - accuracy: 0.94 - ETA: 0s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1278 - accuracy: 0.94 - ETA: 0s - loss: 0.1271 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - 1s 126us/step - loss: 0.1273 - accuracy: 0.9455 - val_loss: 0.0859 - val_accuracy: 0.9710\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.93 - ETA: 0s - loss: 0.1251 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - 1s 118us/step - loss: 0.1211 - accuracy: 0.9496 - val_loss: 0.0850 - val_accuracy: 0.9678\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1045 - accuracy: 0.95 - ETA: 1s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1314 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - 1s 125us/step - loss: 0.1219 - accuracy: 0.9488 - val_loss: 0.0860 - val_accuracy: 0.9675\n",
            "Epoch 14/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0836 - accuracy: 0.97 - ETA: 1s - loss: 0.1239 - accuracy: 0.94 - ETA: 1s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1262 - accuracy: 0.94 - ETA: 0s - loss: 0.1252 - accuracy: 0.94 - 1s 127us/step - loss: 0.1254 - accuracy: 0.9463 - val_loss: 0.0855 - val_accuracy: 0.9747\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1483 - accuracy: 0.93 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - 1s 120us/step - loss: 0.1238 - accuracy: 0.9476 - val_loss: 0.0867 - val_accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.92 - ETA: 1s - loss: 0.1209 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - ETA: 0s - loss: 0.1303 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1295 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1297 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1262 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - 1s 120us/step - loss: 0.1263 - accuracy: 0.9464 - val_loss: 0.0849 - val_accuracy: 0.9708\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1050 - accuracy: 0.95 - ETA: 1s - loss: 0.1379 - accuracy: 0.94 - ETA: 1s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1343 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1309 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1315 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1297 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1299 - accuracy: 0.94 - ETA: 0s - loss: 0.1296 - accuracy: 0.94 - 1s 127us/step - loss: 0.1295 - accuracy: 0.9450 - val_loss: 0.0913 - val_accuracy: 0.9625\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1260 - accuracy: 0.94 - ETA: 1s - loss: 0.1537 - accuracy: 0.93 - ETA: 0s - loss: 0.1386 - accuracy: 0.94 - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1280 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - 1s 122us/step - loss: 0.1274 - accuracy: 0.9454 - val_loss: 0.0900 - val_accuracy: 0.9645\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1476 - accuracy: 0.94 - ETA: 1s - loss: 0.1410 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1272 - accuracy: 0.94 - ETA: 0s - loss: 0.1271 - accuracy: 0.94 - ETA: 0s - loss: 0.1245 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1250 - accuracy: 0.94 - ETA: 0s - loss: 0.1282 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - 1s 120us/step - loss: 0.1263 - accuracy: 0.9456 - val_loss: 0.0826 - val_accuracy: 0.9734\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1111 - accuracy: 0.96 - ETA: 1s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1223 - accuracy: 0.95 - ETA: 0s - loss: 0.1241 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.95 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.95 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.95 - ETA: 0s - loss: 0.1207 - accuracy: 0.95 - ETA: 0s - loss: 0.1216 - accuracy: 0.95 - ETA: 0s - loss: 0.1213 - accuracy: 0.95 - ETA: 0s - loss: 0.1217 - accuracy: 0.95 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - 1s 124us/step - loss: 0.1232 - accuracy: 0.9493 - val_loss: 0.0843 - val_accuracy: 0.9694\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1299 - accuracy: 0.95 - ETA: 1s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - 1s 124us/step - loss: 0.1296 - accuracy: 0.9446 - val_loss: 0.0952 - val_accuracy: 0.9580\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1812 - accuracy: 0.91 - ETA: 1s - loss: 0.1372 - accuracy: 0.93 - ETA: 0s - loss: 0.1368 - accuracy: 0.93 - ETA: 0s - loss: 0.1382 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - 1s 122us/step - loss: 0.1223 - accuracy: 0.9478 - val_loss: 0.0829 - val_accuracy: 0.9717\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 1s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1213 - accuracy: 0.94 - ETA: 0s - loss: 0.1251 - accuracy: 0.94 - ETA: 0s - loss: 0.1271 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - 1s 122us/step - loss: 0.1199 - accuracy: 0.9492 - val_loss: 0.0824 - val_accuracy: 0.9722\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0826 - accuracy: 0.97 - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1190 - accuracy: 0.95 - ETA: 1s - loss: 0.1199 - accuracy: 0.95 - ETA: 1s - loss: 0.1241 - accuracy: 0.94 - ETA: 1s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1250 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - 1s 130us/step - loss: 0.1266 - accuracy: 0.9464 - val_loss: 0.0830 - val_accuracy: 0.9718\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0999 - accuracy: 0.96 - ETA: 1s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1250 - accuracy: 0.94 - ETA: 0s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1310 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1333 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1305 - accuracy: 0.94 - ETA: 0s - loss: 0.1304 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1291 - accuracy: 0.94 - ETA: 0s - loss: 0.1301 - accuracy: 0.94 - ETA: 0s - loss: 0.1291 - accuracy: 0.94 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - 1s 125us/step - loss: 0.1280 - accuracy: 0.9456 - val_loss: 0.0835 - val_accuracy: 0.9707\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - 1s 121us/step - loss: 0.1195 - accuracy: 0.9499 - val_loss: 0.0834 - val_accuracy: 0.9764\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1190 - accuracy: 0.95 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1207 - accuracy: 0.94 - ETA: 0s - loss: 0.1192 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - 1s 125us/step - loss: 0.1219 - accuracy: 0.9475 - val_loss: 0.0813 - val_accuracy: 0.9759\n",
            "Epoch 28/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1300 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1328 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1289 - accuracy: 0.94 - ETA: 0s - loss: 0.1297 - accuracy: 0.94 - ETA: 0s - loss: 0.1294 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1286 - accuracy: 0.94 - 1s 125us/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.0834 - val_accuracy: 0.9694\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1143 - accuracy: 0.95 - ETA: 1s - loss: 0.1240 - accuracy: 0.94 - ETA: 1s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1241 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - ETA: 0s - loss: 0.1213 - accuracy: 0.94 - ETA: 0s - loss: 0.1209 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - 1s 122us/step - loss: 0.1199 - accuracy: 0.9492 - val_loss: 0.0820 - val_accuracy: 0.9721\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.94 - ETA: 1s - loss: 0.1246 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1245 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.94 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1283 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1270 - accuracy: 0.94 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1254 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - 1s 124us/step - loss: 0.1239 - accuracy: 0.9473 - val_loss: 0.0819 - val_accuracy: 0.9768\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0954 - accuracy: 0.97 - ETA: 1s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.94 - ETA: 0s - loss: 0.1180 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - 1s 121us/step - loss: 0.1218 - accuracy: 0.9484 - val_loss: 0.0814 - val_accuracy: 0.9744\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.96 - ETA: 1s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1186 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - 1s 120us/step - loss: 0.1240 - accuracy: 0.9477 - val_loss: 0.0826 - val_accuracy: 0.9695\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.96 - ETA: 0s - loss: 0.1237 - accuracy: 0.95 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.95 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - 1s 120us/step - loss: 0.1181 - accuracy: 0.9502 - val_loss: 0.0809 - val_accuracy: 0.9732\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.95 - ETA: 1s - loss: 0.1230 - accuracy: 0.94 - ETA: 1s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - 1s 123us/step - loss: 0.1170 - accuracy: 0.9512 - val_loss: 0.0793 - val_accuracy: 0.9756\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.94 - ETA: 1s - loss: 0.1327 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1322 - accuracy: 0.94 - ETA: 0s - loss: 0.1312 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1352 - accuracy: 0.94 - ETA: 0s - loss: 0.1334 - accuracy: 0.94 - ETA: 0s - loss: 0.1313 - accuracy: 0.94 - ETA: 0s - loss: 0.1320 - accuracy: 0.94 - ETA: 0s - loss: 0.1299 - accuracy: 0.94 - ETA: 0s - loss: 0.1287 - accuracy: 0.94 - ETA: 0s - loss: 0.1278 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - 1s 123us/step - loss: 0.1265 - accuracy: 0.9463 - val_loss: 0.0816 - val_accuracy: 0.9705\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.92 - ETA: 1s - loss: 0.1221 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.94 - ETA: 0s - loss: 0.1192 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1209 - accuracy: 0.94 - 1s 123us/step - loss: 0.1207 - accuracy: 0.9486 - val_loss: 0.0890 - val_accuracy: 0.9728\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1009 - accuracy: 0.96 - ETA: 1s - loss: 0.1154 - accuracy: 0.95 - ETA: 1s - loss: 0.1235 - accuracy: 0.94 - ETA: 1s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1207 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1213 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - 1s 128us/step - loss: 0.1179 - accuracy: 0.9499 - val_loss: 0.0798 - val_accuracy: 0.9747\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1553 - accuracy: 0.93 - ETA: 1s - loss: 0.1350 - accuracy: 0.93 - ETA: 0s - loss: 0.1257 - accuracy: 0.94 - ETA: 0s - loss: 0.1269 - accuracy: 0.94 - ETA: 0s - loss: 0.1231 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1244 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1231 - accuracy: 0.94 - ETA: 0s - loss: 0.1224 - accuracy: 0.94 - 1s 124us/step - loss: 0.1223 - accuracy: 0.9484 - val_loss: 0.0823 - val_accuracy: 0.9698\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 1s - loss: 0.1387 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1214 - accuracy: 0.95 - ETA: 0s - loss: 0.1207 - accuracy: 0.95 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1191 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - 1s 127us/step - loss: 0.1204 - accuracy: 0.9494 - val_loss: 0.0808 - val_accuracy: 0.9707\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0908 - accuracy: 0.96 - ETA: 1s - loss: 0.1085 - accuracy: 0.95 - ETA: 1s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1218 - accuracy: 0.95 - ETA: 0s - loss: 0.1218 - accuracy: 0.95 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1256 - accuracy: 0.94 - ETA: 0s - loss: 0.1259 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1252 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1239 - accuracy: 0.94 - ETA: 0s - loss: 0.1231 - accuracy: 0.94 - 1s 122us/step - loss: 0.1225 - accuracy: 0.9492 - val_loss: 0.0790 - val_accuracy: 0.9753\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.94 - ETA: 0s - loss: 0.1279 - accuracy: 0.94 - ETA: 0s - loss: 0.1281 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1184 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.94 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1187 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - 1s 120us/step - loss: 0.1200 - accuracy: 0.9495 - val_loss: 0.0802 - val_accuracy: 0.9712\n",
            "Epoch 42/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.90 - ETA: 1s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1201 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - 1s 123us/step - loss: 0.1204 - accuracy: 0.9485 - val_loss: 0.0829 - val_accuracy: 0.9767\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1318 - accuracy: 0.94 - ETA: 1s - loss: 0.1213 - accuracy: 0.95 - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - ETA: 0s - loss: 0.1293 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1250 - accuracy: 0.94 - ETA: 0s - loss: 0.1228 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - 1s 125us/step - loss: 0.1203 - accuracy: 0.9496 - val_loss: 0.0781 - val_accuracy: 0.9772\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.92 - ETA: 1s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1241 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - 1s 120us/step - loss: 0.1209 - accuracy: 0.9499 - val_loss: 0.0798 - val_accuracy: 0.9772\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0929 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.94 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1168 - accuracy: 0.94 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - 1s 121us/step - loss: 0.1146 - accuracy: 0.9513 - val_loss: 0.0782 - val_accuracy: 0.9728\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1147 - accuracy: 0.95 - ETA: 1s - loss: 0.1230 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - 1s 126us/step - loss: 0.1177 - accuracy: 0.9519 - val_loss: 0.0792 - val_accuracy: 0.9710\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1183 - accuracy: 0.94 - ETA: 0s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - 1s 125us/step - loss: 0.1217 - accuracy: 0.9476 - val_loss: 0.0795 - val_accuracy: 0.9750\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1071 - accuracy: 0.95 - ETA: 1s - loss: 0.1328 - accuracy: 0.94 - ETA: 1s - loss: 0.1288 - accuracy: 0.94 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1266 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1218 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1219 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1238 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - 1s 125us/step - loss: 0.1248 - accuracy: 0.9472 - val_loss: 0.0787 - val_accuracy: 0.9752\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1205 - accuracy: 0.94 - ETA: 1s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - 1s 126us/step - loss: 0.1163 - accuracy: 0.9512 - val_loss: 0.0794 - val_accuracy: 0.9746\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.96 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 1s 121us/step - loss: 0.1175 - accuracy: 0.9513 - val_loss: 0.0793 - val_accuracy: 0.9756\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - 0s 110us/step\n",
            "\n",
            "Accuracy on test data: 0.97\n",
            "\n",
            "Loss on test data: 0.08\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       126\n",
            "           1       0.98      0.96      0.97       137\n",
            "           2       0.97      0.96      0.97       439\n",
            "           3       0.95      0.92      0.94       316\n",
            "           4       0.94      0.98      0.96       402\n",
            "\n",
            "    accuracy                           0.96      1420\n",
            "   macro avg       0.97      0.96      0.96      1420\n",
            "weighted avg       0.96      0.96      0.96      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [   20    24    45 ... 14165 14166 14173]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1029 - accuracy: 0.94 - ETA: 1s - loss: 0.1137 - accuracy: 0.94 - ETA: 1s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1208 - accuracy: 0.95 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - 1s 124us/step - loss: 0.1195 - accuracy: 0.9498 - val_loss: 0.0904 - val_accuracy: 0.9603\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.93 - ETA: 0s - loss: 0.1255 - accuracy: 0.94 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1208 - accuracy: 0.95 - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - 1s 120us/step - loss: 0.1183 - accuracy: 0.9510 - val_loss: 0.0760 - val_accuracy: 0.9783\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.93 - ETA: 1s - loss: 0.1232 - accuracy: 0.94 - ETA: 0s - loss: 0.1263 - accuracy: 0.95 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - ETA: 0s - loss: 0.1190 - accuracy: 0.95 - ETA: 0s - loss: 0.1184 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - 1s 119us/step - loss: 0.1193 - accuracy: 0.9499 - val_loss: 0.0785 - val_accuracy: 0.9703\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1074 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1184 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - 1s 124us/step - loss: 0.1182 - accuracy: 0.9504 - val_loss: 0.0838 - val_accuracy: 0.9756\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1219 - accuracy: 0.95 - ETA: 1s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1316 - accuracy: 0.94 - ETA: 0s - loss: 0.1332 - accuracy: 0.94 - ETA: 0s - loss: 0.1311 - accuracy: 0.94 - ETA: 0s - loss: 0.1324 - accuracy: 0.94 - ETA: 0s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1268 - accuracy: 0.94 - ETA: 0s - loss: 0.1249 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1235 - accuracy: 0.94 - ETA: 0s - loss: 0.1236 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.94 - ETA: 0s - loss: 0.1233 - accuracy: 0.94 - 1s 124us/step - loss: 0.1233 - accuracy: 0.9479 - val_loss: 0.0759 - val_accuracy: 0.9790\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0800 - accuracy: 0.97 - ETA: 1s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - 1s 120us/step - loss: 0.1202 - accuracy: 0.9498 - val_loss: 0.0782 - val_accuracy: 0.9733\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 1s - loss: 0.1274 - accuracy: 0.94 - ETA: 0s - loss: 0.1337 - accuracy: 0.94 - ETA: 0s - loss: 0.1260 - accuracy: 0.94 - ETA: 0s - loss: 0.1223 - accuracy: 0.95 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1204 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - 1s 122us/step - loss: 0.1237 - accuracy: 0.9483 - val_loss: 0.0775 - val_accuracy: 0.9721\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1782 - accuracy: 0.92 - ETA: 0s - loss: 0.1242 - accuracy: 0.94 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1276 - accuracy: 0.94 - ETA: 0s - loss: 0.1275 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.94 - ETA: 0s - loss: 0.1191 - accuracy: 0.94 - ETA: 0s - loss: 0.1184 - accuracy: 0.95 - 1s 119us/step - loss: 0.1192 - accuracy: 0.9499 - val_loss: 0.0800 - val_accuracy: 0.9766\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.93 - ETA: 0s - loss: 0.1306 - accuracy: 0.94 - ETA: 0s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - 1s 122us/step - loss: 0.1207 - accuracy: 0.9491 - val_loss: 0.0763 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1226 - accuracy: 0.94 - ETA: 1s - loss: 0.1172 - accuracy: 0.95 - ETA: 1s - loss: 0.1229 - accuracy: 0.94 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.94 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.94 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.94 - 1s 122us/step - loss: 0.1185 - accuracy: 0.9498 - val_loss: 0.0756 - val_accuracy: 0.9765\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0973 - accuracy: 0.95 - ETA: 1s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1205 - accuracy: 0.95 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - 1s 121us/step - loss: 0.1165 - accuracy: 0.9508 - val_loss: 0.0761 - val_accuracy: 0.9735\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0731 - accuracy: 0.97 - ETA: 1s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1216 - accuracy: 0.94 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - 1s 122us/step - loss: 0.1189 - accuracy: 0.9499 - val_loss: 0.0795 - val_accuracy: 0.9763\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0993 - accuracy: 0.96 - ETA: 1s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1225 - accuracy: 0.94 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1188 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - 1s 121us/step - loss: 0.1176 - accuracy: 0.9499 - val_loss: 0.0740 - val_accuracy: 0.9764\n",
            "Epoch 14/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0869 - accuracy: 0.96 - ETA: 0s - loss: 0.1233 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - 1s 122us/step - loss: 0.1185 - accuracy: 0.9509 - val_loss: 0.0752 - val_accuracy: 0.9788\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - ETA: 1s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - ETA: 0s - loss: 0.1207 - accuracy: 0.95 - ETA: 0s - loss: 0.1195 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1223 - accuracy: 0.94 - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - 1s 122us/step - loss: 0.1190 - accuracy: 0.9509 - val_loss: 0.0753 - val_accuracy: 0.9793\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.94 - ETA: 0s - loss: 0.1302 - accuracy: 0.94 - ETA: 0s - loss: 0.1264 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.94 - ETA: 0s - loss: 0.1231 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1172 - accuracy: 0.94 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - 1s 125us/step - loss: 0.1168 - accuracy: 0.9513 - val_loss: 0.0760 - val_accuracy: 0.9781\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1356 - accuracy: 0.93 - ETA: 1s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - 1s 122us/step - loss: 0.1183 - accuracy: 0.9510 - val_loss: 0.0764 - val_accuracy: 0.9731\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.96 - ETA: 0s - loss: 0.1234 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - 1s 122us/step - loss: 0.1186 - accuracy: 0.9507 - val_loss: 0.0790 - val_accuracy: 0.9775\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1233 - accuracy: 0.94 - ETA: 1s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1221 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1183 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - 1s 128us/step - loss: 0.1193 - accuracy: 0.9504 - val_loss: 0.0739 - val_accuracy: 0.9793\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0944 - accuracy: 0.95 - ETA: 1s - loss: 0.1093 - accuracy: 0.95 - ETA: 1s - loss: 0.1307 - accuracy: 0.94 - ETA: 0s - loss: 0.1222 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1220 - accuracy: 0.94 - ETA: 0s - loss: 0.1209 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1205 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - 1s 131us/step - loss: 0.1204 - accuracy: 0.9502 - val_loss: 0.0786 - val_accuracy: 0.9711\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1019 - accuracy: 0.96 - ETA: 1s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - 1s 129us/step - loss: 0.1156 - accuracy: 0.9518 - val_loss: 0.0734 - val_accuracy: 0.9770\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1024 - accuracy: 0.96 - ETA: 1s - loss: 0.1018 - accuracy: 0.96 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - 1s 127us/step - loss: 0.1166 - accuracy: 0.9522 - val_loss: 0.0739 - val_accuracy: 0.9790\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.93 - ETA: 1s - loss: 0.1282 - accuracy: 0.94 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - 1s 123us/step - loss: 0.1196 - accuracy: 0.9508 - val_loss: 0.0737 - val_accuracy: 0.9786\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1549 - accuracy: 0.94 - ETA: 1s - loss: 0.1318 - accuracy: 0.94 - ETA: 0s - loss: 0.1226 - accuracy: 0.95 - ETA: 0s - loss: 0.1211 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - 1s 127us/step - loss: 0.1171 - accuracy: 0.9514 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.97 - ETA: 1s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - 1s 125us/step - loss: 0.1158 - accuracy: 0.9524 - val_loss: 0.0796 - val_accuracy: 0.9667\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0856 - accuracy: 0.96 - ETA: 1s - loss: 0.1371 - accuracy: 0.94 - ETA: 0s - loss: 0.1323 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1227 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - 1s 134us/step - loss: 0.1183 - accuracy: 0.9507 - val_loss: 0.0794 - val_accuracy: 0.9680\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0817 - accuracy: 0.96 - ETA: 1s - loss: 0.1019 - accuracy: 0.95 - ETA: 1s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - 1s 130us/step - loss: 0.1159 - accuracy: 0.9519 - val_loss: 0.0748 - val_accuracy: 0.9760\n",
            "Epoch 28/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 1s 123us/step - loss: 0.1172 - accuracy: 0.9504 - val_loss: 0.0734 - val_accuracy: 0.9775\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.93 - ETA: 1s - loss: 0.1261 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1190 - accuracy: 0.94 - ETA: 0s - loss: 0.1202 - accuracy: 0.94 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.94 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.94 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - 1s 121us/step - loss: 0.1165 - accuracy: 0.9502 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3425 - accuracy: 0.84 - ETA: 0s - loss: 0.1411 - accuracy: 0.94 - ETA: 0s - loss: 0.1258 - accuracy: 0.95 - ETA: 0s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1273 - accuracy: 0.94 - ETA: 0s - loss: 0.1267 - accuracy: 0.94 - ETA: 0s - loss: 0.1265 - accuracy: 0.94 - ETA: 0s - loss: 0.1253 - accuracy: 0.94 - ETA: 0s - loss: 0.1247 - accuracy: 0.94 - ETA: 0s - loss: 0.1237 - accuracy: 0.94 - ETA: 0s - loss: 0.1214 - accuracy: 0.95 - ETA: 0s - loss: 0.1204 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1195 - accuracy: 0.95 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.94 - 1s 125us/step - loss: 0.1202 - accuracy: 0.9498 - val_loss: 0.0763 - val_accuracy: 0.9753\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0719 - accuracy: 0.97 - ETA: 1s - loss: 0.1257 - accuracy: 0.94 - ETA: 1s - loss: 0.1347 - accuracy: 0.94 - ETA: 0s - loss: 0.1277 - accuracy: 0.94 - ETA: 0s - loss: 0.1210 - accuracy: 0.94 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.94 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - 1s 126us/step - loss: 0.1148 - accuracy: 0.9528 - val_loss: 0.0732 - val_accuracy: 0.9761\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1453 - accuracy: 0.93 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - 1s 122us/step - loss: 0.1169 - accuracy: 0.9517 - val_loss: 0.0724 - val_accuracy: 0.9767\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1644 - accuracy: 0.92 - ETA: 1s - loss: 0.1319 - accuracy: 0.94 - ETA: 0s - loss: 0.1248 - accuracy: 0.94 - ETA: 0s - loss: 0.1179 - accuracy: 0.94 - ETA: 0s - loss: 0.1212 - accuracy: 0.94 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - 1s 123us/step - loss: 0.1171 - accuracy: 0.9515 - val_loss: 0.0721 - val_accuracy: 0.9767\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1463 - accuracy: 0.93 - ETA: 1s - loss: 0.1188 - accuracy: 0.95 - ETA: 1s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1197 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - 1s 123us/step - loss: 0.1144 - accuracy: 0.9527 - val_loss: 0.0731 - val_accuracy: 0.9764\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - 1s 119us/step - loss: 0.1132 - accuracy: 0.9534 - val_loss: 0.0722 - val_accuracy: 0.9790\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1349 - accuracy: 0.95 - ETA: 1s - loss: 0.1184 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - 1s 124us/step - loss: 0.1141 - accuracy: 0.9523 - val_loss: 0.0714 - val_accuracy: 0.9793\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0949 - accuracy: 0.95 - ETA: 1s - loss: 0.1012 - accuracy: 0.95 - ETA: 1s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - 1s 125us/step - loss: 0.1106 - accuracy: 0.9550 - val_loss: 0.0752 - val_accuracy: 0.9755\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1073 - accuracy: 0.95 - ETA: 1s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1229 - accuracy: 0.95 - ETA: 0s - loss: 0.1224 - accuracy: 0.95 - ETA: 0s - loss: 0.1211 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1192 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 1s 138us/step - loss: 0.1181 - accuracy: 0.9508 - val_loss: 0.0721 - val_accuracy: 0.9787\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1319 - accuracy: 0.94 - ETA: 1s - loss: 0.1184 - accuracy: 0.94 - ETA: 1s - loss: 0.1188 - accuracy: 0.95 - ETA: 1s - loss: 0.1161 - accuracy: 0.95 - ETA: 1s - loss: 0.1132 - accuracy: 0.95 - ETA: 1s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - 2s 148us/step - loss: 0.1122 - accuracy: 0.9532 - val_loss: 0.0718 - val_accuracy: 0.9762\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2926 - accuracy: 0.90 - ETA: 1s - loss: 0.1373 - accuracy: 0.94 - ETA: 1s - loss: 0.1312 - accuracy: 0.94 - ETA: 1s - loss: 0.1297 - accuracy: 0.94 - ETA: 1s - loss: 0.1238 - accuracy: 0.95 - ETA: 0s - loss: 0.1243 - accuracy: 0.95 - ETA: 0s - loss: 0.1204 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - 1s 140us/step - loss: 0.1132 - accuracy: 0.9531 - val_loss: 0.0714 - val_accuracy: 0.9761\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1222 - accuracy: 0.95 - ETA: 1s - loss: 0.1275 - accuracy: 0.94 - ETA: 1s - loss: 0.1184 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1214 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - 1s 141us/step - loss: 0.1162 - accuracy: 0.9524 - val_loss: 0.0725 - val_accuracy: 0.9745\n",
            "Epoch 42/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1254 - accuracy: 0.93 - ETA: 1s - loss: 0.1123 - accuracy: 0.95 - ETA: 1s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - 1s 136us/step - loss: 0.1129 - accuracy: 0.9520 - val_loss: 0.0719 - val_accuracy: 0.9770\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0913 - accuracy: 0.96 - ETA: 1s - loss: 0.0953 - accuracy: 0.96 - ETA: 1s - loss: 0.1003 - accuracy: 0.96 - ETA: 1s - loss: 0.1009 - accuracy: 0.96 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 2s 150us/step - loss: 0.1093 - accuracy: 0.9548 - val_loss: 0.0736 - val_accuracy: 0.9730\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1016 - accuracy: 0.96 - ETA: 1s - loss: 0.0995 - accuracy: 0.96 - ETA: 1s - loss: 0.0958 - accuracy: 0.96 - ETA: 1s - loss: 0.1023 - accuracy: 0.95 - ETA: 1s - loss: 0.1033 - accuracy: 0.95 - ETA: 1s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - 1s 138us/step - loss: 0.1147 - accuracy: 0.9514 - val_loss: 0.0774 - val_accuracy: 0.9695\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1261 - accuracy: 0.94 - ETA: 1s - loss: 0.1084 - accuracy: 0.95 - ETA: 1s - loss: 0.1069 - accuracy: 0.95 - ETA: 1s - loss: 0.1053 - accuracy: 0.95 - ETA: 1s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - 1s 138us/step - loss: 0.1118 - accuracy: 0.9547 - val_loss: 0.0781 - val_accuracy: 0.9677\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0875 - accuracy: 0.96 - ETA: 1s - loss: 0.0970 - accuracy: 0.96 - ETA: 1s - loss: 0.1093 - accuracy: 0.95 - ETA: 1s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - 1s 139us/step - loss: 0.1123 - accuracy: 0.9537 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0931 - accuracy: 0.96 - ETA: 1s - loss: 0.1006 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.96 - ETA: 1s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - 1s 135us/step - loss: 0.1115 - accuracy: 0.9533 - val_loss: 0.0748 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1110 - accuracy: 0.96 - ETA: 1s - loss: 0.1353 - accuracy: 0.94 - ETA: 1s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1284 - accuracy: 0.94 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1214 - accuracy: 0.94 - ETA: 0s - loss: 0.1213 - accuracy: 0.94 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - 1s 141us/step - loss: 0.1160 - accuracy: 0.9517 - val_loss: 0.0699 - val_accuracy: 0.9800\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1117 - accuracy: 0.96 - ETA: 1s - loss: 0.1124 - accuracy: 0.95 - ETA: 1s - loss: 0.1067 - accuracy: 0.95 - ETA: 1s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - 1s 140us/step - loss: 0.1132 - accuracy: 0.9535 - val_loss: 0.0714 - val_accuracy: 0.9808\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0948 - accuracy: 0.96 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1136 - accuracy: 0.95 - ETA: 1s - loss: 0.1169 - accuracy: 0.95 - ETA: 1s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - 1s 139us/step - loss: 0.1133 - accuracy: 0.9522 - val_loss: 0.0706 - val_accuracy: 0.9781\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 130us/step\n",
            "\n",
            "Accuracy on test data: 0.98\n",
            "\n",
            "Loss on test data: 0.07\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       120\n",
            "           1       1.00      0.99      1.00       141\n",
            "           2       0.98      0.96      0.97       408\n",
            "           3       0.96      0.85      0.90       310\n",
            "           4       0.90      0.99      0.94       441\n",
            "\n",
            "    accuracy                           0.95      1420\n",
            "   macro avg       0.97      0.96      0.96      1420\n",
            "weighted avg       0.95      0.95      0.95      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [    3     4    15 ... 14156 14158 14162]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 2s - loss: 0.0955 - accuracy: 0.96 - ETA: 1s - loss: 0.1054 - accuracy: 0.95 - ETA: 1s - loss: 0.1114 - accuracy: 0.95 - ETA: 1s - loss: 0.1101 - accuracy: 0.95 - ETA: 1s - loss: 0.1117 - accuracy: 0.95 - ETA: 1s - loss: 0.1133 - accuracy: 0.95 - ETA: 1s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1211 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.94 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1194 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 1s 146us/step - loss: 0.1166 - accuracy: 0.9520 - val_loss: 0.0728 - val_accuracy: 0.9776\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1157 - accuracy: 0.94 - ETA: 1s - loss: 0.1519 - accuracy: 0.93 - ETA: 1s - loss: 0.1296 - accuracy: 0.94 - ETA: 1s - loss: 0.1216 - accuracy: 0.94 - ETA: 1s - loss: 0.1186 - accuracy: 0.94 - ETA: 1s - loss: 0.1178 - accuracy: 0.94 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - 1s 144us/step - loss: 0.1175 - accuracy: 0.9512 - val_loss: 0.0713 - val_accuracy: 0.9791\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0856 - accuracy: 0.96 - ETA: 1s - loss: 0.1054 - accuracy: 0.95 - ETA: 1s - loss: 0.1080 - accuracy: 0.95 - ETA: 1s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - 1s 141us/step - loss: 0.1113 - accuracy: 0.9530 - val_loss: 0.0711 - val_accuracy: 0.9783\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0985 - accuracy: 0.96 - ETA: 1s - loss: 0.1163 - accuracy: 0.94 - ETA: 1s - loss: 0.1176 - accuracy: 0.94 - ETA: 1s - loss: 0.1116 - accuracy: 0.95 - ETA: 1s - loss: 0.1109 - accuracy: 0.95 - ETA: 1s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - 1s 140us/step - loss: 0.1101 - accuracy: 0.9536 - val_loss: 0.0708 - val_accuracy: 0.9813\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 1s - loss: 0.0993 - accuracy: 0.96 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - 1s 136us/step - loss: 0.1123 - accuracy: 0.9531 - val_loss: 0.0740 - val_accuracy: 0.9750\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0714 - accuracy: 0.97 - ETA: 1s - loss: 0.1015 - accuracy: 0.95 - ETA: 1s - loss: 0.1044 - accuracy: 0.95 - ETA: 1s - loss: 0.1136 - accuracy: 0.95 - ETA: 1s - loss: 0.1174 - accuracy: 0.95 - ETA: 1s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.94 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.94 - ETA: 0s - loss: 0.1187 - accuracy: 0.94 - ETA: 0s - loss: 0.1179 - accuracy: 0.94 - ETA: 0s - loss: 0.1194 - accuracy: 0.94 - ETA: 0s - loss: 0.1186 - accuracy: 0.94 - ETA: 0s - loss: 0.1172 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.94 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - 1s 139us/step - loss: 0.1150 - accuracy: 0.9512 - val_loss: 0.0717 - val_accuracy: 0.9746\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.3557 - accuracy: 0.87 - ETA: 1s - loss: 0.1416 - accuracy: 0.94 - ETA: 1s - loss: 0.1398 - accuracy: 0.94 - ETA: 1s - loss: 0.1363 - accuracy: 0.94 - ETA: 1s - loss: 0.1290 - accuracy: 0.94 - ETA: 0s - loss: 0.1243 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.94 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.94 - ETA: 0s - loss: 0.1178 - accuracy: 0.94 - ETA: 0s - loss: 0.1184 - accuracy: 0.94 - ETA: 0s - loss: 0.1183 - accuracy: 0.94 - ETA: 0s - loss: 0.1187 - accuracy: 0.94 - ETA: 0s - loss: 0.1181 - accuracy: 0.94 - 1s 141us/step - loss: 0.1185 - accuracy: 0.9495 - val_loss: 0.0722 - val_accuracy: 0.9795\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0916 - accuracy: 0.96 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 1s - loss: 0.1017 - accuracy: 0.95 - ETA: 1s - loss: 0.1041 - accuracy: 0.95 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - 1s 139us/step - loss: 0.1101 - accuracy: 0.9541 - val_loss: 0.0740 - val_accuracy: 0.9739\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0834 - accuracy: 0.97 - ETA: 1s - loss: 0.1122 - accuracy: 0.95 - ETA: 1s - loss: 0.1063 - accuracy: 0.95 - ETA: 1s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1174 - accuracy: 0.94 - ETA: 0s - loss: 0.1181 - accuracy: 0.94 - ETA: 0s - loss: 0.1173 - accuracy: 0.94 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1162 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - 1s 138us/step - loss: 0.1167 - accuracy: 0.9511 - val_loss: 0.0740 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0857 - accuracy: 0.96 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 1s - loss: 0.1165 - accuracy: 0.95 - ETA: 1s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1207 - accuracy: 0.94 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1217 - accuracy: 0.94 - ETA: 0s - loss: 0.1196 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - 1s 143us/step - loss: 0.1181 - accuracy: 0.9509 - val_loss: 0.0763 - val_accuracy: 0.9696\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1264 - accuracy: 0.93 - ETA: 1s - loss: 0.1263 - accuracy: 0.94 - ETA: 1s - loss: 0.1181 - accuracy: 0.94 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1166 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1189 - accuracy: 0.95 - ETA: 0s - loss: 0.1180 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - 1s 136us/step - loss: 0.1142 - accuracy: 0.9526 - val_loss: 0.0698 - val_accuracy: 0.9792\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1278 - accuracy: 0.93 - ETA: 1s - loss: 0.1114 - accuracy: 0.95 - ETA: 1s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.94 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - 1s 139us/step - loss: 0.1096 - accuracy: 0.9540 - val_loss: 0.0704 - val_accuracy: 0.9791\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0669 - accuracy: 0.98 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 1s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - 2s 147us/step - loss: 0.1154 - accuracy: 0.9515 - val_loss: 0.0706 - val_accuracy: 0.9758\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1065 - accuracy: 0.95 - ETA: 1s - loss: 0.1103 - accuracy: 0.95 - ETA: 1s - loss: 0.1076 - accuracy: 0.95 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 1s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - 1s 143us/step - loss: 0.1059 - accuracy: 0.9570 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0862 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.94 - ETA: 1s - loss: 0.1092 - accuracy: 0.95 - ETA: 1s - loss: 0.1113 - accuracy: 0.95 - ETA: 1s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - 1s 138us/step - loss: 0.1136 - accuracy: 0.9514 - val_loss: 0.0733 - val_accuracy: 0.9710\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0996 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.95 - ETA: 1s - loss: 0.1053 - accuracy: 0.95 - ETA: 1s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.94 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 1s 138us/step - loss: 0.1087 - accuracy: 0.9546 - val_loss: 0.0701 - val_accuracy: 0.9776\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2027 - accuracy: 0.91 - ETA: 1s - loss: 0.1439 - accuracy: 0.93 - ETA: 1s - loss: 0.1306 - accuracy: 0.94 - ETA: 1s - loss: 0.1198 - accuracy: 0.95 - ETA: 1s - loss: 0.1208 - accuracy: 0.94 - ETA: 0s - loss: 0.1215 - accuracy: 0.94 - ETA: 0s - loss: 0.1177 - accuracy: 0.94 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.94 - ETA: 0s - loss: 0.1176 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.94 - ETA: 0s - loss: 0.1168 - accuracy: 0.94 - ETA: 0s - loss: 0.1169 - accuracy: 0.94 - ETA: 0s - loss: 0.1166 - accuracy: 0.94 - ETA: 0s - loss: 0.1160 - accuracy: 0.94 - ETA: 0s - loss: 0.1164 - accuracy: 0.94 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1156 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - 1s 138us/step - loss: 0.1145 - accuracy: 0.9512 - val_loss: 0.0736 - val_accuracy: 0.9717\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0715 - accuracy: 0.97 - ETA: 1s - loss: 0.0903 - accuracy: 0.96 - ETA: 1s - loss: 0.0925 - accuracy: 0.96 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 1s 141us/step - loss: 0.1109 - accuracy: 0.9536 - val_loss: 0.0721 - val_accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2102 - accuracy: 0.91 - ETA: 1s - loss: 0.1336 - accuracy: 0.94 - ETA: 1s - loss: 0.1279 - accuracy: 0.94 - ETA: 1s - loss: 0.1246 - accuracy: 0.94 - ETA: 1s - loss: 0.1190 - accuracy: 0.95 - ETA: 1s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - 1s 140us/step - loss: 0.1121 - accuracy: 0.9535 - val_loss: 0.0713 - val_accuracy: 0.9804\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0874 - accuracy: 0.97 - ETA: 1s - loss: 0.0990 - accuracy: 0.96 - ETA: 1s - loss: 0.0984 - accuracy: 0.95 - ETA: 1s - loss: 0.1058 - accuracy: 0.95 - ETA: 1s - loss: 0.1057 - accuracy: 0.95 - ETA: 1s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - 1s 142us/step - loss: 0.1111 - accuracy: 0.9540 - val_loss: 0.0740 - val_accuracy: 0.9700\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0984 - accuracy: 0.96 - ETA: 1s - loss: 0.1138 - accuracy: 0.95 - ETA: 1s - loss: 0.1154 - accuracy: 0.95 - ETA: 1s - loss: 0.1171 - accuracy: 0.95 - ETA: 1s - loss: 0.1240 - accuracy: 0.94 - ETA: 0s - loss: 0.1234 - accuracy: 0.94 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - ETA: 0s - loss: 0.1178 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1177 - accuracy: 0.95 - ETA: 0s - loss: 0.1185 - accuracy: 0.95 - 1s 142us/step - loss: 0.1179 - accuracy: 0.9512 - val_loss: 0.0723 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0954 - accuracy: 0.95 - ETA: 1s - loss: 0.1016 - accuracy: 0.95 - ETA: 1s - loss: 0.1061 - accuracy: 0.95 - ETA: 1s - loss: 0.1139 - accuracy: 0.95 - ETA: 1s - loss: 0.1173 - accuracy: 0.94 - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - ETA: 0s - loss: 0.1201 - accuracy: 0.94 - ETA: 0s - loss: 0.1173 - accuracy: 0.94 - ETA: 0s - loss: 0.1159 - accuracy: 0.94 - ETA: 0s - loss: 0.1156 - accuracy: 0.94 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - 1s 140us/step - loss: 0.1104 - accuracy: 0.9532 - val_loss: 0.0712 - val_accuracy: 0.9757\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0937 - accuracy: 0.95 - ETA: 1s - loss: 0.0939 - accuracy: 0.96 - ETA: 1s - loss: 0.0938 - accuracy: 0.96 - ETA: 1s - loss: 0.1041 - accuracy: 0.95 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - 1s 141us/step - loss: 0.1111 - accuracy: 0.9526 - val_loss: 0.0721 - val_accuracy: 0.9757\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0982 - accuracy: 0.96 - ETA: 1s - loss: 0.0961 - accuracy: 0.96 - ETA: 1s - loss: 0.0956 - accuracy: 0.96 - ETA: 1s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - 1s 135us/step - loss: 0.1072 - accuracy: 0.9553 - val_loss: 0.0756 - val_accuracy: 0.9786\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0850 - accuracy: 0.97 - ETA: 1s - loss: 0.1181 - accuracy: 0.94 - ETA: 1s - loss: 0.1151 - accuracy: 0.94 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - 1s 137us/step - loss: 0.1084 - accuracy: 0.9554 - val_loss: 0.0711 - val_accuracy: 0.9746\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1100 - accuracy: 0.95 - ETA: 1s - loss: 0.0965 - accuracy: 0.95 - ETA: 1s - loss: 0.1046 - accuracy: 0.95 - ETA: 1s - loss: 0.1041 - accuracy: 0.95 - ETA: 1s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - 1s 142us/step - loss: 0.1066 - accuracy: 0.9553 - val_loss: 0.0731 - val_accuracy: 0.9797\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0928 - accuracy: 0.97 - ETA: 1s - loss: 0.1260 - accuracy: 0.95 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1170 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1181 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - ETA: 0s - loss: 0.1173 - accuracy: 0.95 - 1s 134us/step - loss: 0.1169 - accuracy: 0.9509 - val_loss: 0.0697 - val_accuracy: 0.9793\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1124 - accuracy: 0.95 - ETA: 1s - loss: 0.1055 - accuracy: 0.95 - ETA: 1s - loss: 0.0954 - accuracy: 0.96 - ETA: 1s - loss: 0.0993 - accuracy: 0.96 - ETA: 1s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - 1s 139us/step - loss: 0.1086 - accuracy: 0.9562 - val_loss: 0.0684 - val_accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0933 - accuracy: 0.95 - ETA: 1s - loss: 0.1020 - accuracy: 0.95 - ETA: 1s - loss: 0.1045 - accuracy: 0.95 - ETA: 1s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 1s 137us/step - loss: 0.1100 - accuracy: 0.9555 - val_loss: 0.0686 - val_accuracy: 0.9804\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1658 - accuracy: 0.93 - ETA: 1s - loss: 0.1293 - accuracy: 0.94 - ETA: 1s - loss: 0.1181 - accuracy: 0.95 - ETA: 1s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - 1s 143us/step - loss: 0.1083 - accuracy: 0.9559 - val_loss: 0.0701 - val_accuracy: 0.9756\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1128 - accuracy: 0.94 - ETA: 1s - loss: 0.1106 - accuracy: 0.95 - ETA: 1s - loss: 0.1162 - accuracy: 0.94 - ETA: 1s - loss: 0.1131 - accuracy: 0.95 - ETA: 1s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - 1s 142us/step - loss: 0.1055 - accuracy: 0.9566 - val_loss: 0.0706 - val_accuracy: 0.9771\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1519 - accuracy: 0.92 - ETA: 1s - loss: 0.1089 - accuracy: 0.95 - ETA: 1s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - 1s 138us/step - loss: 0.1051 - accuracy: 0.9563 - val_loss: 0.0710 - val_accuracy: 0.9734\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2093 - accuracy: 0.90 - ETA: 1s - loss: 0.1178 - accuracy: 0.94 - ETA: 1s - loss: 0.1110 - accuracy: 0.95 - ETA: 1s - loss: 0.1083 - accuracy: 0.95 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 1s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - 1s 142us/step - loss: 0.1081 - accuracy: 0.9558 - val_loss: 0.0683 - val_accuracy: 0.9776\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0825 - accuracy: 0.96 - ETA: 1s - loss: 0.0832 - accuracy: 0.96 - ETA: 1s - loss: 0.0867 - accuracy: 0.96 - ETA: 1s - loss: 0.0883 - accuracy: 0.96 - ETA: 1s - loss: 0.0944 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.96 - ETA: 0s - loss: 0.0998 - accuracy: 0.96 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - 1s 140us/step - loss: 0.1091 - accuracy: 0.9551 - val_loss: 0.0678 - val_accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0923 - accuracy: 0.97 - ETA: 1s - loss: 0.1041 - accuracy: 0.95 - ETA: 1s - loss: 0.1125 - accuracy: 0.95 - ETA: 1s - loss: 0.1065 - accuracy: 0.95 - ETA: 1s - loss: 0.1051 - accuracy: 0.95 - ETA: 1s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - 1s 139us/step - loss: 0.1077 - accuracy: 0.9564 - val_loss: 0.0678 - val_accuracy: 0.9798\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0910 - accuracy: 0.95 - ETA: 1s - loss: 0.1001 - accuracy: 0.95 - ETA: 1s - loss: 0.1036 - accuracy: 0.95 - ETA: 1s - loss: 0.1048 - accuracy: 0.95 - ETA: 1s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - 1s 139us/step - loss: 0.1066 - accuracy: 0.9561 - val_loss: 0.0682 - val_accuracy: 0.9776\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1232 - accuracy: 0.94 - ETA: 1s - loss: 0.1142 - accuracy: 0.94 - ETA: 1s - loss: 0.1067 - accuracy: 0.95 - ETA: 1s - loss: 0.1095 - accuracy: 0.95 - ETA: 1s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1137 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - 1s 141us/step - loss: 0.1107 - accuracy: 0.9542 - val_loss: 0.0685 - val_accuracy: 0.9812\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1071 - accuracy: 0.95 - ETA: 1s - loss: 0.1168 - accuracy: 0.95 - ETA: 1s - loss: 0.1208 - accuracy: 0.94 - ETA: 1s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1209 - accuracy: 0.94 - ETA: 0s - loss: 0.1163 - accuracy: 0.94 - ETA: 0s - loss: 0.1185 - accuracy: 0.94 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - 1s 142us/step - loss: 0.1102 - accuracy: 0.9542 - val_loss: 0.0682 - val_accuracy: 0.9765\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1107 - accuracy: 0.96 - ETA: 1s - loss: 0.0982 - accuracy: 0.96 - ETA: 1s - loss: 0.0975 - accuracy: 0.95 - ETA: 1s - loss: 0.0948 - accuracy: 0.96 - ETA: 1s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - 1s 142us/step - loss: 0.1142 - accuracy: 0.9524 - val_loss: 0.0714 - val_accuracy: 0.9719\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1309 - accuracy: 0.94 - ETA: 1s - loss: 0.1164 - accuracy: 0.95 - ETA: 1s - loss: 0.1262 - accuracy: 0.94 - ETA: 1s - loss: 0.1228 - accuracy: 0.94 - ETA: 1s - loss: 0.1199 - accuracy: 0.94 - ETA: 1s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1146 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - 1s 142us/step - loss: 0.1108 - accuracy: 0.9546 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0740 - accuracy: 0.96 - ETA: 1s - loss: 0.0977 - accuracy: 0.96 - ETA: 1s - loss: 0.1097 - accuracy: 0.95 - ETA: 1s - loss: 0.1209 - accuracy: 0.95 - ETA: 1s - loss: 0.1130 - accuracy: 0.95 - ETA: 1s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1157 - accuracy: 0.95 - ETA: 0s - loss: 0.1155 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1145 - accuracy: 0.95 - ETA: 0s - loss: 0.1139 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 1s 143us/step - loss: 0.1094 - accuracy: 0.9540 - val_loss: 0.0687 - val_accuracy: 0.9800\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0922 - accuracy: 0.96 - ETA: 1s - loss: 0.0916 - accuracy: 0.96 - ETA: 1s - loss: 0.1014 - accuracy: 0.95 - ETA: 1s - loss: 0.1061 - accuracy: 0.95 - ETA: 1s - loss: 0.1117 - accuracy: 0.95 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 1s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - 2s 147us/step - loss: 0.1111 - accuracy: 0.9553 - val_loss: 0.0687 - val_accuracy: 0.9769\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0996 - accuracy: 0.96 - ETA: 1s - loss: 0.1211 - accuracy: 0.94 - ETA: 1s - loss: 0.1197 - accuracy: 0.94 - ETA: 1s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - 1s 138us/step - loss: 0.1064 - accuracy: 0.9558 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1148 - accuracy: 0.93 - ETA: 1s - loss: 0.0952 - accuracy: 0.95 - ETA: 1s - loss: 0.1024 - accuracy: 0.95 - ETA: 1s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - 1s 138us/step - loss: 0.1074 - accuracy: 0.9558 - val_loss: 0.0852 - val_accuracy: 0.9610\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1061 - accuracy: 0.96 - ETA: 1s - loss: 0.1116 - accuracy: 0.95 - ETA: 1s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - 1s 138us/step - loss: 0.1076 - accuracy: 0.9550 - val_loss: 0.0673 - val_accuracy: 0.9810\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1317 - accuracy: 0.94 - ETA: 1s - loss: 0.1348 - accuracy: 0.93 - ETA: 1s - loss: 0.1216 - accuracy: 0.94 - ETA: 1s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - 1s 138us/step - loss: 0.1087 - accuracy: 0.9546 - val_loss: 0.0676 - val_accuracy: 0.9818\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1224 - accuracy: 0.96 - ETA: 1s - loss: 0.1061 - accuracy: 0.95 - ETA: 1s - loss: 0.1009 - accuracy: 0.95 - ETA: 1s - loss: 0.0988 - accuracy: 0.95 - ETA: 1s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0975 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.95 - ETA: 0s - loss: 0.0974 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - 1s 135us/step - loss: 0.1019 - accuracy: 0.9581 - val_loss: 0.0663 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0863 - accuracy: 0.95 - ETA: 1s - loss: 0.0910 - accuracy: 0.96 - ETA: 1s - loss: 0.0951 - accuracy: 0.96 - ETA: 1s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - 1s 138us/step - loss: 0.1106 - accuracy: 0.9543 - val_loss: 0.0659 - val_accuracy: 0.9811\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1004 - accuracy: 0.95 - ETA: 1s - loss: 0.1110 - accuracy: 0.95 - ETA: 1s - loss: 0.1143 - accuracy: 0.95 - ETA: 1s - loss: 0.1159 - accuracy: 0.94 - ETA: 1s - loss: 0.1150 - accuracy: 0.94 - ETA: 0s - loss: 0.1171 - accuracy: 0.94 - ETA: 0s - loss: 0.1145 - accuracy: 0.94 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - 1s 139us/step - loss: 0.1075 - accuracy: 0.9544 - val_loss: 0.0690 - val_accuracy: 0.9761\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1098 - accuracy: 0.95 - ETA: 1s - loss: 0.1006 - accuracy: 0.95 - ETA: 1s - loss: 0.1066 - accuracy: 0.95 - ETA: 1s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1169 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - 1s 139us/step - loss: 0.1048 - accuracy: 0.9573 - val_loss: 0.0673 - val_accuracy: 0.9824\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 122us/step\n",
            "\n",
            "Accuracy on test data: 0.99\n",
            "\n",
            "Loss on test data: 0.06\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       123\n",
            "           1       0.99      1.00      1.00       146\n",
            "           2       0.99      0.96      0.98       392\n",
            "           3       0.98      0.94      0.96       309\n",
            "           4       0.95      0.99      0.97       450\n",
            "\n",
            "    accuracy                           0.98      1420\n",
            "   macro avg       0.98      0.98      0.98      1420\n",
            "weighted avg       0.98      0.98      0.98      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     3     4 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [    1     2    13 ... 14161 14170 14172]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1194 - accuracy: 0.95 - ETA: 1s - loss: 0.1032 - accuracy: 0.96 - ETA: 1s - loss: 0.0990 - accuracy: 0.96 - ETA: 1s - loss: 0.0991 - accuracy: 0.96 - ETA: 1s - loss: 0.0994 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - 1s 138us/step - loss: 0.1116 - accuracy: 0.9537 - val_loss: 0.0644 - val_accuracy: 0.9827\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1053 - accuracy: 0.94 - ETA: 1s - loss: 0.1086 - accuracy: 0.95 - ETA: 1s - loss: 0.1088 - accuracy: 0.95 - ETA: 1s - loss: 0.1177 - accuracy: 0.95 - ETA: 1s - loss: 0.1120 - accuracy: 0.95 - ETA: 1s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - 1s 144us/step - loss: 0.1067 - accuracy: 0.9568 - val_loss: 0.0699 - val_accuracy: 0.9721\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0759 - accuracy: 0.97 - ETA: 1s - loss: 0.1234 - accuracy: 0.95 - ETA: 1s - loss: 0.1262 - accuracy: 0.94 - ETA: 1s - loss: 0.1221 - accuracy: 0.94 - ETA: 1s - loss: 0.1190 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1153 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - 1s 140us/step - loss: 0.1103 - accuracy: 0.9555 - val_loss: 0.0629 - val_accuracy: 0.9825\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0839 - accuracy: 0.96 - ETA: 1s - loss: 0.1215 - accuracy: 0.94 - ETA: 1s - loss: 0.1074 - accuracy: 0.95 - ETA: 1s - loss: 0.1134 - accuracy: 0.95 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1070 - accuracy: 0.95 - ETA: 1s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - 1s 143us/step - loss: 0.1075 - accuracy: 0.9557 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0868 - accuracy: 0.96 - ETA: 1s - loss: 0.0946 - accuracy: 0.96 - ETA: 1s - loss: 0.1015 - accuracy: 0.95 - ETA: 1s - loss: 0.0978 - accuracy: 0.96 - ETA: 1s - loss: 0.0990 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - 1s 137us/step - loss: 0.1055 - accuracy: 0.9566 - val_loss: 0.0650 - val_accuracy: 0.9798\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0764 - accuracy: 0.97 - ETA: 1s - loss: 0.0961 - accuracy: 0.96 - ETA: 1s - loss: 0.1031 - accuracy: 0.95 - ETA: 1s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - 1s 142us/step - loss: 0.1066 - accuracy: 0.9557 - val_loss: 0.0646 - val_accuracy: 0.9832\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0941 - accuracy: 0.95 - ETA: 1s - loss: 0.1105 - accuracy: 0.95 - ETA: 1s - loss: 0.1178 - accuracy: 0.95 - ETA: 1s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - 1s 144us/step - loss: 0.1073 - accuracy: 0.9552 - val_loss: 0.0701 - val_accuracy: 0.9730\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1558 - accuracy: 0.93 - ETA: 1s - loss: 0.1171 - accuracy: 0.95 - ETA: 1s - loss: 0.1058 - accuracy: 0.95 - ETA: 1s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.0969 - accuracy: 0.96 - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - 1s 137us/step - loss: 0.1081 - accuracy: 0.9553 - val_loss: 0.0621 - val_accuracy: 0.9827\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0804 - accuracy: 0.97 - ETA: 1s - loss: 0.0918 - accuracy: 0.96 - ETA: 1s - loss: 0.0931 - accuracy: 0.96 - ETA: 1s - loss: 0.0977 - accuracy: 0.96 - ETA: 1s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0977 - accuracy: 0.96 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - ETA: 0s - loss: 0.0992 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - 1s 141us/step - loss: 0.1062 - accuracy: 0.9566 - val_loss: 0.0626 - val_accuracy: 0.9815\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0751 - accuracy: 0.97 - ETA: 1s - loss: 0.0938 - accuracy: 0.96 - ETA: 1s - loss: 0.0943 - accuracy: 0.96 - ETA: 1s - loss: 0.0944 - accuracy: 0.96 - ETA: 1s - loss: 0.0925 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.95 - ETA: 0s - loss: 0.0968 - accuracy: 0.95 - ETA: 0s - loss: 0.0988 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - ETA: 0s - loss: 0.0978 - accuracy: 0.95 - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - ETA: 0s - loss: 0.0978 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - 1s 146us/step - loss: 0.0989 - accuracy: 0.9588 - val_loss: 0.0645 - val_accuracy: 0.9830\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1032 - accuracy: 0.95 - ETA: 1s - loss: 0.1223 - accuracy: 0.94 - ETA: 1s - loss: 0.1074 - accuracy: 0.95 - ETA: 1s - loss: 0.1054 - accuracy: 0.95 - ETA: 1s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - 1s 143us/step - loss: 0.1103 - accuracy: 0.9538 - val_loss: 0.0648 - val_accuracy: 0.9772\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1113 - accuracy: 0.94 - ETA: 1s - loss: 0.1059 - accuracy: 0.95 - ETA: 1s - loss: 0.1088 - accuracy: 0.95 - ETA: 1s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - 1s 138us/step - loss: 0.1082 - accuracy: 0.9565 - val_loss: 0.0718 - val_accuracy: 0.9682\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0880 - accuracy: 0.96 - ETA: 1s - loss: 0.1045 - accuracy: 0.95 - ETA: 1s - loss: 0.0981 - accuracy: 0.96 - ETA: 1s - loss: 0.0988 - accuracy: 0.96 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - 2s 147us/step - loss: 0.1080 - accuracy: 0.9562 - val_loss: 0.0648 - val_accuracy: 0.9772\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1051 - accuracy: 0.95 - ETA: 1s - loss: 0.1325 - accuracy: 0.94 - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1171 - accuracy: 0.95 - ETA: 1s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1204 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1164 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1135 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 1s 146us/step - loss: 0.1108 - accuracy: 0.9557 - val_loss: 0.0634 - val_accuracy: 0.9779\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0838 - accuracy: 0.96 - ETA: 1s - loss: 0.0995 - accuracy: 0.96 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 1s - loss: 0.1158 - accuracy: 0.95 - ETA: 1s - loss: 0.1243 - accuracy: 0.94 - ETA: 1s - loss: 0.1188 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - 1s 144us/step - loss: 0.1068 - accuracy: 0.9573 - val_loss: 0.0646 - val_accuracy: 0.9772\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0798 - accuracy: 0.96 - ETA: 1s - loss: 0.1071 - accuracy: 0.95 - ETA: 1s - loss: 0.1047 - accuracy: 0.95 - ETA: 1s - loss: 0.1089 - accuracy: 0.95 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1047 - accuracy: 0.95 - ETA: 1s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - 2s 147us/step - loss: 0.1032 - accuracy: 0.9572 - val_loss: 0.0626 - val_accuracy: 0.9811\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1075 - accuracy: 0.95 - ETA: 1s - loss: 0.0913 - accuracy: 0.96 - ETA: 1s - loss: 0.0933 - accuracy: 0.96 - ETA: 1s - loss: 0.1003 - accuracy: 0.95 - ETA: 1s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - 2s 163us/step - loss: 0.1047 - accuracy: 0.9571 - val_loss: 0.0614 - val_accuracy: 0.9832\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0793 - accuracy: 0.96 - ETA: 1s - loss: 0.0819 - accuracy: 0.96 - ETA: 1s - loss: 0.0952 - accuracy: 0.96 - ETA: 1s - loss: 0.1071 - accuracy: 0.95 - ETA: 1s - loss: 0.1032 - accuracy: 0.95 - ETA: 1s - loss: 0.1015 - accuracy: 0.95 - ETA: 1s - loss: 0.0999 - accuracy: 0.95 - ETA: 1s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - 1s 144us/step - loss: 0.1044 - accuracy: 0.9570 - val_loss: 0.0615 - val_accuracy: 0.9826\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0923 - accuracy: 0.96 - ETA: 1s - loss: 0.1119 - accuracy: 0.95 - ETA: 1s - loss: 0.1046 - accuracy: 0.95 - ETA: 1s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 1s 137us/step - loss: 0.1099 - accuracy: 0.9544 - val_loss: 0.0630 - val_accuracy: 0.9816\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0981 - accuracy: 0.96 - ETA: 1s - loss: 0.1233 - accuracy: 0.94 - ETA: 1s - loss: 0.1163 - accuracy: 0.95 - ETA: 1s - loss: 0.1052 - accuracy: 0.95 - ETA: 1s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - 1s 135us/step - loss: 0.1070 - accuracy: 0.9551 - val_loss: 0.0614 - val_accuracy: 0.9829\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0908 - accuracy: 0.97 - ETA: 1s - loss: 0.1056 - accuracy: 0.95 - ETA: 1s - loss: 0.1046 - accuracy: 0.95 - ETA: 1s - loss: 0.0989 - accuracy: 0.95 - ETA: 1s - loss: 0.1056 - accuracy: 0.95 - ETA: 1s - loss: 0.1167 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1179 - accuracy: 0.95 - ETA: 0s - loss: 0.1230 - accuracy: 0.94 - ETA: 0s - loss: 0.1205 - accuracy: 0.94 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1190 - accuracy: 0.95 - ETA: 0s - loss: 0.1187 - accuracy: 0.95 - ETA: 0s - loss: 0.1175 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1147 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1120 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - 1s 144us/step - loss: 0.1107 - accuracy: 0.9542 - val_loss: 0.0621 - val_accuracy: 0.9804\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0816 - accuracy: 0.96 - ETA: 1s - loss: 0.1023 - accuracy: 0.95 - ETA: 1s - loss: 0.0994 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - 1s 141us/step - loss: 0.1066 - accuracy: 0.9554 - val_loss: 0.0666 - val_accuracy: 0.9744\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0776 - accuracy: 0.97 - ETA: 1s - loss: 0.0969 - accuracy: 0.96 - ETA: 1s - loss: 0.1055 - accuracy: 0.95 - ETA: 1s - loss: 0.1027 - accuracy: 0.95 - ETA: 1s - loss: 0.1021 - accuracy: 0.95 - ETA: 1s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - 1s 142us/step - loss: 0.1078 - accuracy: 0.9558 - val_loss: 0.0768 - val_accuracy: 0.9650\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0814 - accuracy: 0.97 - ETA: 1s - loss: 0.1008 - accuracy: 0.95 - ETA: 1s - loss: 0.1091 - accuracy: 0.95 - ETA: 1s - loss: 0.1017 - accuracy: 0.95 - ETA: 1s - loss: 0.1023 - accuracy: 0.95 - ETA: 1s - loss: 0.1015 - accuracy: 0.95 - ETA: 1s - loss: 0.1029 - accuracy: 0.95 - ETA: 1s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - 1s 146us/step - loss: 0.1026 - accuracy: 0.9574 - val_loss: 0.0638 - val_accuracy: 0.9792\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0861 - accuracy: 0.96 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 1s - loss: 0.1138 - accuracy: 0.95 - ETA: 1s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - 1s 143us/step - loss: 0.1071 - accuracy: 0.9564 - val_loss: 0.0642 - val_accuracy: 0.9760\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1157 - accuracy: 0.93 - ETA: 1s - loss: 0.1045 - accuracy: 0.95 - ETA: 1s - loss: 0.0984 - accuracy: 0.95 - ETA: 1s - loss: 0.1096 - accuracy: 0.95 - ETA: 1s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - 1s 144us/step - loss: 0.1079 - accuracy: 0.9544 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0782 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.95 - ETA: 1s - loss: 0.1077 - accuracy: 0.95 - ETA: 1s - loss: 0.1041 - accuracy: 0.95 - ETA: 1s - loss: 0.1042 - accuracy: 0.95 - ETA: 1s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.0979 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - 1s 137us/step - loss: 0.1023 - accuracy: 0.9580 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.2005 - accuracy: 0.92 - ETA: 1s - loss: 0.1169 - accuracy: 0.95 - ETA: 1s - loss: 0.1151 - accuracy: 0.95 - ETA: 1s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 1s 144us/step - loss: 0.1054 - accuracy: 0.9565 - val_loss: 0.0616 - val_accuracy: 0.9832\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1311 - accuracy: 0.93 - ETA: 1s - loss: 0.1180 - accuracy: 0.95 - ETA: 1s - loss: 0.1102 - accuracy: 0.95 - ETA: 1s - loss: 0.1118 - accuracy: 0.95 - ETA: 1s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - 1s 139us/step - loss: 0.1064 - accuracy: 0.9562 - val_loss: 0.0609 - val_accuracy: 0.9836\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1103 - accuracy: 0.95 - ETA: 1s - loss: 0.0860 - accuracy: 0.96 - ETA: 1s - loss: 0.1028 - accuracy: 0.95 - ETA: 1s - loss: 0.0970 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.0968 - accuracy: 0.95 - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0968 - accuracy: 0.95 - ETA: 0s - loss: 0.0977 - accuracy: 0.95 - ETA: 0s - loss: 0.0967 - accuracy: 0.95 - ETA: 0s - loss: 0.0967 - accuracy: 0.95 - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.0990 - accuracy: 0.95 - ETA: 0s - loss: 0.0990 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - 1s 138us/step - loss: 0.1019 - accuracy: 0.9567 - val_loss: 0.0607 - val_accuracy: 0.9844\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0967 - accuracy: 0.95 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1050 - accuracy: 0.95 - ETA: 1s - loss: 0.1065 - accuracy: 0.95 - ETA: 1s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1134 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - 1s 137us/step - loss: 0.1076 - accuracy: 0.9557 - val_loss: 0.0613 - val_accuracy: 0.9826\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1086 - accuracy: 0.95 - ETA: 1s - loss: 0.0922 - accuracy: 0.96 - ETA: 1s - loss: 0.0950 - accuracy: 0.95 - ETA: 1s - loss: 0.0930 - accuracy: 0.96 - ETA: 1s - loss: 0.0889 - accuracy: 0.96 - ETA: 0s - loss: 0.0938 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0967 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - 1s 142us/step - loss: 0.1012 - accuracy: 0.9577 - val_loss: 0.0702 - val_accuracy: 0.9690\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1620 - accuracy: 0.93 - ETA: 1s - loss: 0.1202 - accuracy: 0.95 - ETA: 1s - loss: 0.1072 - accuracy: 0.95 - ETA: 1s - loss: 0.1056 - accuracy: 0.95 - ETA: 1s - loss: 0.1109 - accuracy: 0.95 - ETA: 1s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1141 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1140 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - 1s 139us/step - loss: 0.1085 - accuracy: 0.9560 - val_loss: 0.0622 - val_accuracy: 0.9809\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1109 - accuracy: 0.96 - ETA: 1s - loss: 0.1246 - accuracy: 0.95 - ETA: 1s - loss: 0.1120 - accuracy: 0.95 - ETA: 1s - loss: 0.1054 - accuracy: 0.96 - ETA: 1s - loss: 0.1135 - accuracy: 0.95 - ETA: 1s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1113 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - 1s 139us/step - loss: 0.1084 - accuracy: 0.9560 - val_loss: 0.0622 - val_accuracy: 0.9795\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0677 - accuracy: 0.97 - ETA: 1s - loss: 0.1011 - accuracy: 0.96 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 1s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - 1s 143us/step - loss: 0.1071 - accuracy: 0.9550 - val_loss: 0.0757 - val_accuracy: 0.9652\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0930 - accuracy: 0.96 - ETA: 1s - loss: 0.1260 - accuracy: 0.95 - ETA: 1s - loss: 0.1068 - accuracy: 0.96 - ETA: 1s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.96 - ETA: 0s - loss: 0.1025 - accuracy: 0.96 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - 1s 144us/step - loss: 0.1089 - accuracy: 0.9550 - val_loss: 0.0705 - val_accuracy: 0.9728\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0943 - accuracy: 0.96 - ETA: 1s - loss: 0.1053 - accuracy: 0.95 - ETA: 1s - loss: 0.0988 - accuracy: 0.96 - ETA: 1s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.0977 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1087 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - 1s 141us/step - loss: 0.1081 - accuracy: 0.9565 - val_loss: 0.0616 - val_accuracy: 0.9828\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1359 - accuracy: 0.94 - ETA: 1s - loss: 0.1088 - accuracy: 0.95 - ETA: 1s - loss: 0.1159 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - 1s 139us/step - loss: 0.1107 - accuracy: 0.9548 - val_loss: 0.0615 - val_accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0860 - accuracy: 0.96 - ETA: 1s - loss: 0.1161 - accuracy: 0.95 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 0s - loss: 0.1149 - accuracy: 0.95 - ETA: 0s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1103 - accuracy: 0.95 - ETA: 0s - loss: 0.1152 - accuracy: 0.95 - ETA: 0s - loss: 0.1163 - accuracy: 0.95 - ETA: 0s - loss: 0.1150 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1100 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1082 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - 1s 137us/step - loss: 0.1074 - accuracy: 0.9555 - val_loss: 0.0605 - val_accuracy: 0.9836\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1050 - accuracy: 0.96 - ETA: 1s - loss: 0.1307 - accuracy: 0.94 - ETA: 1s - loss: 0.1112 - accuracy: 0.95 - ETA: 1s - loss: 0.1146 - accuracy: 0.95 - ETA: 1s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - 1s 138us/step - loss: 0.1045 - accuracy: 0.9582 - val_loss: 0.0646 - val_accuracy: 0.9815\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0822 - accuracy: 0.97 - ETA: 1s - loss: 0.1007 - accuracy: 0.95 - ETA: 1s - loss: 0.0965 - accuracy: 0.96 - ETA: 1s - loss: 0.0966 - accuracy: 0.96 - ETA: 1s - loss: 0.0981 - accuracy: 0.96 - ETA: 1s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.0992 - accuracy: 0.96 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - 1s 143us/step - loss: 0.1073 - accuracy: 0.9564 - val_loss: 0.0624 - val_accuracy: 0.9829\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1034 - accuracy: 0.95 - ETA: 1s - loss: 0.1230 - accuracy: 0.94 - ETA: 1s - loss: 0.1133 - accuracy: 0.95 - ETA: 1s - loss: 0.1177 - accuracy: 0.95 - ETA: 1s - loss: 0.1078 - accuracy: 0.95 - ETA: 1s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - ETA: 0s - loss: 0.1084 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1079 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - 1s 140us/step - loss: 0.1079 - accuracy: 0.9555 - val_loss: 0.0609 - val_accuracy: 0.9834\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1206 - accuracy: 0.95 - ETA: 1s - loss: 0.1073 - accuracy: 0.95 - ETA: 1s - loss: 0.1075 - accuracy: 0.95 - ETA: 1s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - 1s 141us/step - loss: 0.1029 - accuracy: 0.9578 - val_loss: 0.0618 - val_accuracy: 0.9783\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0719 - accuracy: 0.98 - ETA: 1s - loss: 0.0911 - accuracy: 0.96 - ETA: 1s - loss: 0.0931 - accuracy: 0.96 - ETA: 0s - loss: 0.0916 - accuracy: 0.96 - ETA: 0s - loss: 0.0906 - accuracy: 0.96 - ETA: 0s - loss: 0.0913 - accuracy: 0.96 - ETA: 0s - loss: 0.0934 - accuracy: 0.96 - ETA: 0s - loss: 0.0955 - accuracy: 0.96 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - 1s 136us/step - loss: 0.1020 - accuracy: 0.9586 - val_loss: 0.0623 - val_accuracy: 0.9789\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1639 - accuracy: 0.93 - ETA: 1s - loss: 0.1206 - accuracy: 0.94 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 1s - loss: 0.1057 - accuracy: 0.95 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - 1s 143us/step - loss: 0.1025 - accuracy: 0.9588 - val_loss: 0.0614 - val_accuracy: 0.9783\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1730 - accuracy: 0.93 - ETA: 1s - loss: 0.1232 - accuracy: 0.95 - ETA: 1s - loss: 0.1058 - accuracy: 0.96 - ETA: 1s - loss: 0.1052 - accuracy: 0.95 - ETA: 1s - loss: 0.1012 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1111 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1119 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1114 - accuracy: 0.95 - ETA: 0s - loss: 0.1130 - accuracy: 0.95 - ETA: 0s - loss: 0.1128 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - 2s 150us/step - loss: 0.1109 - accuracy: 0.9535 - val_loss: 0.0650 - val_accuracy: 0.9750\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0835 - accuracy: 0.97 - ETA: 1s - loss: 0.0935 - accuracy: 0.96 - ETA: 1s - loss: 0.1121 - accuracy: 0.95 - ETA: 1s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1051 - accuracy: 0.95 - 1s 135us/step - loss: 0.1053 - accuracy: 0.9576 - val_loss: 0.0599 - val_accuracy: 0.9829\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0746 - accuracy: 0.96 - ETA: 1s - loss: 0.0979 - accuracy: 0.96 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 1s - loss: 0.1008 - accuracy: 0.95 - ETA: 1s - loss: 0.0984 - accuracy: 0.96 - ETA: 1s - loss: 0.1004 - accuracy: 0.96 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - 1s 140us/step - loss: 0.1056 - accuracy: 0.9570 - val_loss: 0.0607 - val_accuracy: 0.9817\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1285 - accuracy: 0.94 - ETA: 1s - loss: 0.0939 - accuracy: 0.96 - ETA: 1s - loss: 0.0935 - accuracy: 0.96 - ETA: 1s - loss: 0.0922 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - 1s 140us/step - loss: 0.1011 - accuracy: 0.9590 - val_loss: 0.0591 - val_accuracy: 0.9833\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1292 - accuracy: 0.94 - ETA: 1s - loss: 0.1044 - accuracy: 0.95 - ETA: 1s - loss: 0.1014 - accuracy: 0.95 - ETA: 1s - loss: 0.0934 - accuracy: 0.96 - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - ETA: 0s - loss: 0.0930 - accuracy: 0.96 - ETA: 0s - loss: 0.0976 - accuracy: 0.95 - ETA: 0s - loss: 0.0984 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 1s 138us/step - loss: 0.1046 - accuracy: 0.9569 - val_loss: 0.0620 - val_accuracy: 0.9787\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 132us/step\n",
            "\n",
            "Accuracy on test data: 0.98\n",
            "\n",
            "Loss on test data: 0.06\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       105\n",
            "           1       1.00      0.99      0.99       155\n",
            "           2       0.99      0.94      0.96       456\n",
            "           3       0.93      0.92      0.93       298\n",
            "           4       0.93      1.00      0.96       406\n",
            "\n",
            "    accuracy                           0.96      1420\n",
            "   macro avg       0.97      0.97      0.97      1420\n",
            "weighted avg       0.96      0.96      0.96      1420\n",
            "\n",
            "finished\n",
            "Train Index:  [    0     1     2 ... 14197 14198 14199] \n",
            "\n",
            "Test Index:  [   16    27    30 ... 14148 14182 14195]\n",
            "\n",
            "--- Fit the model ---\n",
            "\n",
            "Train on 10224 samples, validate on 2556 samples\n",
            "Epoch 1/50\n",
            "10224/10224 [==============================] - ETA: 2s - loss: 0.0765 - accuracy: 0.96 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 1s - loss: 0.0961 - accuracy: 0.95 - ETA: 1s - loss: 0.1031 - accuracy: 0.95 - ETA: 1s - loss: 0.1020 - accuracy: 0.95 - ETA: 1s - loss: 0.0999 - accuracy: 0.95 - ETA: 1s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1065 - accuracy: 0.95 - ETA: 0s - loss: 0.1060 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - 1s 144us/step - loss: 0.1072 - accuracy: 0.9551 - val_loss: 0.0600 - val_accuracy: 0.9818\n",
            "Epoch 2/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0964 - accuracy: 0.95 - ETA: 1s - loss: 0.1020 - accuracy: 0.95 - ETA: 1s - loss: 0.0973 - accuracy: 0.95 - ETA: 1s - loss: 0.0980 - accuracy: 0.95 - ETA: 1s - loss: 0.0984 - accuracy: 0.95 - ETA: 0s - loss: 0.0975 - accuracy: 0.95 - ETA: 0s - loss: 0.0950 - accuracy: 0.96 - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - 1s 139us/step - loss: 0.1038 - accuracy: 0.9569 - val_loss: 0.0607 - val_accuracy: 0.9826\n",
            "Epoch 3/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1299 - accuracy: 0.93 - ETA: 1s - loss: 0.1044 - accuracy: 0.95 - ETA: 1s - loss: 0.1129 - accuracy: 0.95 - ETA: 1s - loss: 0.1117 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - 1s 139us/step - loss: 0.1018 - accuracy: 0.9588 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
            "Epoch 4/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1028 - accuracy: 0.96 - ETA: 1s - loss: 0.1052 - accuracy: 0.95 - ETA: 1s - loss: 0.1097 - accuracy: 0.95 - ETA: 1s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1122 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - 1s 138us/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 0.0592 - val_accuracy: 0.9841\n",
            "Epoch 5/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0759 - accuracy: 0.97 - ETA: 1s - loss: 0.0833 - accuracy: 0.96 - ETA: 1s - loss: 0.0866 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.0973 - accuracy: 0.95 - ETA: 0s - loss: 0.0975 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - 1s 140us/step - loss: 0.1017 - accuracy: 0.9579 - val_loss: 0.0598 - val_accuracy: 0.9828\n",
            "Epoch 6/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0985 - accuracy: 0.95 - ETA: 1s - loss: 0.0928 - accuracy: 0.96 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0949 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - 1s 140us/step - loss: 0.1005 - accuracy: 0.9589 - val_loss: 0.0602 - val_accuracy: 0.9830\n",
            "Epoch 7/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0781 - accuracy: 0.97 - ETA: 1s - loss: 0.1002 - accuracy: 0.96 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 1s - loss: 0.1124 - accuracy: 0.95 - ETA: 1s - loss: 0.1074 - accuracy: 0.95 - ETA: 1s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - 1s 139us/step - loss: 0.1030 - accuracy: 0.9578 - val_loss: 0.0602 - val_accuracy: 0.9818\n",
            "Epoch 8/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1423 - accuracy: 0.93 - ETA: 1s - loss: 0.1126 - accuracy: 0.95 - ETA: 1s - loss: 0.1088 - accuracy: 0.95 - ETA: 1s - loss: 0.1045 - accuracy: 0.95 - ETA: 1s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - ETA: 0s - loss: 0.0974 - accuracy: 0.95 - ETA: 0s - loss: 0.0956 - accuracy: 0.96 - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0955 - accuracy: 0.96 - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - 1s 140us/step - loss: 0.0991 - accuracy: 0.9597 - val_loss: 0.0594 - val_accuracy: 0.9816\n",
            "Epoch 9/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0783 - accuracy: 0.97 - ETA: 1s - loss: 0.1058 - accuracy: 0.95 - ETA: 1s - loss: 0.1010 - accuracy: 0.95 - ETA: 1s - loss: 0.1023 - accuracy: 0.95 - ETA: 1s - loss: 0.1020 - accuracy: 0.95 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0967 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.0975 - accuracy: 0.95 - ETA: 0s - loss: 0.0988 - accuracy: 0.95 - 1s 142us/step - loss: 0.0990 - accuracy: 0.9590 - val_loss: 0.0585 - val_accuracy: 0.9846\n",
            "Epoch 10/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0872 - accuracy: 0.97 - ETA: 1s - loss: 0.0955 - accuracy: 0.95 - ETA: 1s - loss: 0.0963 - accuracy: 0.96 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - 1s 137us/step - loss: 0.1060 - accuracy: 0.9554 - val_loss: 0.0599 - val_accuracy: 0.9820\n",
            "Epoch 11/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1300 - accuracy: 0.93 - ETA: 1s - loss: 0.0991 - accuracy: 0.95 - ETA: 1s - loss: 0.1006 - accuracy: 0.95 - ETA: 1s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.0974 - accuracy: 0.95 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.0979 - accuracy: 0.95 - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - 1s 144us/step - loss: 0.1041 - accuracy: 0.9570 - val_loss: 0.0608 - val_accuracy: 0.9831\n",
            "Epoch 12/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1067 - accuracy: 0.95 - ETA: 1s - loss: 0.0996 - accuracy: 0.95 - ETA: 1s - loss: 0.0988 - accuracy: 0.95 - ETA: 1s - loss: 0.1148 - accuracy: 0.95 - ETA: 1s - loss: 0.1160 - accuracy: 0.95 - ETA: 1s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - 1s 141us/step - loss: 0.1037 - accuracy: 0.9576 - val_loss: 0.0621 - val_accuracy: 0.9777\n",
            "Epoch 13/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1494 - accuracy: 0.94 - ETA: 1s - loss: 0.1220 - accuracy: 0.95 - ETA: 1s - loss: 0.1063 - accuracy: 0.95 - ETA: 1s - loss: 0.1114 - accuracy: 0.95 - ETA: 1s - loss: 0.1168 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1154 - accuracy: 0.95 - ETA: 0s - loss: 0.1143 - accuracy: 0.95 - ETA: 0s - loss: 0.1123 - accuracy: 0.95 - ETA: 0s - loss: 0.1131 - accuracy: 0.95 - ETA: 0s - loss: 0.1121 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1115 - accuracy: 0.95 - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1099 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1098 - accuracy: 0.95 - 1s 137us/step - loss: 0.1094 - accuracy: 0.9550 - val_loss: 0.0616 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1188 - accuracy: 0.96 - ETA: 1s - loss: 0.1016 - accuracy: 0.96 - ETA: 1s - loss: 0.1119 - accuracy: 0.95 - ETA: 1s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1059 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1080 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - 1s 143us/step - loss: 0.1082 - accuracy: 0.9551 - val_loss: 0.0620 - val_accuracy: 0.9791\n",
            "Epoch 15/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1108 - accuracy: 0.94 - ETA: 1s - loss: 0.0960 - accuracy: 0.95 - ETA: 1s - loss: 0.1062 - accuracy: 0.95 - ETA: 1s - loss: 0.1099 - accuracy: 0.95 - ETA: 1s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1116 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1085 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - 1s 143us/step - loss: 0.1037 - accuracy: 0.9566 - val_loss: 0.0609 - val_accuracy: 0.9786\n",
            "Epoch 16/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1348 - accuracy: 0.94 - ETA: 1s - loss: 0.1012 - accuracy: 0.95 - ETA: 1s - loss: 0.0999 - accuracy: 0.95 - ETA: 1s - loss: 0.0944 - accuracy: 0.96 - ETA: 1s - loss: 0.0976 - accuracy: 0.96 - ETA: 1s - loss: 0.0976 - accuracy: 0.96 - ETA: 1s - loss: 0.0969 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - 1s 142us/step - loss: 0.1020 - accuracy: 0.9584 - val_loss: 0.0585 - val_accuracy: 0.9831\n",
            "Epoch 17/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0745 - accuracy: 0.97 - ETA: 1s - loss: 0.0949 - accuracy: 0.96 - ETA: 1s - loss: 0.1005 - accuracy: 0.95 - ETA: 1s - loss: 0.0996 - accuracy: 0.95 - ETA: 1s - loss: 0.0992 - accuracy: 0.95 - ETA: 1s - loss: 0.1019 - accuracy: 0.95 - ETA: 1s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - 1s 143us/step - loss: 0.1026 - accuracy: 0.9577 - val_loss: 0.0584 - val_accuracy: 0.9829\n",
            "Epoch 18/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1514 - accuracy: 0.93 - ETA: 1s - loss: 0.0969 - accuracy: 0.96 - ETA: 1s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0998 - accuracy: 0.96 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0992 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - 1s 141us/step - loss: 0.1008 - accuracy: 0.9593 - val_loss: 0.0615 - val_accuracy: 0.9790\n",
            "Epoch 19/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1189 - accuracy: 0.94 - ETA: 1s - loss: 0.0979 - accuracy: 0.95 - ETA: 1s - loss: 0.1040 - accuracy: 0.95 - ETA: 1s - loss: 0.1034 - accuracy: 0.95 - ETA: 1s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - ETA: 0s - loss: 0.0955 - accuracy: 0.96 - ETA: 0s - loss: 0.0990 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - 1s 142us/step - loss: 0.1030 - accuracy: 0.9579 - val_loss: 0.0612 - val_accuracy: 0.9768\n",
            "Epoch 20/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0823 - accuracy: 0.96 - ETA: 1s - loss: 0.1184 - accuracy: 0.95 - ETA: 1s - loss: 0.1072 - accuracy: 0.95 - ETA: 1s - loss: 0.1103 - accuracy: 0.95 - ETA: 1s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1136 - accuracy: 0.95 - ETA: 0s - loss: 0.1107 - accuracy: 0.95 - ETA: 0s - loss: 0.1124 - accuracy: 0.95 - ETA: 0s - loss: 0.1101 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1097 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1092 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1095 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - 1s 137us/step - loss: 0.1097 - accuracy: 0.9549 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
            "Epoch 21/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1226 - accuracy: 0.95 - ETA: 1s - loss: 0.1033 - accuracy: 0.95 - ETA: 1s - loss: 0.1049 - accuracy: 0.95 - ETA: 1s - loss: 0.1007 - accuracy: 0.95 - ETA: 1s - loss: 0.1027 - accuracy: 0.95 - ETA: 1s - loss: 0.1009 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0979 - accuracy: 0.96 - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - 1s 140us/step - loss: 0.0987 - accuracy: 0.9600 - val_loss: 0.0593 - val_accuracy: 0.9802\n",
            "Epoch 22/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0941 - accuracy: 0.95 - ETA: 1s - loss: 0.1180 - accuracy: 0.95 - ETA: 1s - loss: 0.1160 - accuracy: 0.95 - ETA: 1s - loss: 0.1155 - accuracy: 0.94 - ETA: 1s - loss: 0.1142 - accuracy: 0.95 - ETA: 1s - loss: 0.1078 - accuracy: 0.95 - ETA: 0s - loss: 0.1109 - accuracy: 0.95 - ETA: 0s - loss: 0.1125 - accuracy: 0.95 - ETA: 0s - loss: 0.1110 - accuracy: 0.95 - ETA: 0s - loss: 0.1096 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1073 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1066 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - 1s 140us/step - loss: 0.1018 - accuracy: 0.9579 - val_loss: 0.0592 - val_accuracy: 0.9829\n",
            "Epoch 23/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0623 - accuracy: 0.97 - ETA: 1s - loss: 0.0830 - accuracy: 0.96 - ETA: 1s - loss: 0.0990 - accuracy: 0.95 - ETA: 1s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0973 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - ETA: 0s - loss: 0.0973 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0992 - accuracy: 0.96 - ETA: 0s - loss: 0.0992 - accuracy: 0.96 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - 1s 139us/step - loss: 0.0991 - accuracy: 0.9596 - val_loss: 0.0589 - val_accuracy: 0.9819\n",
            "Epoch 24/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1253 - accuracy: 0.95 - ETA: 1s - loss: 0.1069 - accuracy: 0.95 - ETA: 1s - loss: 0.1078 - accuracy: 0.95 - ETA: 1s - loss: 0.1094 - accuracy: 0.95 - ETA: 1s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - 1s 141us/step - loss: 0.1029 - accuracy: 0.9578 - val_loss: 0.0591 - val_accuracy: 0.9833\n",
            "Epoch 25/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1136 - accuracy: 0.94 - ETA: 1s - loss: 0.1087 - accuracy: 0.95 - ETA: 1s - loss: 0.1010 - accuracy: 0.95 - ETA: 1s - loss: 0.1027 - accuracy: 0.95 - ETA: 1s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.96 - ETA: 0s - loss: 0.1012 - accuracy: 0.96 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1012 - accuracy: 0.95 - 1s 141us/step - loss: 0.1019 - accuracy: 0.9588 - val_loss: 0.0574 - val_accuracy: 0.9833\n",
            "Epoch 26/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1025 - accuracy: 0.95 - ETA: 1s - loss: 0.0912 - accuracy: 0.96 - ETA: 1s - loss: 0.0898 - accuracy: 0.96 - ETA: 1s - loss: 0.0927 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0930 - accuracy: 0.96 - ETA: 0s - loss: 0.0957 - accuracy: 0.96 - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0923 - accuracy: 0.96 - ETA: 0s - loss: 0.0925 - accuracy: 0.96 - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - ETA: 0s - loss: 0.0932 - accuracy: 0.96 - ETA: 0s - loss: 0.0922 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - ETA: 0s - loss: 0.0967 - accuracy: 0.96 - 1s 139us/step - loss: 0.0970 - accuracy: 0.9603 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1161 - accuracy: 0.95 - ETA: 1s - loss: 0.1129 - accuracy: 0.95 - ETA: 1s - loss: 0.1086 - accuracy: 0.95 - ETA: 1s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0924 - accuracy: 0.96 - ETA: 0s - loss: 0.0926 - accuracy: 0.96 - ETA: 0s - loss: 0.0932 - accuracy: 0.96 - ETA: 0s - loss: 0.0946 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - ETA: 0s - loss: 0.0979 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.0974 - accuracy: 0.96 - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - ETA: 0s - loss: 0.0963 - accuracy: 0.96 - 1s 137us/step - loss: 0.0963 - accuracy: 0.9610 - val_loss: 0.0586 - val_accuracy: 0.9805\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1123 - accuracy: 0.95 - ETA: 1s - loss: 0.1111 - accuracy: 0.95 - ETA: 1s - loss: 0.1153 - accuracy: 0.95 - ETA: 1s - loss: 0.1160 - accuracy: 0.95 - ETA: 1s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1089 - accuracy: 0.95 - ETA: 0s - loss: 0.1071 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1106 - accuracy: 0.95 - ETA: 0s - loss: 0.1094 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1076 - accuracy: 0.95 - ETA: 0s - loss: 0.1063 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1052 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 1s 139us/step - loss: 0.1049 - accuracy: 0.9570 - val_loss: 0.0579 - val_accuracy: 0.9829\n",
            "Epoch 29/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1095 - accuracy: 0.95 - ETA: 1s - loss: 0.0972 - accuracy: 0.96 - ETA: 1s - loss: 0.0949 - accuracy: 0.96 - ETA: 1s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0962 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0948 - accuracy: 0.96 - ETA: 0s - loss: 0.0926 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0952 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.0982 - accuracy: 0.95 - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - 1s 137us/step - loss: 0.1000 - accuracy: 0.9593 - val_loss: 0.0693 - val_accuracy: 0.9710\n",
            "Epoch 30/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0665 - accuracy: 0.97 - ETA: 1s - loss: 0.0944 - accuracy: 0.95 - ETA: 1s - loss: 0.0982 - accuracy: 0.95 - ETA: 1s - loss: 0.1007 - accuracy: 0.95 - ETA: 1s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1022 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1069 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1074 - accuracy: 0.95 - ETA: 0s - loss: 0.1090 - accuracy: 0.95 - ETA: 0s - loss: 0.1081 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1046 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - 1s 144us/step - loss: 0.1037 - accuracy: 0.9579 - val_loss: 0.0579 - val_accuracy: 0.9823\n",
            "Epoch 31/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1934 - accuracy: 0.91 - ETA: 1s - loss: 0.1190 - accuracy: 0.95 - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1104 - accuracy: 0.95 - ETA: 1s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1102 - accuracy: 0.95 - ETA: 0s - loss: 0.1105 - accuracy: 0.95 - ETA: 0s - loss: 0.1083 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1041 - accuracy: 0.95 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - 1s 140us/step - loss: 0.1028 - accuracy: 0.9581 - val_loss: 0.0610 - val_accuracy: 0.9779\n",
            "Epoch 32/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0948 - accuracy: 0.96 - ETA: 1s - loss: 0.1053 - accuracy: 0.95 - ETA: 1s - loss: 0.0971 - accuracy: 0.95 - ETA: 1s - loss: 0.0945 - accuracy: 0.95 - ETA: 1s - loss: 0.1004 - accuracy: 0.95 - ETA: 1s - loss: 0.0980 - accuracy: 0.95 - ETA: 0s - loss: 0.0973 - accuracy: 0.95 - ETA: 0s - loss: 0.0967 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - ETA: 0s - loss: 0.0976 - accuracy: 0.95 - ETA: 0s - loss: 0.0976 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - 1s 140us/step - loss: 0.1007 - accuracy: 0.9587 - val_loss: 0.0612 - val_accuracy: 0.9787\n",
            "Epoch 33/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0851 - accuracy: 0.97 - ETA: 1s - loss: 0.1146 - accuracy: 0.95 - ETA: 1s - loss: 0.1118 - accuracy: 0.95 - ETA: 1s - loss: 0.1046 - accuracy: 0.95 - ETA: 1s - loss: 0.0999 - accuracy: 0.95 - ETA: 1s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0988 - accuracy: 0.96 - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - 1s 142us/step - loss: 0.0985 - accuracy: 0.9600 - val_loss: 0.0645 - val_accuracy: 0.9731\n",
            "Epoch 34/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0644 - accuracy: 0.98 - ETA: 1s - loss: 0.0993 - accuracy: 0.96 - ETA: 1s - loss: 0.0925 - accuracy: 0.96 - ETA: 1s - loss: 0.0921 - accuracy: 0.96 - ETA: 1s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0931 - accuracy: 0.96 - ETA: 0s - loss: 0.0922 - accuracy: 0.96 - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - ETA: 0s - loss: 0.0975 - accuracy: 0.95 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0932 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0938 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0942 - accuracy: 0.96 - ETA: 0s - loss: 0.0948 - accuracy: 0.96 - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - ETA: 0s - loss: 0.0948 - accuracy: 0.96 - ETA: 0s - loss: 0.0957 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0957 - accuracy: 0.96 - 1s 144us/step - loss: 0.0963 - accuracy: 0.9597 - val_loss: 0.0568 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1054 - accuracy: 0.96 - ETA: 1s - loss: 0.1059 - accuracy: 0.95 - ETA: 1s - loss: 0.0974 - accuracy: 0.95 - ETA: 1s - loss: 0.0988 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0973 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - ETA: 0s - loss: 0.0992 - accuracy: 0.95 - ETA: 0s - loss: 0.0971 - accuracy: 0.95 - ETA: 0s - loss: 0.0963 - accuracy: 0.96 - ETA: 0s - loss: 0.0977 - accuracy: 0.95 - ETA: 0s - loss: 0.0974 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.0997 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - 1s 141us/step - loss: 0.1025 - accuracy: 0.9573 - val_loss: 0.0639 - val_accuracy: 0.9813\n",
            "Epoch 36/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0902 - accuracy: 0.96 - ETA: 1s - loss: 0.0886 - accuracy: 0.96 - ETA: 1s - loss: 0.0891 - accuracy: 0.96 - ETA: 1s - loss: 0.0923 - accuracy: 0.96 - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1015 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1006 - accuracy: 0.95 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - 1s 142us/step - loss: 0.1004 - accuracy: 0.9596 - val_loss: 0.0576 - val_accuracy: 0.9846\n",
            "Epoch 37/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1155 - accuracy: 0.94 - ETA: 1s - loss: 0.1054 - accuracy: 0.95 - ETA: 1s - loss: 0.0912 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.96 - ETA: 0s - loss: 0.1001 - accuracy: 0.96 - ETA: 0s - loss: 0.0994 - accuracy: 0.96 - ETA: 0s - loss: 0.0997 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.0985 - accuracy: 0.96 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - 1s 137us/step - loss: 0.1021 - accuracy: 0.9587 - val_loss: 0.0598 - val_accuracy: 0.9843\n",
            "Epoch 38/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0962 - accuracy: 0.96 - ETA: 1s - loss: 0.1268 - accuracy: 0.95 - ETA: 1s - loss: 0.1191 - accuracy: 0.95 - ETA: 1s - loss: 0.1109 - accuracy: 0.95 - ETA: 1s - loss: 0.1065 - accuracy: 0.95 - ETA: 1s - loss: 0.1027 - accuracy: 0.96 - ETA: 0s - loss: 0.1014 - accuracy: 0.96 - ETA: 0s - loss: 0.1000 - accuracy: 0.96 - ETA: 0s - loss: 0.0995 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0997 - accuracy: 0.96 - ETA: 0s - loss: 0.0988 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - ETA: 0s - loss: 0.0988 - accuracy: 0.96 - 1s 139us/step - loss: 0.0993 - accuracy: 0.9602 - val_loss: 0.0565 - val_accuracy: 0.9849\n",
            "Epoch 39/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0588 - accuracy: 0.98 - ETA: 1s - loss: 0.0950 - accuracy: 0.96 - ETA: 1s - loss: 0.1111 - accuracy: 0.95 - ETA: 1s - loss: 0.1095 - accuracy: 0.95 - ETA: 1s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1062 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1075 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1049 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - 1s 143us/step - loss: 0.1042 - accuracy: 0.9572 - val_loss: 0.0588 - val_accuracy: 0.9837\n",
            "Epoch 40/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1030 - accuracy: 0.95 - ETA: 1s - loss: 0.0838 - accuracy: 0.96 - ETA: 1s - loss: 0.0952 - accuracy: 0.95 - ETA: 1s - loss: 0.0973 - accuracy: 0.95 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0962 - accuracy: 0.96 - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - ETA: 0s - loss: 0.0950 - accuracy: 0.96 - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0931 - accuracy: 0.96 - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0950 - accuracy: 0.96 - 1s 143us/step - loss: 0.0950 - accuracy: 0.9616 - val_loss: 0.0564 - val_accuracy: 0.9836\n",
            "Epoch 41/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1036 - accuracy: 0.95 - ETA: 1s - loss: 0.0910 - accuracy: 0.96 - ETA: 1s - loss: 0.0968 - accuracy: 0.95 - ETA: 1s - loss: 0.0969 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.1007 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - ETA: 0s - loss: 0.0989 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0998 - accuracy: 0.95 - ETA: 0s - loss: 0.0995 - accuracy: 0.95 - ETA: 0s - loss: 0.0990 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.0988 - accuracy: 0.95 - ETA: 0s - loss: 0.0987 - accuracy: 0.95 - 1s 141us/step - loss: 0.0985 - accuracy: 0.9596 - val_loss: 0.0641 - val_accuracy: 0.9737\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0939 - accuracy: 0.96 - ETA: 1s - loss: 0.0959 - accuracy: 0.96 - ETA: 1s - loss: 0.0978 - accuracy: 0.96 - ETA: 1s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - ETA: 0s - loss: 0.1013 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.0991 - accuracy: 0.95 - ETA: 0s - loss: 0.0988 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - 1s 140us/step - loss: 0.0999 - accuracy: 0.9590 - val_loss: 0.0610 - val_accuracy: 0.9797\n",
            "Epoch 43/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1292 - accuracy: 0.94 - ETA: 1s - loss: 0.1030 - accuracy: 0.95 - ETA: 1s - loss: 0.0901 - accuracy: 0.96 - ETA: 1s - loss: 0.0981 - accuracy: 0.95 - ETA: 0s - loss: 0.0930 - accuracy: 0.96 - ETA: 0s - loss: 0.0966 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - ETA: 0s - loss: 0.1038 - accuracy: 0.95 - ETA: 0s - loss: 0.1053 - accuracy: 0.95 - ETA: 0s - loss: 0.1070 - accuracy: 0.95 - ETA: 0s - loss: 0.1068 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1058 - accuracy: 0.95 - ETA: 0s - loss: 0.1050 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - ETA: 0s - loss: 0.1055 - accuracy: 0.95 - 1s 140us/step - loss: 0.1057 - accuracy: 0.9565 - val_loss: 0.0601 - val_accuracy: 0.9787\n",
            "Epoch 44/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0687 - accuracy: 0.97 - ETA: 1s - loss: 0.0817 - accuracy: 0.96 - ETA: 1s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.1004 - accuracy: 0.95 - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.0976 - accuracy: 0.96 - ETA: 0s - loss: 0.0996 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1005 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.0994 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1001 - accuracy: 0.95 - ETA: 0s - loss: 0.0996 - accuracy: 0.96 - ETA: 0s - loss: 0.0995 - accuracy: 0.96 - ETA: 0s - loss: 0.0994 - accuracy: 0.96 - ETA: 0s - loss: 0.0999 - accuracy: 0.95 - 1s 139us/step - loss: 0.0998 - accuracy: 0.9601 - val_loss: 0.0567 - val_accuracy: 0.9850\n",
            "Epoch 45/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0856 - accuracy: 0.96 - ETA: 1s - loss: 0.0891 - accuracy: 0.96 - ETA: 1s - loss: 0.0966 - accuracy: 0.96 - ETA: 1s - loss: 0.0929 - accuracy: 0.96 - ETA: 1s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1023 - accuracy: 0.95 - ETA: 0s - loss: 0.1018 - accuracy: 0.95 - ETA: 0s - loss: 0.1008 - accuracy: 0.95 - ETA: 0s - loss: 0.1000 - accuracy: 0.95 - ETA: 0s - loss: 0.1016 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1034 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1036 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - 1s 139us/step - loss: 0.1048 - accuracy: 0.9568 - val_loss: 0.0570 - val_accuracy: 0.9844\n",
            "Epoch 46/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0780 - accuracy: 0.96 - ETA: 1s - loss: 0.0792 - accuracy: 0.97 - ETA: 1s - loss: 0.0835 - accuracy: 0.96 - ETA: 1s - loss: 0.0889 - accuracy: 0.96 - ETA: 0s - loss: 0.0917 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.96 - ETA: 0s - loss: 0.1011 - accuracy: 0.95 - ETA: 0s - loss: 0.1040 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1108 - accuracy: 0.95 - ETA: 0s - loss: 0.1112 - accuracy: 0.95 - ETA: 0s - loss: 0.1086 - accuracy: 0.95 - ETA: 0s - loss: 0.1091 - accuracy: 0.95 - ETA: 0s - loss: 0.1093 - accuracy: 0.95 - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - ETA: 0s - loss: 0.1077 - accuracy: 0.95 - ETA: 0s - loss: 0.1072 - accuracy: 0.95 - ETA: 0s - loss: 0.1067 - accuracy: 0.95 - ETA: 0s - loss: 0.1064 - accuracy: 0.95 - ETA: 0s - loss: 0.1054 - accuracy: 0.95 - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - ETA: 0s - loss: 0.1057 - accuracy: 0.95 - 1s 138us/step - loss: 0.1055 - accuracy: 0.9575 - val_loss: 0.0604 - val_accuracy: 0.9784\n",
            "Epoch 47/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.1118 - accuracy: 0.96 - ETA: 1s - loss: 0.1008 - accuracy: 0.95 - ETA: 1s - loss: 0.1026 - accuracy: 0.95 - ETA: 1s - loss: 0.0985 - accuracy: 0.95 - ETA: 1s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1044 - accuracy: 0.95 - ETA: 0s - loss: 0.1014 - accuracy: 0.95 - ETA: 0s - loss: 0.1010 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1025 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1045 - accuracy: 0.95 - ETA: 0s - loss: 0.1030 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1017 - accuracy: 0.95 - ETA: 0s - loss: 0.1028 - accuracy: 0.95 - ETA: 0s - loss: 0.1019 - accuracy: 0.95 - ETA: 0s - loss: 0.1024 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - 1s 141us/step - loss: 0.1025 - accuracy: 0.9575 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
            "Epoch 48/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0863 - accuracy: 0.97 - ETA: 1s - loss: 0.0820 - accuracy: 0.97 - ETA: 1s - loss: 0.0912 - accuracy: 0.96 - ETA: 0s - loss: 0.0886 - accuracy: 0.96 - ETA: 0s - loss: 0.0885 - accuracy: 0.96 - ETA: 0s - loss: 0.0901 - accuracy: 0.96 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - ETA: 0s - loss: 0.0952 - accuracy: 0.96 - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - ETA: 0s - loss: 0.0946 - accuracy: 0.96 - ETA: 0s - loss: 0.0947 - accuracy: 0.96 - ETA: 0s - loss: 0.0952 - accuracy: 0.96 - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - ETA: 0s - loss: 0.0963 - accuracy: 0.96 - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0981 - accuracy: 0.95 - 1s 138us/step - loss: 0.0982 - accuracy: 0.9599 - val_loss: 0.0589 - val_accuracy: 0.9836\n",
            "Epoch 49/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0792 - accuracy: 0.97 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 1s - loss: 0.0937 - accuracy: 0.96 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0966 - accuracy: 0.96 - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 0s - loss: 0.0970 - accuracy: 0.96 - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0950 - accuracy: 0.96 - ETA: 0s - loss: 0.0983 - accuracy: 0.95 - ETA: 0s - loss: 0.0961 - accuracy: 0.96 - ETA: 0s - loss: 0.0978 - accuracy: 0.95 - ETA: 0s - loss: 0.1002 - accuracy: 0.95 - ETA: 0s - loss: 0.1003 - accuracy: 0.95 - ETA: 0s - loss: 0.1026 - accuracy: 0.95 - ETA: 0s - loss: 0.1047 - accuracy: 0.95 - ETA: 0s - loss: 0.1043 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1037 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1031 - accuracy: 0.95 - 1s 139us/step - loss: 0.1032 - accuracy: 0.9573 - val_loss: 0.0607 - val_accuracy: 0.9779\n",
            "Epoch 50/50\n",
            "10224/10224 [==============================] - ETA: 1s - loss: 0.0989 - accuracy: 0.96 - ETA: 1s - loss: 0.0844 - accuracy: 0.96 - ETA: 1s - loss: 0.0921 - accuracy: 0.96 - ETA: 1s - loss: 0.0901 - accuracy: 0.96 - ETA: 0s - loss: 0.0897 - accuracy: 0.96 - ETA: 0s - loss: 0.0896 - accuracy: 0.96 - ETA: 0s - loss: 0.0909 - accuracy: 0.96 - ETA: 0s - loss: 0.0918 - accuracy: 0.96 - ETA: 0s - loss: 0.0927 - accuracy: 0.96 - ETA: 0s - loss: 0.0933 - accuracy: 0.96 - ETA: 0s - loss: 0.0962 - accuracy: 0.96 - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - ETA: 0s - loss: 0.0943 - accuracy: 0.96 - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - ETA: 0s - loss: 0.0998 - accuracy: 0.96 - ETA: 0s - loss: 0.1021 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1027 - accuracy: 0.95 - ETA: 0s - loss: 0.1020 - accuracy: 0.95 - 1s 136us/step - loss: 0.1029 - accuracy: 0.9581 - val_loss: 0.0583 - val_accuracy: 0.9839\n",
            "\n",
            "--- Learning curve of model training ---\n",
            "\n",
            "\n",
            "--- Check against test data ---\n",
            "\n",
            "1420/1420 [==============================] - ETA:  - ETA:  - ETA:  - 0s 111us/step\n",
            "\n",
            "Accuracy on test data: 0.98\n",
            "\n",
            "Loss on test data: 0.06\n",
            "\n",
            "--- Confusion matrix for test data ---\n",
            "\n",
            "hello\n",
            "<bound method _BaseKFold.split of KFold(n_splits=10, random_state=None, shuffle=True)>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       121\n",
            "           1       0.99      0.99      0.99       141\n",
            "           2       0.99      0.96      0.97       425\n",
            "           3       0.93      0.98      0.95       294\n",
            "           4       0.96      0.96      0.96       439\n",
            "\n",
            "    accuracy                           0.97      1420\n",
            "   macro avg       0.97      0.98      0.98      1420\n",
            "weighted avg       0.97      0.97      0.97      1420\n",
            "\n",
            "finished\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10, shuffle=True) # Define the split - into 2 folds\n",
        "kf.get_n_splits(x_train) # returns the number of splitting iterations in the cross-validator\n",
        "print(kf)\n",
        "i=0\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    print(\"Train Index: \", train_index, \"\\n\")\n",
        "    print(\"Test Index: \", test_index)\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = x_train[train_index], x_train[test_index], y_train[train_index], y_train[test_index]\n",
        "    tr_img_data1, test_img_data1  = tr_img_data[train_index], tr_img_data[test_index]\n",
        "\n",
        "\n",
        "    print(\"\\n--- Fit the model ---\\n\")\n",
        "\n",
        "    # The EarlyStopping callback monitors training accuracy:\n",
        "    # if it fails to improve for two consecutive epochs,\n",
        "    # training stops early\n",
        "    callbacks_list = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "            monitor='val_loss', save_best_only=True),\n",
        "        keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Hyper-parameters\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 50\n",
        "\n",
        "    # Define the Keras TensorBoard callback.\n",
        "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "     ##Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
        "    history = model2.fit([X_train, tr_img_data1],\n",
        "                          Y_train,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          epochs=EPOCHS,\n",
        "                          callbacks=[tensorboard_callback],\n",
        "                          validation_split=0.2,\n",
        "                          verbose=1\n",
        "                        )\n",
        "\n",
        "    score = model2.evaluate([X_test, test_img_data1], Y_test, verbose=1)\n",
        "\n",
        "    print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
        "    print(\"\\nLoss on test data: %0.2f\" % score[0])\n",
        "    print(\"\\n--- Confusion matrix for test data ---\\n\")\n",
        "\n",
        "    y_pred_test = model2.predict([X_test, test_img_data1])\n",
        "    print(kf.split)\n",
        "\n",
        "    if i==0:\n",
        "        y_pred_test_all = y_pred_test\n",
        "        Y_test_all = Y_test\n",
        "        X_test_all = X_test\n",
        "        test_img_data1_all = test_img_data1\n",
        "    if i>0:\n",
        "        y_pred_test_all = np.concatenate((y_pred_test_all, y_pred_test))\n",
        "        Y_test_all = np.concatenate((Y_test_all, Y_test))\n",
        "        X_test_all = np.concatenate((X_test_all, X_test))\n",
        "        test_img_data1_all = np.concatenate((test_img_data1_all, test_img_data1))\n",
        "\n",
        "    # Take the class with the highest probability from the test predictions\n",
        "    max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "    max_y_test = np.argmax(Y_test, axis=1)\n",
        "\n",
        "    show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "    print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "    print(classification_report(max_y_test, max_y_pred_test))\n",
        "    print(\"finished\")\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "3rNE9GrnDBSY",
        "outputId": "4165f498-fbc5-4f0f-a43f-21e9a59df34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3550/3550 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 130us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       290\n",
            "           1       0.98      0.98      0.98       349\n",
            "           2       0.99      0.96      0.98      1077\n",
            "           3       0.93      0.99      0.96       804\n",
            "           4       0.97      0.96      0.96      1030\n",
            "\n",
            "    accuracy                           0.97      3550\n",
            "   macro avg       0.97      0.98      0.98      3550\n",
            "weighted avg       0.97      0.97      0.97      3550\n",
            "\n",
            "\n",
            "Accuracy on test data: 0.984\n",
            "\n",
            "Loss on test data: 0.059\n"
          ]
        }
      ],
      "source": [
        "#per test train split\n",
        "\n",
        "score = model2.evaluate([x_test2, tst_img_data2], y_test2, verbose=1)\n",
        "\n",
        "y_pred_test = model2.predict([x_test2, tst_img_data2])\n",
        "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "max_y_test = np.argmax(y_test2, axis=1)\n",
        "\n",
        "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "print(classification_report(max_y_test, max_y_pred_test))\n",
        "\n",
        "\n",
        "print(\"\\nAccuracy on test data: %0.3f\" % score[1])\n",
        "print(\"\\nLoss on test data: %0.3f\" % score[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3jafc6kDBSY",
        "outputId": "b690ceac-d956-4edb-df2c-11747037200e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1384/1384 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 136us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       137\n",
            "           1       0.00      0.00      0.00       115\n",
            "           2       0.36      0.55      0.44       506\n",
            "           3       0.00      0.00      0.00       208\n",
            "           4       0.61      0.65      0.63       418\n",
            "\n",
            "    accuracy                           0.40      1384\n",
            "   macro avg       0.20      0.24      0.21      1384\n",
            "weighted avg       0.32      0.40      0.35      1384\n",
            "\n",
            "\n",
            "Accuracy on test data: 0.758\n",
            "\n",
            "Loss on test data: 1.663\n"
          ]
        }
      ],
      "source": [
        "#per user\n",
        "\n",
        "score = model2.evaluate([x_test1, tst_img_data], y_test1, verbose=1)\n",
        "\n",
        "y_pred_test = model2.predict([x_test1, tst_img_data])\n",
        "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "max_y_test = np.argmax(y_test1, axis=1)\n",
        "\n",
        "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "print(classification_report(max_y_test, max_y_pred_test))\n",
        "\n",
        "\n",
        "print(\"\\nAccuracy on test data: %0.3f\" % score[1])\n",
        "print(\"\\nLoss on test data: %0.3f\" % score[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_we4waxDBSY",
        "outputId": "0badd8ac-5013-468a-8643-21c3de72c27d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████| 1384/1384 [00:12<00:00, 112.61it/s]\n"
          ]
        }
      ],
      "source": [
        "test_data =r'C:\\Users\\cmp3woodwk\\Desktop\\deep transfer learning\\gasf_user20'\n",
        "testing_images = test_data_with_label()\n",
        "tst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,64,64,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJT6dERJDBSY",
        "outputId": "2648b4f9-bd05-4d51-b440-8913d79f8b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Reshape the data into segments ---\n",
            "\n",
            "\n",
            "--- Reshape data to be accepted by Keras ---\n",
            "\n",
            "x_train shape:  (14200, 200)\n",
            "14200 training samples\n",
            "y_train shape:  (14200, 5)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_user1 = read_data2('user20.csv')\n",
        "\n",
        "\n",
        "\n",
        "# Define column name of the label vector\n",
        "LABEL = \"ActivityEncoded\"\n",
        "# Transform the labels from String to Integer via LabelEncoder\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Add a new column to the existing DataFrame with the encoded values\n",
        "df_user1[LABEL] = le.fit_transform(df_user1[\"state\"].values.ravel())\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Reshape the data into segments ---\\n\")\n",
        "\n",
        "# Differentiate between test set and training set\n",
        "df_test = df_user1\n",
        "\n",
        "df_test['EDA'] = feature_normalize(df_user1['EDA'])\n",
        "df_test['HR'] = feature_normalize(df_user1['HR'])\n",
        "\n",
        "x_test1, y_test1 = create_segments_and_labels(df_test,\n",
        "                                              TIME_PERIODS,\n",
        "                                              STEP_DISTANCE,\n",
        "                                              LABEL)\n",
        "\n",
        "\n",
        "print(\"\\n--- Reshape data to be accepted by Keras ---\\n\")\n",
        "\n",
        "# Inspect x data\n",
        "print('x_train shape: ', x_train.shape)\n",
        "# Displays (20869, 40, 3)\n",
        "print(x_train.shape[0], 'training samples')\n",
        "# Displays 20869 train samples\n",
        "\n",
        "# Inspect y data\n",
        "print('y_train shape: ', y_train.shape)\n",
        "# Displays (20869,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA6MYZI8DBSY",
        "outputId": "135eed7e-740c-4474-fc1d-36209baf4c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5]\n",
            "x_train shape: (14200, 200)\n",
            "input_shape: 200\n",
            "New y_train shape:  (14200, 5)\n",
            "\n",
            "--- Create neural network model ---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set input & output dimensions\n",
        "\n",
        "print(list(le.classes_))\n",
        "num_classes = 5\n",
        "# Set input_shape / reshape for Keras\n",
        "# Remark: acceleration data is concatenated in one array in order to feed\n",
        "# it properly into coreml later, the preferred matrix of shape [40,3]\n",
        "# cannot be read in with the current version of coreml (see also reshape\n",
        "# layer as the first layer in the keras model)\n",
        "input_shape = (num_time_periods*num_sensors)\n",
        "\n",
        "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
        "\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "# x_train shape: (20869, 120)\n",
        "print('input_shape:', input_shape)\n",
        "# input_shape: (120)\n",
        "\n",
        "x_test1 = x_test1.astype(\"float32\")\n",
        "y_test1 = y_test1.astype(\"float32\")\n",
        "\n",
        "# %%\n",
        "\n",
        "# One-hot encoding of y_train labels (only execute once!)\n",
        "y_test1 = np_utils.to_categorical(y_test1, num_classes)\n",
        "\n",
        "print('New y_train shape: ', y_train.shape)\n",
        "# (4173, 6)\n",
        "\n",
        "print(\"\\n--- Create neural network model ---\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9p6UJRTDBSZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model2, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yns6xingDBSZ"
      },
      "outputs": [],
      "source": [
        "from ann_visualizer.visualize import ann_viz;\n",
        "\n",
        "ann_viz(model2, title=\"My first neural network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qgY9ThoDBSa",
        "outputId": "224ecbfa-5d39-43a8-d464-ca7e2c07563c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17750/17750 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 115us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification report for test data ---\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       148\n",
            "           1       0.99      1.00      0.99       178\n",
            "           2       0.98      0.98      0.98       513\n",
            "           3       0.96      1.00      0.98       373\n",
            "           4       0.99      0.96      0.98       563\n",
            "\n",
            "    accuracy                           0.98      1775\n",
            "   macro avg       0.98      0.99      0.99      1775\n",
            "weighted avg       0.98      0.98      0.98      1775\n",
            "\n",
            "\n",
            "Accuracy on test data: 0.99\n",
            "\n",
            "Loss on test data: 0.02\n"
          ]
        }
      ],
      "source": [
        "score = model2.evaluate([X_test_all, test_img_data1_all], Y_test_all, verbose=1)\n",
        "\n",
        "max_y_pred_test_all = np.argmax(y_pred_test_all, axis=1)\n",
        "max_y_test_all = np.argmax(Y_test_all, axis=1)\n",
        "\n",
        "show_confusion_matrix(max_y_test_all, max_y_pred_test_all)\n",
        "print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "print(classification_report(max_y_test, max_y_pred_test))\n",
        "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
        "print(\"\\nLoss on test data: %0.2f\" % score[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b84o79SsDBSa"
      },
      "outputs": [],
      "source": [
        "np.corrcoef([df_train['EDA'],df_train['HR'],df_train['UV'],df_train['bTemp'],df_train['AirPressure'],df_train['EnvNoise']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqMXpYaTDBSa"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#matplotlib.style.use('ggplot')\n",
        "\n",
        "plt.scatter(df_train['bTemp'], df_train['AirPressure'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zepr42euDBSa"
      },
      "outputs": [],
      "source": [
        "from tempfile import TemporaryFile\n",
        "outfile = TemporaryFile()\n",
        "\n",
        "np.save(outfile, y_pred_test_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA6_yrZiDBSa"
      },
      "source": [
        "# No cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6QJoMifrDBSa"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Fit the model ---\\n\")\n",
        "\n",
        "# The EarlyStopping callback monitors training accuracy:\n",
        "# if it fails to improve for two consecutive epochs,\n",
        "# training stops early\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "        monitor='val_loss', save_best_only=True),\n",
        "    keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 50\n",
        "\n",
        "\n",
        " ##Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
        "history = model2.fit([x_train, tr_img_data],\n",
        "                      y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      callbacks=callbacks_list,\n",
        "                      validation_split=0.2,\n",
        "                      verbose=1\n",
        "                    )\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Learning curve of model training ---\\n\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Check against test data ---\\n\")\n",
        "\n",
        "score = model2.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
        "print(\"\\nLoss on test data: %0.2f\" % score[0])\n",
        "\n",
        "# %%\n",
        "\n",
        "print(\"\\n--- Confusion matrix for test data ---\\n\")\n",
        "\n",
        "y_pred_test = model_m.predict(x_test)\n",
        "# Take the class with the highest probability from the test predictions\n",
        "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "max_y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "print(classification_report(max_y_test, max_y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTjEsPtvDBSa"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWJiojjPDBSa"
      },
      "source": [
        "# Stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIJ2A7fYDBSa"
      },
      "outputs": [],
      "source": [
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "model2.fit_generator(generator=gen_flow,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD4lVJ5jcVDw"
      },
      "outputs": [],
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wB8wWFEdyeU"
      },
      "outputs": [],
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "steps=STEP_SIZE_TEST,\n",
        "verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDDv8mBL7e2P"
      },
      "outputs": [],
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "classes = test_generator.classes[test_generator.index_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoFsncC299MD"
      },
      "outputs": [],
      "source": [
        "predicted_class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXWVn5iX9_h9"
      },
      "outputs": [],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaZeWiG19iN1"
      },
      "outputs": [],
      "source": [
        "sum(predicted_class_indices==classes)/4096\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAJfNV449tc9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_generator.classes[test_generator.index_array],predicted_class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tciI6CwKduRV"
      },
      "outputs": [],
      "source": [
        "#labels = (train_generator.class_indices) #original changed to test\n",
        "labels = (test_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhtafD7Ly7y1"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYEDTm9Ed-DC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwqT9uhmzDKd"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRpZG52v6EU5"
      },
      "source": [
        "Model is now trained. Now lets test some independent input images to check the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElECZAMB6EU6"
      },
      "outputs": [],
      "source": [
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaTy7XYk6EU7"
      },
      "outputs": [],
      "source": [
        "img_path = 'experiment6.png'\n",
        "new_image = load_image(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J9MUMyZ6EU9"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(new_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUk2CkfI6EVC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}